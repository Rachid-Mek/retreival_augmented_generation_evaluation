{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdtS-YIFYHeK"
      },
      "source": [
        "This notebook shows how to evaluate LLMs with the Evaluation Harness framework, focusing on quantized LLMs and LoRA adapters.\n",
        "\n",
        "**First, we need to install lm-eval which runs the evaluation harness. Also,install bitsandbytes to evaluate quantized models.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIbG0cbNcCs0",
        "outputId": "511193fa-0355-4608-e1a5-2989c81f3ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.7.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.9.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.64.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.20.0 (from qdrant_client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.25.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.0.7)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant_client)\n",
            "  Downloading protobuf-5.27.0-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.11.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.20.0->qdrant_client) (1.2.1)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, h11, httpcore, h2, grpcio-tools, httpx, qdrant_client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.52.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
            "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.27.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-tools-1.64.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 portalocker-2.8.2 protobuf-5.27.0 qdrant_client-1.9.1\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/peft.git\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install qdrant_client\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YunQj2374vAY",
        "outputId": "4ee1e5b1-0f07-4dec-87b9-8417201b2634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(token='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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLL5Chn8cF7E",
        "outputId": "3031b221-0f7d-48cf-e25b-e78ad1712a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'RGB'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 50 (delta 22), reused 32 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (50/50), 8.16 MiB | 13.37 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/chen700564/RGB.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwCm8RlkcGQ7",
        "outputId": "5d61802d-e904-432a-93c4-9184e5295504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/RGB\n"
          ]
        }
      ],
      "source": [
        "%cd /content/RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9mGc5SfcILC",
        "outputId": "43589bbc-d6d8-4aab-f439-5d283395acd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en_fact.json  en.json\t      zh_fact.json  zh.json\n",
            "en_int.json   en_refine.json  zh_int.json   zh_refine.json\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDaSuBm6TadI"
      },
      "source": [
        "# Counterfactual Robustness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC_9lro4cKqj",
        "outputId": "a50f37f6-e4c6-4715-8080-12ae39ecea75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rtokenizer_config.json:   0% 0.00/244 [00:00<?, ?B/s]\rtokenizer_config.json: 100% 244/244 [00:00<00:00, 1.62MB/s]\n",
            "\rtokenization_chatglm.py:   0% 0.00/10.1k [00:00<?, ?B/s]\rtokenization_chatglm.py: 100% 10.1k/10.1k [00:00<00:00, 47.4MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
            "- tokenization_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "tokenizer.model: 100% 1.02M/1.02M [00:00<00:00, 20.3MB/s]\n",
            "config.json: 100% 1.32k/1.32k [00:00<00:00, 10.4MB/s]\n",
            "configuration_chatglm.py: 100% 2.33k/2.33k [00:00<00:00, 19.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
            "- configuration_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_chatglm.py: 100% 54.9k/54.9k [00:00<00:00, 5.99MB/s]\n",
            "quantization.py: 100% 14.7k/14.7k [00:00<00:00, 62.4MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
            "- modeling_chatglm.py\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "pytorch_model.bin.index.json: 100% 20.4k/20.4k [00:00<00:00, 47.7MB/s]\n",
            "Downloading shards:   0% 0/7 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00007.bin:   0% 0.00/1.83G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   1% 10.5M/1.83G [00:00<00:39, 45.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   1% 21.0M/1.83G [00:00<00:32, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   2% 31.5M/1.83G [00:00<00:28, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   2% 41.9M/1.83G [00:00<00:24, 71.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   3% 52.4M/1.83G [00:00<00:22, 80.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   4% 73.4M/1.83G [00:00<00:18, 96.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   5% 94.4M/1.83G [00:01<00:15, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   6% 115M/1.83G [00:01<00:14, 120MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   7% 136M/1.83G [00:01<00:13, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:   9% 157M/1.83G [00:01<00:13, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  10% 178M/1.83G [00:01<00:12, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  11% 199M/1.83G [00:01<00:12, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  12% 220M/1.83G [00:01<00:11, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  13% 241M/1.83G [00:02<00:11, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  14% 262M/1.83G [00:02<00:11, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  15% 283M/1.83G [00:02<00:11, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  17% 304M/1.83G [00:02<00:11, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  18% 325M/1.83G [00:02<00:10, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  19% 346M/1.83G [00:02<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  20% 367M/1.83G [00:03<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  21% 388M/1.83G [00:03<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  22% 409M/1.83G [00:03<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  24% 430M/1.83G [00:03<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  25% 451M/1.83G [00:03<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  26% 472M/1.83G [00:03<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  27% 493M/1.83G [00:03<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  28% 514M/1.83G [00:04<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  29% 535M/1.83G [00:04<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  30% 556M/1.83G [00:04<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  32% 577M/1.83G [00:04<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  33% 598M/1.83G [00:04<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  34% 619M/1.83G [00:04<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  35% 640M/1.83G [00:04<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  36% 661M/1.83G [00:05<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  37% 682M/1.83G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  38% 703M/1.83G [00:05<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  40% 724M/1.83G [00:05<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  41% 744M/1.83G [00:05<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  42% 765M/1.83G [00:05<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  43% 786M/1.83G [00:06<00:07, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  44% 807M/1.83G [00:06<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  45% 828M/1.83G [00:06<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  46% 849M/1.83G [00:06<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  48% 870M/1.83G [00:06<00:07, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  49% 891M/1.83G [00:06<00:07, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  50% 912M/1.83G [00:06<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  51% 933M/1.83G [00:07<00:06, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  52% 954M/1.83G [00:07<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  53% 975M/1.83G [00:07<00:06, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  55% 996M/1.83G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  56% 1.02G/1.83G [00:07<00:05, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  57% 1.04G/1.83G [00:07<00:05, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  58% 1.06G/1.83G [00:08<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  59% 1.08G/1.83G [00:08<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  60% 1.10G/1.83G [00:08<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  61% 1.12G/1.83G [00:08<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  63% 1.14G/1.83G [00:08<00:04, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  64% 1.16G/1.83G [00:08<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  65% 1.18G/1.83G [00:08<00:04, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  66% 1.21G/1.83G [00:09<00:04, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  67% 1.23G/1.83G [00:09<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  68% 1.25G/1.83G [00:09<00:04, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  69% 1.27G/1.83G [00:09<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  71% 1.29G/1.83G [00:09<00:03, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  72% 1.31G/1.83G [00:09<00:03, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  73% 1.33G/1.83G [00:09<00:03, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  74% 1.35G/1.83G [00:10<00:04, 105MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  75% 1.37G/1.83G [00:10<00:05, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  76% 1.38G/1.83G [00:10<00:05, 82.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  76% 1.39G/1.83G [00:11<00:06, 71.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  77% 1.41G/1.83G [00:11<00:06, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  77% 1.42G/1.83G [00:11<00:06, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  78% 1.43G/1.83G [00:11<00:06, 65.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  79% 1.44G/1.83G [00:11<00:06, 64.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  80% 1.46G/1.83G [00:11<00:04, 82.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  81% 1.48G/1.83G [00:12<00:04, 86.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  81% 1.49G/1.83G [00:12<00:04, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  83% 1.51G/1.83G [00:12<00:03, 84.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  84% 1.53G/1.83G [00:12<00:03, 85.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  84% 1.54G/1.83G [00:12<00:03, 78.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  85% 1.55G/1.83G [00:13<00:03, 75.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  85% 1.56G/1.83G [00:13<00:04, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  87% 1.58G/1.83G [00:13<00:03, 78.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  87% 1.59G/1.83G [00:13<00:03, 77.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  88% 1.61G/1.83G [00:13<00:02, 78.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  89% 1.63G/1.83G [00:14<00:02, 76.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  90% 1.65G/1.83G [00:14<00:02, 70.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  91% 1.66G/1.83G [00:14<00:02, 70.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  92% 1.68G/1.83G [00:14<00:01, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  93% 1.70G/1.83G [00:14<00:01, 97.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  94% 1.72G/1.83G [00:15<00:00, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  95% 1.74G/1.83G [00:15<00:00, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  96% 1.76G/1.83G [00:15<00:00, 124MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  98% 1.78G/1.83G [00:15<00:00, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin:  99% 1.80G/1.83G [00:15<00:00, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00007.bin: 100% 1.83G/1.83G [00:15<00:00, 115MB/s]\n",
            "Downloading shards:  14% 1/7 [00:15<01:35, 15.99s/it]\n",
            "pytorch_model-00002-of-00007.bin:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   1% 10.5M/1.97G [00:00<01:09, 28.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   1% 21.0M/1.97G [00:00<00:47, 41.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   2% 31.5M/1.97G [00:00<00:35, 54.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   2% 41.9M/1.97G [00:00<00:29, 65.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   3% 52.4M/1.97G [00:00<00:25, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   4% 73.4M/1.97G [00:01<00:20, 92.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   5% 94.4M/1.97G [00:01<00:17, 108MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   6% 115M/1.97G [00:01<00:15, 119MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   7% 136M/1.97G [00:01<00:14, 126MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   8% 157M/1.97G [00:01<00:13, 130MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:   9% 178M/1.97G [00:01<00:18, 96.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  10% 199M/1.97G [00:02<00:16, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  11% 220M/1.97G [00:02<00:15, 115MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  12% 241M/1.97G [00:02<00:14, 121MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  13% 262M/1.97G [00:02<00:13, 126MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  14% 283M/1.97G [00:02<00:13, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  15% 304M/1.97G [00:02<00:12, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  17% 325M/1.97G [00:03<00:12, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  18% 346M/1.97G [00:03<00:12, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  19% 367M/1.97G [00:03<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  20% 388M/1.97G [00:03<00:11, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  21% 409M/1.97G [00:03<00:11, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  22% 430M/1.97G [00:03<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  23% 451M/1.97G [00:03<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  24% 472M/1.97G [00:04<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  25% 493M/1.97G [00:04<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  26% 514M/1.97G [00:04<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  27% 535M/1.97G [00:04<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  28% 556M/1.97G [00:04<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  29% 577M/1.97G [00:04<00:10, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  30% 598M/1.97G [00:05<00:10, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  31% 619M/1.97G [00:05<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  32% 640M/1.97G [00:05<00:09, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  34% 661M/1.97G [00:05<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  35% 682M/1.97G [00:05<00:09, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  36% 703M/1.97G [00:05<00:09, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  37% 724M/1.97G [00:05<00:09, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  38% 744M/1.97G [00:06<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  39% 765M/1.97G [00:06<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  40% 786M/1.97G [00:06<00:08, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  41% 807M/1.97G [00:06<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  42% 828M/1.97G [00:06<00:08, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  43% 849M/1.97G [00:06<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  44% 870M/1.97G [00:07<00:08, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  45% 891M/1.97G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  46% 912M/1.97G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  47% 933M/1.97G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  48% 954M/1.97G [00:07<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  50% 975M/1.97G [00:07<00:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  51% 996M/1.97G [00:07<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  52% 1.02G/1.97G [00:08<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  53% 1.04G/1.97G [00:08<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  54% 1.06G/1.97G [00:08<00:06, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  55% 1.08G/1.97G [00:08<00:06, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  56% 1.10G/1.97G [00:08<00:06, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  57% 1.12G/1.97G [00:08<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  58% 1.14G/1.97G [00:09<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  59% 1.16G/1.97G [00:09<00:05, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  60% 1.18G/1.97G [00:09<00:05, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  61% 1.21G/1.97G [00:09<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  62% 1.23G/1.97G [00:09<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  63% 1.25G/1.97G [00:09<00:05, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  64% 1.27G/1.97G [00:09<00:04, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  66% 1.29G/1.97G [00:10<00:04, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  67% 1.31G/1.97G [00:10<00:05, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  68% 1.33G/1.97G [00:10<00:06, 104MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  69% 1.35G/1.97G [00:10<00:06, 94.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  69% 1.36G/1.97G [00:11<00:07, 84.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  70% 1.38G/1.97G [00:11<00:05, 97.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  71% 1.39G/1.97G [00:11<00:05, 98.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  72% 1.42G/1.97G [00:11<00:05, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  73% 1.44G/1.97G [00:11<00:05, 101MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  74% 1.46G/1.97G [00:11<00:05, 97.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  75% 1.47G/1.97G [00:12<00:05, 92.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  75% 1.48G/1.97G [00:12<00:06, 72.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  76% 1.49G/1.97G [00:12<00:07, 67.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  77% 1.51G/1.97G [00:12<00:05, 78.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  78% 1.53G/1.97G [00:12<00:05, 83.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  78% 1.54G/1.97G [00:13<00:05, 83.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  79% 1.55G/1.97G [00:13<00:05, 78.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  79% 1.56G/1.97G [00:13<00:05, 79.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  80% 1.57G/1.97G [00:13<00:05, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  80% 1.58G/1.97G [00:13<00:04, 79.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  81% 1.59G/1.97G [00:13<00:04, 76.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  82% 1.60G/1.97G [00:13<00:04, 73.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  82% 1.61G/1.97G [00:14<00:04, 76.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  83% 1.63G/1.97G [00:14<00:04, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  83% 1.64G/1.97G [00:14<00:04, 77.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  84% 1.65G/1.97G [00:14<00:04, 68.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  85% 1.67G/1.97G [00:14<00:03, 83.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  86% 1.69G/1.97G [00:14<00:02, 100MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  87% 1.71G/1.97G [00:14<00:02, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  88% 1.73G/1.97G [00:15<00:01, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  89% 1.75G/1.97G [00:15<00:01, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  90% 1.77G/1.97G [00:15<00:01, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  91% 1.79G/1.97G [00:15<00:01, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  92% 1.81G/1.97G [00:15<00:01, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  93% 1.84G/1.97G [00:15<00:00, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  94% 1.86G/1.97G [00:16<00:00, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  95% 1.88G/1.97G [00:16<00:00, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  96% 1.90G/1.97G [00:16<00:00, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  97% 1.92G/1.97G [00:16<00:00, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin:  99% 1.94G/1.97G [00:16<00:00, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00007.bin: 100% 1.97G/1.97G [00:16<00:00, 117MB/s]\n",
            "Downloading shards:  29% 2/7 [00:32<01:22, 16.57s/it]\n",
            "pytorch_model-00003-of-00007.bin:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   1% 10.5M/1.93G [00:00<00:47, 40.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   1% 21.0M/1.93G [00:00<00:38, 49.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   2% 31.5M/1.93G [00:00<00:32, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   2% 41.9M/1.93G [00:00<00:29, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   3% 52.4M/1.93G [00:00<00:25, 73.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   4% 73.4M/1.93G [00:00<00:20, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   5% 94.4M/1.93G [00:01<00:16, 108MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   6% 115M/1.93G [00:01<00:15, 120MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   7% 136M/1.93G [00:01<00:14, 127MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   8% 157M/1.93G [00:01<00:13, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:   9% 178M/1.93G [00:01<00:12, 135MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  10% 199M/1.93G [00:01<00:13, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  11% 220M/1.93G [00:02<00:12, 137MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  13% 241M/1.93G [00:02<00:11, 141MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  14% 262M/1.93G [00:02<00:11, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  15% 283M/1.93G [00:02<00:11, 141MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  16% 304M/1.93G [00:02<00:11, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  17% 325M/1.93G [00:02<00:11, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  18% 346M/1.93G [00:02<00:10, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  19% 367M/1.93G [00:03<00:10, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  20% 388M/1.93G [00:03<00:10, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  21% 409M/1.93G [00:03<00:10, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  22% 430M/1.93G [00:03<00:10, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  23% 451M/1.93G [00:03<00:10, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  24% 472M/1.93G [00:03<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  26% 493M/1.93G [00:03<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  27% 514M/1.93G [00:04<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  28% 535M/1.93G [00:04<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  29% 556M/1.93G [00:04<00:09, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  30% 577M/1.93G [00:04<00:09, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  31% 598M/1.93G [00:04<00:09, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  32% 619M/1.93G [00:04<00:09, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  33% 640M/1.93G [00:04<00:08, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  34% 661M/1.93G [00:05<00:08, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  35% 682M/1.93G [00:05<00:08, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  36% 703M/1.93G [00:05<00:08, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  38% 724M/1.93G [00:05<00:08, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  39% 744M/1.93G [00:05<00:08, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  40% 765M/1.93G [00:05<00:07, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  41% 786M/1.93G [00:05<00:07, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  42% 807M/1.93G [00:06<00:07, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  43% 828M/1.93G [00:06<00:07, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  44% 849M/1.93G [00:06<00:07, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  45% 870M/1.93G [00:06<00:07, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  46% 891M/1.93G [00:06<00:07, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  47% 912M/1.93G [00:06<00:07, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  48% 933M/1.93G [00:06<00:06, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  50% 954M/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  51% 975M/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  52% 996M/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  53% 1.02G/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  54% 1.04G/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  55% 1.06G/1.93G [00:07<00:06, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  56% 1.08G/1.93G [00:07<00:05, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  57% 1.10G/1.93G [00:08<00:05, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  58% 1.12G/1.93G [00:08<00:05, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  59% 1.14G/1.93G [00:08<00:05, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  60% 1.16G/1.93G [00:08<00:05, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  61% 1.18G/1.93G [00:08<00:05, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  63% 1.21G/1.93G [00:08<00:04, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  64% 1.23G/1.93G [00:08<00:04, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  65% 1.25G/1.93G [00:09<00:04, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  66% 1.27G/1.93G [00:09<00:04, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  67% 1.29G/1.93G [00:09<00:04, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  68% 1.31G/1.93G [00:09<00:04, 147MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  69% 1.33G/1.93G [00:09<00:04, 147MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  70% 1.35G/1.93G [00:09<00:03, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  71% 1.37G/1.93G [00:09<00:03, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  72% 1.39G/1.93G [00:10<00:04, 115MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  73% 1.42G/1.93G [00:10<00:05, 95.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  75% 1.44G/1.93G [00:10<00:05, 89.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  75% 1.45G/1.93G [00:10<00:05, 90.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  76% 1.47G/1.93G [00:11<00:04, 99.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  77% 1.49G/1.93G [00:11<00:05, 84.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  78% 1.50G/1.93G [00:11<00:05, 76.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  78% 1.51G/1.93G [00:11<00:05, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  79% 1.52G/1.93G [00:12<00:06, 65.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  79% 1.53G/1.93G [00:12<00:06, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  80% 1.54G/1.93G [00:12<00:05, 65.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  81% 1.55G/1.93G [00:12<00:05, 68.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  81% 1.56G/1.93G [00:12<00:05, 67.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  82% 1.57G/1.93G [00:12<00:05, 70.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  83% 1.59G/1.93G [00:13<00:04, 78.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  83% 1.60G/1.93G [00:13<00:04, 74.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  84% 1.61G/1.93G [00:13<00:04, 76.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  84% 1.63G/1.93G [00:13<00:04, 70.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  85% 1.64G/1.93G [00:13<00:03, 77.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  85% 1.65G/1.93G [00:13<00:03, 79.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  86% 1.66G/1.93G [00:13<00:03, 83.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  87% 1.67G/1.93G [00:13<00:03, 85.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  87% 1.68G/1.93G [00:14<00:03, 78.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  88% 1.70G/1.93G [00:14<00:02, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  89% 1.72G/1.93G [00:14<00:01, 111MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  90% 1.74G/1.93G [00:14<00:01, 121MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  91% 1.76G/1.93G [00:14<00:01, 91.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  93% 1.79G/1.93G [00:15<00:01, 119MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  94% 1.81G/1.93G [00:15<00:00, 124MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  95% 1.84G/1.93G [00:15<00:00, 130MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  96% 1.86G/1.93G [00:15<00:00, 129MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  97% 1.88G/1.93G [00:15<00:00, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin:  98% 1.90G/1.93G [00:15<00:00, 137MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00007.bin: 100% 1.93G/1.93G [00:15<00:00, 121MB/s]\n",
            "Downloading shards:  43% 3/7 [00:49<01:05, 16.36s/it]\n",
            "pytorch_model-00004-of-00007.bin:   0% 0.00/1.82G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   1% 10.5M/1.82G [00:00<01:37, 18.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   1% 21.0M/1.82G [00:00<01:10, 25.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   2% 31.5M/1.82G [00:01<00:54, 32.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   2% 41.9M/1.82G [00:01<00:43, 41.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   3% 52.4M/1.82G [00:01<00:36, 48.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   3% 62.9M/1.82G [00:01<00:30, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   4% 73.4M/1.82G [00:01<00:26, 66.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   5% 94.4M/1.82G [00:01<00:19, 87.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   6% 115M/1.82G [00:01<00:17, 98.2MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   8% 136M/1.82G [00:02<00:15, 110MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:   9% 157M/1.82G [00:02<00:14, 116MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  10% 178M/1.82G [00:02<00:13, 124MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  11% 199M/1.82G [00:02<00:12, 128MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  12% 220M/1.82G [00:02<00:12, 128MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  13% 241M/1.82G [00:02<00:12, 131MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  14% 262M/1.82G [00:03<00:11, 132MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  16% 283M/1.82G [00:03<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  17% 304M/1.82G [00:03<00:11, 130MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  18% 325M/1.82G [00:03<00:11, 129MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  19% 346M/1.82G [00:03<00:11, 131MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  20% 367M/1.82G [00:03<00:10, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  21% 388M/1.82G [00:03<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  23% 409M/1.82G [00:04<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  24% 430M/1.82G [00:04<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  25% 451M/1.82G [00:04<00:10, 134MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  26% 472M/1.82G [00:04<00:09, 135MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  27% 493M/1.82G [00:04<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  28% 514M/1.82G [00:04<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  29% 535M/1.82G [00:05<00:09, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  31% 556M/1.82G [00:05<00:09, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  32% 577M/1.82G [00:05<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  33% 598M/1.82G [00:05<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  34% 619M/1.82G [00:05<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  35% 640M/1.82G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  36% 661M/1.82G [00:05<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  38% 682M/1.82G [00:06<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  39% 703M/1.82G [00:06<00:08, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  40% 724M/1.82G [00:06<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  41% 744M/1.82G [00:06<00:07, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  42% 765M/1.82G [00:06<00:07, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  43% 786M/1.82G [00:06<00:07, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  44% 807M/1.82G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  46% 828M/1.82G [00:07<00:07, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  47% 849M/1.82G [00:07<00:07, 135MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  48% 870M/1.82G [00:07<00:06, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  49% 891M/1.82G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  50% 912M/1.82G [00:07<00:06, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  51% 933M/1.82G [00:07<00:06, 131MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  53% 954M/1.82G [00:08<00:06, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  54% 975M/1.82G [00:08<00:06, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  55% 996M/1.82G [00:08<00:06, 134MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  56% 1.02G/1.82G [00:08<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  57% 1.04G/1.82G [00:08<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  58% 1.06G/1.82G [00:08<00:05, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  59% 1.08G/1.82G [00:09<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  61% 1.10G/1.82G [00:09<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  62% 1.12G/1.82G [00:09<00:05, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  63% 1.14G/1.82G [00:09<00:04, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  64% 1.16G/1.82G [00:09<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  65% 1.18G/1.82G [00:09<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  66% 1.21G/1.82G [00:09<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  68% 1.23G/1.82G [00:10<00:04, 120MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  69% 1.25G/1.82G [00:10<00:05, 94.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  70% 1.27G/1.82G [00:10<00:06, 81.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  71% 1.29G/1.82G [00:11<00:06, 76.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  72% 1.30G/1.82G [00:11<00:06, 77.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  72% 1.31G/1.82G [00:11<00:06, 75.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  73% 1.32G/1.82G [00:11<00:06, 74.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  73% 1.33G/1.82G [00:11<00:06, 71.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  74% 1.34G/1.82G [00:11<00:06, 75.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  75% 1.35G/1.82G [00:12<00:06, 67.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  76% 1.37G/1.82G [00:12<00:05, 78.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  76% 1.38G/1.82G [00:12<00:06, 68.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  77% 1.41G/1.82G [00:12<00:05, 77.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  78% 1.42G/1.82G [00:12<00:05, 78.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  79% 1.43G/1.82G [00:13<00:05, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  79% 1.44G/1.82G [00:13<00:05, 69.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  80% 1.46G/1.82G [00:13<00:04, 86.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  81% 1.47G/1.82G [00:13<00:05, 68.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  83% 1.50G/1.82G [00:13<00:03, 102MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  84% 1.52G/1.82G [00:13<00:02, 113MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  85% 1.54G/1.82G [00:14<00:02, 120MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  86% 1.56G/1.82G [00:14<00:02, 124MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  87% 1.58G/1.82G [00:14<00:01, 127MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  88% 1.60G/1.82G [00:14<00:01, 126MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  90% 1.63G/1.82G [00:14<00:01, 130MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  91% 1.65G/1.82G [00:14<00:01, 132MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  92% 1.67G/1.82G [00:15<00:01, 132MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  93% 1.69G/1.82G [00:15<00:00, 134MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  94% 1.71G/1.82G [00:15<00:00, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  95% 1.73G/1.82G [00:15<00:00, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  96% 1.75G/1.82G [00:15<00:00, 133MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  98% 1.77G/1.82G [00:15<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin:  99% 1.79G/1.82G [00:15<00:00, 136MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00007.bin: 100% 1.82G/1.82G [00:16<00:00, 113MB/s]\n",
            "Downloading shards:  57% 4/7 [01:05<00:48, 16.33s/it]\n",
            "pytorch_model-00005-of-00007.bin:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   1% 10.5M/1.97G [00:00<00:23, 82.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   1% 21.0M/1.97G [00:00<00:21, 89.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   2% 31.5M/1.97G [00:00<00:20, 94.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   2% 41.9M/1.97G [00:00<00:19, 97.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   3% 62.9M/1.97G [00:00<00:16, 116MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   4% 83.9M/1.97G [00:00<00:15, 125MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   5% 105M/1.97G [00:00<00:14, 129MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   6% 126M/1.97G [00:01<00:13, 133MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   7% 147M/1.97G [00:01<00:13, 132MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:   9% 168M/1.97G [00:01<00:13, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  10% 189M/1.97G [00:01<00:13, 136MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  11% 210M/1.97G [00:01<00:12, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  12% 231M/1.97G [00:01<00:12, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  13% 252M/1.97G [00:01<00:12, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  14% 273M/1.97G [00:02<00:12, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  15% 294M/1.97G [00:02<00:11, 141MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  16% 315M/1.97G [00:02<00:12, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  17% 336M/1.97G [00:02<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  18% 357M/1.97G [00:02<00:11, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  19% 377M/1.97G [00:02<00:11, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  20% 398M/1.97G [00:03<00:11, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  21% 419M/1.97G [00:03<00:11, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  22% 440M/1.97G [00:03<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  23% 461M/1.97G [00:03<00:10, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  25% 482M/1.97G [00:03<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  26% 503M/1.97G [00:03<00:10, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  27% 524M/1.97G [00:03<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  28% 545M/1.97G [00:04<00:10, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  29% 566M/1.97G [00:04<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  30% 587M/1.97G [00:04<00:09, 141MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  31% 608M/1.97G [00:04<00:09, 141MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  32% 629M/1.97G [00:04<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  33% 650M/1.97G [00:04<00:09, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  34% 671M/1.97G [00:04<00:09, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  35% 692M/1.97G [00:05<00:09, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  36% 713M/1.97G [00:05<00:09, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  37% 734M/1.97G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  38% 755M/1.97G [00:05<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  39% 776M/1.97G [00:05<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  40% 797M/1.97G [00:05<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  42% 818M/1.97G [00:06<00:08, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  43% 839M/1.97G [00:06<00:08, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  44% 860M/1.97G [00:06<00:07, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  45% 881M/1.97G [00:06<00:08, 132MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  46% 902M/1.97G [00:06<00:07, 134MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  47% 923M/1.97G [00:06<00:07, 136MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  48% 944M/1.97G [00:06<00:07, 133MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  49% 965M/1.97G [00:07<00:07, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  50% 986M/1.97G [00:07<00:07, 136MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  51% 1.01G/1.97G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  52% 1.03G/1.97G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  53% 1.05G/1.97G [00:07<00:06, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  54% 1.07G/1.97G [00:07<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  55% 1.09G/1.97G [00:08<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  56% 1.11G/1.97G [00:08<00:06, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  58% 1.13G/1.97G [00:08<00:06, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  59% 1.15G/1.97G [00:08<00:05, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  60% 1.17G/1.97G [00:08<00:05, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  61% 1.20G/1.97G [00:08<00:05, 133MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  62% 1.22G/1.97G [00:08<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  63% 1.24G/1.97G [00:09<00:05, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  64% 1.26G/1.97G [00:09<00:05, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  65% 1.28G/1.97G [00:09<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  66% 1.30G/1.97G [00:09<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  67% 1.32G/1.97G [00:09<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  68% 1.34G/1.97G [00:09<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  69% 1.36G/1.97G [00:10<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  70% 1.38G/1.97G [00:10<00:05, 97.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  71% 1.41G/1.97G [00:10<00:06, 82.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  72% 1.42G/1.97G [00:10<00:07, 74.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  72% 1.43G/1.97G [00:11<00:07, 77.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  73% 1.44G/1.97G [00:11<00:08, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  74% 1.45G/1.97G [00:11<00:08, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  75% 1.47G/1.97G [00:11<00:06, 77.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  75% 1.48G/1.97G [00:11<00:06, 73.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  76% 1.49G/1.97G [00:12<00:07, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  76% 1.50G/1.97G [00:12<00:07, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  77% 1.52G/1.97G [00:12<00:05, 76.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  78% 1.54G/1.97G [00:12<00:05, 76.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  79% 1.55G/1.97G [00:12<00:05, 71.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  79% 1.56G/1.97G [00:13<00:05, 76.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  80% 1.57G/1.97G [00:13<00:05, 76.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  80% 1.58G/1.97G [00:13<00:04, 81.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  81% 1.59G/1.97G [00:13<00:04, 82.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  82% 1.60G/1.97G [00:13<00:04, 85.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  82% 1.61G/1.97G [00:13<00:04, 74.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  83% 1.64G/1.97G [00:13<00:03, 88.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  84% 1.66G/1.97G [00:14<00:03, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  85% 1.68G/1.97G [00:14<00:02, 111MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  86% 1.70G/1.97G [00:14<00:02, 120MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  87% 1.72G/1.97G [00:14<00:01, 126MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  88% 1.74G/1.97G [00:14<00:01, 127MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  89% 1.76G/1.97G [00:14<00:01, 129MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  91% 1.78G/1.97G [00:14<00:01, 132MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  92% 1.80G/1.97G [00:15<00:01, 135MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  93% 1.82G/1.97G [00:15<00:01, 137MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  94% 1.85G/1.97G [00:15<00:00, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  95% 1.87G/1.97G [00:15<00:00, 138MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  96% 1.89G/1.97G [00:15<00:00, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  97% 1.91G/1.97G [00:15<00:00, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  98% 1.93G/1.97G [00:16<00:00, 139MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin:  99% 1.95G/1.97G [00:16<00:00, 140MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00007.bin: 100% 1.97G/1.97G [00:16<00:00, 121MB/s]\n",
            "Downloading shards:  71% 5/7 [01:21<00:32, 16.37s/it]\n",
            "pytorch_model-00006-of-00007.bin:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   1% 10.5M/1.93G [00:00<00:36, 52.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   1% 21.0M/1.93G [00:00<00:31, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   2% 31.5M/1.93G [00:00<00:28, 67.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   3% 52.4M/1.93G [00:00<00:22, 84.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   4% 73.4M/1.93G [00:00<00:18, 100MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   5% 94.4M/1.93G [00:01<00:16, 111MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   6% 115M/1.93G [00:01<00:15, 119MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   7% 136M/1.93G [00:01<00:14, 124MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   8% 157M/1.93G [00:01<00:13, 127MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:   9% 178M/1.93G [00:01<00:13, 129MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  10% 199M/1.93G [00:01<00:17, 101MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  11% 220M/1.93G [00:02<00:14, 117MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  13% 241M/1.93G [00:02<00:13, 121MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  14% 262M/1.93G [00:02<00:13, 123MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  15% 283M/1.93G [00:02<00:13, 126MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  16% 304M/1.93G [00:02<00:12, 129MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  17% 325M/1.93G [00:02<00:12, 131MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  18% 346M/1.93G [00:02<00:11, 132MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  19% 367M/1.93G [00:03<00:11, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  20% 388M/1.93G [00:03<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  21% 409M/1.93G [00:03<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  22% 430M/1.93G [00:03<00:11, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  23% 451M/1.93G [00:03<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  24% 472M/1.93G [00:03<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  26% 493M/1.93G [00:04<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  27% 514M/1.93G [00:04<00:10, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  28% 535M/1.93G [00:04<00:10, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  29% 556M/1.93G [00:04<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  30% 577M/1.93G [00:04<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  31% 598M/1.93G [00:04<00:09, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  32% 619M/1.93G [00:05<00:09, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  33% 640M/1.93G [00:05<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  34% 661M/1.93G [00:05<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  35% 682M/1.93G [00:05<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  36% 703M/1.93G [00:05<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  38% 724M/1.93G [00:05<00:08, 137MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  39% 744M/1.93G [00:05<00:08, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  40% 765M/1.93G [00:06<00:08, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  41% 786M/1.93G [00:06<00:08, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  42% 807M/1.93G [00:06<00:08, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  43% 828M/1.93G [00:06<00:08, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  44% 849M/1.93G [00:06<00:08, 129MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  45% 870M/1.93G [00:06<00:08, 131MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  46% 891M/1.93G [00:07<00:07, 132MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  47% 912M/1.93G [00:07<00:07, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  48% 933M/1.93G [00:07<00:07, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  50% 954M/1.93G [00:07<00:07, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  51% 975M/1.93G [00:07<00:07, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  52% 996M/1.93G [00:07<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  53% 1.02G/1.93G [00:07<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  54% 1.04G/1.93G [00:08<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  55% 1.06G/1.93G [00:08<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  56% 1.08G/1.93G [00:08<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  57% 1.10G/1.93G [00:08<00:06, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  58% 1.12G/1.93G [00:08<00:05, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  59% 1.14G/1.93G [00:08<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  60% 1.16G/1.93G [00:09<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  61% 1.18G/1.93G [00:09<00:05, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  63% 1.21G/1.93G [00:09<00:05, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  64% 1.23G/1.93G [00:09<00:05, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  65% 1.25G/1.93G [00:09<00:05, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  66% 1.27G/1.93G [00:09<00:04, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  67% 1.29G/1.93G [00:10<00:04, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  68% 1.31G/1.93G [00:10<00:05, 118MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  69% 1.33G/1.93G [00:10<00:06, 98.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  70% 1.35G/1.93G [00:10<00:07, 72.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  71% 1.36G/1.93G [00:11<00:07, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  71% 1.37G/1.93G [00:11<00:08, 66.7MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  72% 1.38G/1.93G [00:11<00:08, 65.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  72% 1.39G/1.93G [00:11<00:08, 66.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  73% 1.41G/1.93G [00:11<00:08, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  73% 1.42G/1.93G [00:11<00:07, 69.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  75% 1.44G/1.93G [00:12<00:06, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  75% 1.45G/1.93G [00:12<00:06, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  76% 1.46G/1.93G [00:12<00:07, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  77% 1.48G/1.93G [00:12<00:06, 71.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  77% 1.49G/1.93G [00:12<00:05, 73.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  78% 1.50G/1.93G [00:13<00:06, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  78% 1.51G/1.93G [00:13<00:06, 67.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  79% 1.52G/1.93G [00:13<00:05, 68.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  80% 1.54G/1.93G [00:13<00:04, 85.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  81% 1.56G/1.93G [00:13<00:03, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  82% 1.58G/1.93G [00:13<00:03, 109MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  83% 1.60G/1.93G [00:14<00:02, 117MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  84% 1.63G/1.93G [00:14<00:02, 122MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  85% 1.65G/1.93G [00:14<00:02, 126MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  87% 1.67G/1.93G [00:14<00:02, 129MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  88% 1.69G/1.93G [00:14<00:01, 130MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  89% 1.71G/1.93G [00:14<00:01, 132MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  90% 1.73G/1.93G [00:15<00:01, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  91% 1.75G/1.93G [00:15<00:01, 133MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  92% 1.77G/1.93G [00:15<00:01, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  93% 1.79G/1.93G [00:15<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  94% 1.81G/1.93G [00:15<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  95% 1.84G/1.93G [00:15<00:00, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  96% 1.86G/1.93G [00:16<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  97% 1.88G/1.93G [00:16<00:00, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin:  98% 1.90G/1.93G [00:16<00:00, 134MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00007.bin: 100% 1.93G/1.93G [00:16<00:00, 116MB/s]\n",
            "Downloading shards:  86% 6/7 [01:38<00:16, 16.58s/it]\n",
            "pytorch_model-00007-of-00007.bin:   0% 0.00/1.05G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   1% 10.5M/1.05G [00:00<00:33, 30.9MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   2% 21.0M/1.05G [00:00<00:26, 38.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   3% 31.5M/1.05G [00:00<00:22, 45.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   4% 41.9M/1.05G [00:00<00:19, 52.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   5% 52.4M/1.05G [00:01<00:16, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   7% 73.4M/1.05G [00:01<00:12, 77.5MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:   9% 94.4M/1.05G [00:01<00:10, 94.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  11% 115M/1.05G [00:01<00:08, 107MB/s]  \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  13% 136M/1.05G [00:01<00:07, 117MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  15% 157M/1.05G [00:01<00:07, 121MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  17% 178M/1.05G [00:01<00:07, 124MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  19% 199M/1.05G [00:02<00:06, 130MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  21% 220M/1.05G [00:02<00:06, 132MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  23% 241M/1.05G [00:02<00:06, 134MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  25% 262M/1.05G [00:02<00:05, 137MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  27% 283M/1.05G [00:02<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  29% 304M/1.05G [00:02<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  31% 325M/1.05G [00:03<00:05, 136MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  33% 346M/1.05G [00:03<00:05, 137MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  35% 367M/1.05G [00:03<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  37% 388M/1.05G [00:03<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  39% 409M/1.05G [00:03<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  41% 430M/1.05G [00:03<00:04, 138MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  43% 451M/1.05G [00:03<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  45% 472M/1.05G [00:04<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  47% 493M/1.05G [00:04<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  49% 514M/1.05G [00:04<00:03, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  51% 535M/1.05G [00:04<00:03, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  53% 556M/1.05G [00:04<00:03, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  55% 577M/1.05G [00:04<00:03, 138MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  57% 598M/1.05G [00:05<00:03, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  59% 619M/1.05G [00:05<00:03, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  61% 640M/1.05G [00:05<00:02, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  63% 661M/1.05G [00:05<00:02, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  65% 682M/1.05G [00:05<00:02, 139MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  67% 703M/1.05G [00:05<00:02, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  69% 724M/1.05G [00:05<00:02, 141MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  71% 744M/1.05G [00:06<00:02, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  73% 765M/1.05G [00:06<00:02, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  75% 786M/1.05G [00:06<00:01, 141MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  77% 807M/1.05G [00:06<00:01, 140MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  79% 828M/1.05G [00:06<00:01, 133MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  81% 849M/1.05G [00:06<00:01, 137MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  83% 870M/1.05G [00:07<00:01, 97.0MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  86% 902M/1.05G [00:07<00:01, 123MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  88% 923M/1.05G [00:07<00:01, 127MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  90% 944M/1.05G [00:07<00:00, 130MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  92% 965M/1.05G [00:07<00:00, 132MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  94% 986M/1.05G [00:07<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  96% 1.01G/1.05G [00:08<00:00, 136MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin:  98% 1.03G/1.05G [00:08<00:00, 135MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00007.bin: 100% 1.05G/1.05G [00:08<00:00, 125MB/s]\n",
            "Downloading shards: 100% 7/7 [01:47<00:00, 15.39s/it]\n",
            "Loading checkpoint shards: 100% 7/7 [00:06<00:00,  1.08it/s]\n",
            "100% 100/100 [02:53<00:00,  1.74s/it]\n",
            "0.09\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en_fact \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm THUDM/chatglm2-6b \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi8fF095WY-b",
        "outputId": "d1c049af-2cfb-4dd5-959f-0d922f070e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 727/727 [00:00<00:00, 5.43MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.90MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 6.92MB/s]\n",
            "special_tokens_map.json: 100% 435/435 [00:00<00:00, 3.17MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "config.json: 100% 549/549 [00:00<00:00, 4.15MB/s]\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 104MB/s]\n",
            "Downloading shards:   0% 0/34 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00034.bin:   0% 0.00/396M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:   3% 10.5M/396M [00:00<00:25, 15.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:   5% 21.0M/396M [00:00<00:14, 25.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:   8% 31.5M/396M [00:01<00:10, 35.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  11% 41.9M/396M [00:01<00:07, 46.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  13% 52.4M/396M [00:01<00:06, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  16% 62.9M/396M [00:01<00:05, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  19% 73.4M/396M [00:01<00:08, 39.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  21% 83.9M/396M [00:02<00:06, 47.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  24% 94.4M/396M [00:02<00:06, 49.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  26% 105M/396M [00:02<00:05, 50.8MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  29% 115M/396M [00:02<00:05, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  32% 126M/396M [00:02<00:04, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  34% 136M/396M [00:02<00:04, 55.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  37% 147M/396M [00:03<00:04, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  40% 157M/396M [00:03<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  42% 168M/396M [00:03<00:03, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  45% 178M/396M [00:03<00:03, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  48% 189M/396M [00:03<00:03, 59.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  50% 199M/396M [00:03<00:03, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  53% 210M/396M [00:04<00:03, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  56% 220M/396M [00:04<00:02, 65.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  58% 231M/396M [00:04<00:02, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  61% 241M/396M [00:04<00:02, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  63% 252M/396M [00:04<00:02, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  66% 262M/396M [00:04<00:02, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  69% 273M/396M [00:05<00:02, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  71% 283M/396M [00:05<00:01, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  74% 294M/396M [00:05<00:01, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  77% 304M/396M [00:05<00:01, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  79% 315M/396M [00:05<00:01, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  82% 325M/396M [00:06<00:01, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  85% 336M/396M [00:06<00:00, 64.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  87% 346M/396M [00:06<00:00, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  90% 357M/396M [00:06<00:00, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  93% 367M/396M [00:06<00:00, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  95% 377M/396M [00:06<00:00, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin:  98% 388M/396M [00:07<00:00, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00034.bin: 100% 396M/396M [00:07<00:00, 55.0MB/s]\n",
            "Downloading shards:   3% 1/34 [00:07<04:15,  7.75s/it]\n",
            "pytorch_model-00002-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:   3% 10.5M/405M [00:00<00:28, 14.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:   5% 21.0M/405M [00:00<00:16, 23.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 32.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 41.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 64.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  23% 94.4M/405M [00:01<00:04, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  26% 105M/405M [00:02<00:04, 62.3MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  28% 115M/405M [00:02<00:04, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  34% 136M/405M [00:02<00:04, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  36% 147M/405M [00:02<00:04, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  39% 157M/405M [00:03<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  41% 168M/405M [00:03<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  44% 178M/405M [00:03<00:03, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  49% 199M/405M [00:03<00:03, 52.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  52% 210M/405M [00:04<00:03, 52.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  54% 220M/405M [00:04<00:03, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  57% 231M/405M [00:04<00:03, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  60% 241M/405M [00:04<00:02, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  62% 252M/405M [00:04<00:02, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  65% 262M/405M [00:04<00:02, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  67% 273M/405M [00:05<00:02, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  70% 283M/405M [00:05<00:02, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  73% 294M/405M [00:05<00:01, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  75% 304M/405M [00:05<00:01, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  78% 315M/405M [00:05<00:01, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  80% 325M/405M [00:06<00:01, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  83% 336M/405M [00:06<00:01, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  85% 346M/405M [00:06<00:00, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  88% 357M/405M [00:06<00:00, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  91% 367M/405M [00:06<00:00, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  93% 377M/405M [00:06<00:00, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  96% 388M/405M [00:07<00:00, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin:  98% 398M/405M [00:07<00:00, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.6MB/s]\n",
            "Downloading shards:   6% 2/34 [00:15<04:12,  7.90s/it]\n",
            "pytorch_model-00003-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 16.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:   5% 21.0M/405M [00:00<00:13, 27.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:   8% 31.5M/405M [00:00<00:09, 38.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  26% 105M/405M [00:02<00:05, 59.2MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  28% 115M/405M [00:02<00:05, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  34% 136M/405M [00:02<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  36% 147M/405M [00:02<00:04, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  39% 157M/405M [00:03<00:04, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  41% 168M/405M [00:03<00:04, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  44% 178M/405M [00:03<00:03, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  47% 189M/405M [00:03<00:03, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  49% 199M/405M [00:03<00:03, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  52% 210M/405M [00:03<00:03, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  54% 220M/405M [00:04<00:03, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  57% 231M/405M [00:04<00:02, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  60% 241M/405M [00:04<00:02, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  62% 252M/405M [00:04<00:02, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  65% 262M/405M [00:04<00:02, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  67% 273M/405M [00:05<00:02, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  70% 283M/405M [00:05<00:02, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  73% 294M/405M [00:05<00:01, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  75% 304M/405M [00:05<00:01, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  78% 315M/405M [00:05<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  80% 325M/405M [00:05<00:01, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  83% 336M/405M [00:06<00:01, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  85% 346M/405M [00:06<00:01, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  88% 357M/405M [00:06<00:00, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  91% 367M/405M [00:06<00:00, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  93% 377M/405M [00:06<00:00, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin:  96% 388M/405M [00:06<00:00, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.9MB/s]\n",
            "Downloading shards:   9% 3/34 [00:23<04:03,  7.87s/it]\n",
            "pytorch_model-00004-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:   3% 10.5M/405M [00:03<02:29, 2.63MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:   5% 21.0M/405M [00:04<01:18, 4.92MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:   8% 31.5M/405M [00:05<00:49, 7.53MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  10% 41.9M/405M [00:05<00:34, 10.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  13% 52.4M/405M [00:05<00:24, 14.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  16% 62.9M/405M [00:06<00:18, 18.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  18% 73.4M/405M [00:06<00:13, 23.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  21% 83.9M/405M [00:06<00:10, 29.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  23% 94.4M/405M [00:06<00:08, 36.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  26% 105M/405M [00:06<00:07, 40.5MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  28% 115M/405M [00:07<00:06, 44.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  31% 126M/405M [00:07<00:05, 50.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  34% 136M/405M [00:07<00:05, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  36% 147M/405M [00:07<00:04, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  39% 157M/405M [00:07<00:04, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  41% 168M/405M [00:07<00:04, 57.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  44% 178M/405M [00:08<00:03, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  47% 189M/405M [00:08<00:03, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  49% 199M/405M [00:08<00:03, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  52% 210M/405M [00:08<00:03, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  54% 220M/405M [00:08<00:03, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  57% 231M/405M [00:08<00:02, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  60% 241M/405M [00:09<00:02, 62.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  62% 252M/405M [00:09<00:02, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  65% 262M/405M [00:09<00:02, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  67% 273M/405M [00:09<00:02, 57.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  70% 283M/405M [00:09<00:01, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  73% 294M/405M [00:09<00:01, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  75% 304M/405M [00:10<00:01, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  78% 315M/405M [00:10<00:01, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  80% 325M/405M [00:10<00:01, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  83% 336M/405M [00:10<00:01, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  85% 346M/405M [00:10<00:00, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  88% 357M/405M [00:11<00:00, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  91% 367M/405M [00:11<00:00, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  93% 377M/405M [00:11<00:00, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin:  96% 388M/405M [00:11<00:00, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00034.bin: 100% 405M/405M [00:11<00:00, 34.3MB/s]\n",
            "Downloading shards:  12% 4/34 [00:35<04:49,  9.66s/it]\n",
            "pytorch_model-00005-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:   3% 10.5M/405M [00:00<00:26, 15.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 24.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 34.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 45.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  26% 105M/405M [00:02<00:05, 57.2MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  28% 115M/405M [00:02<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  31% 126M/405M [00:02<00:04, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  34% 136M/405M [00:02<00:05, 49.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  36% 147M/405M [00:03<00:04, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  39% 157M/405M [00:03<00:04, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  41% 168M/405M [00:03<00:04, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  44% 178M/405M [00:03<00:04, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  49% 199M/405M [00:03<00:03, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  52% 210M/405M [00:04<00:03, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  54% 220M/405M [00:04<00:03, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  57% 231M/405M [00:04<00:03, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  60% 241M/405M [00:04<00:02, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  62% 252M/405M [00:04<00:02, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  65% 262M/405M [00:05<00:02, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  67% 273M/405M [00:05<00:02, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  70% 283M/405M [00:05<00:02, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  75% 304M/405M [00:05<00:01, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  78% 315M/405M [00:05<00:01, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  80% 325M/405M [00:06<00:01, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  83% 336M/405M [00:06<00:01, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  85% 346M/405M [00:06<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  88% 357M/405M [00:06<00:00, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  91% 367M/405M [00:06<00:00, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  93% 377M/405M [00:06<00:00, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  96% 388M/405M [00:07<00:00, 54.9MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin:  98% 398M/405M [00:07<00:00, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.2MB/s]\n",
            "Downloading shards:  15% 5/34 [00:44<04:23,  9.10s/it]\n",
            "pytorch_model-00006-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 36.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  18% 73.4M/405M [00:01<00:04, 66.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  21% 83.9M/405M [00:01<00:04, 67.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  23% 94.4M/405M [00:01<00:04, 66.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  26% 105M/405M [00:02<00:04, 66.9MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  28% 115M/405M [00:02<00:04, 65.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  31% 126M/405M [00:02<00:04, 62.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  34% 136M/405M [00:02<00:04, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  36% 147M/405M [00:02<00:04, 64.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  39% 157M/405M [00:02<00:03, 65.6MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  41% 168M/405M [00:03<00:03, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  44% 178M/405M [00:03<00:03, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  47% 189M/405M [00:03<00:03, 62.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  49% 199M/405M [00:03<00:03, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  52% 210M/405M [00:03<00:03, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  54% 220M/405M [00:03<00:02, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  57% 231M/405M [00:04<00:02, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  60% 241M/405M [00:04<00:02, 63.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  62% 252M/405M [00:04<00:02, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  65% 262M/405M [00:04<00:02, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  67% 273M/405M [00:04<00:02, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  70% 283M/405M [00:04<00:01, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  73% 294M/405M [00:05<00:01, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  75% 304M/405M [00:05<00:01, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  78% 315M/405M [00:05<00:01, 64.2MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  80% 325M/405M [00:05<00:01, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  83% 336M/405M [00:05<00:01, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  85% 346M/405M [00:05<00:00, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  88% 357M/405M [00:06<00:00, 63.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  91% 367M/405M [00:06<00:00, 65.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  93% 377M/405M [00:06<00:00, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin:  96% 388M/405M [00:06<00:00, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00034.bin: 100% 405M/405M [00:06<00:00, 59.4MB/s]\n",
            "Downloading shards:  18% 6/34 [00:51<03:58,  8.53s/it]\n",
            "pytorch_model-00007-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 16.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:   5% 21.0M/405M [00:00<00:13, 27.5MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:   8% 31.5M/405M [00:00<00:09, 38.1MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 44.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  13% 52.4M/405M [00:01<00:07, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 49.1MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 50.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 54.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  26% 105M/405M [00:02<00:05, 54.9MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  28% 115M/405M [00:02<00:04, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  31% 126M/405M [00:02<00:04, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  34% 136M/405M [00:02<00:05, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  36% 147M/405M [00:03<00:05, 51.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  39% 157M/405M [00:03<00:05, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  41% 168M/405M [00:03<00:04, 49.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  44% 178M/405M [00:03<00:04, 48.0MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  47% 189M/405M [00:03<00:04, 48.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  49% 199M/405M [00:04<00:04, 50.1MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  52% 210M/405M [00:04<00:03, 51.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  54% 220M/405M [00:04<00:03, 51.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  57% 231M/405M [00:04<00:03, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  60% 241M/405M [00:04<00:03, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  62% 252M/405M [00:05<00:03, 50.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  65% 262M/405M [00:05<00:02, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  67% 273M/405M [00:05<00:02, 51.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  70% 283M/405M [00:05<00:02, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  73% 294M/405M [00:06<00:02, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  75% 304M/405M [00:06<00:01, 52.4MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  78% 315M/405M [00:06<00:01, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  80% 325M/405M [00:06<00:01, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  83% 336M/405M [00:06<00:01, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  85% 346M/405M [00:07<00:01, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  88% 357M/405M [00:07<00:00, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  91% 367M/405M [00:07<00:00, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  93% 377M/405M [00:07<00:00, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  96% 388M/405M [00:07<00:00, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin:  98% 398M/405M [00:07<00:00, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00034.bin: 100% 405M/405M [00:08<00:00, 50.0MB/s]\n",
            "Downloading shards:  21% 7/34 [01:00<03:52,  8.60s/it]\n",
            "pytorch_model-00008-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:   3% 10.5M/405M [00:00<00:28, 13.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:   5% 21.0M/405M [00:00<00:16, 23.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 32.3MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 42.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 53.7MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 63.5MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  26% 105M/405M [00:02<00:04, 62.8MB/s] \u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  28% 115M/405M [00:02<00:04, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  31% 126M/405M [00:02<00:04, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  34% 136M/405M [00:02<00:04, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  36% 147M/405M [00:02<00:04, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  39% 157M/405M [00:03<00:04, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  41% 168M/405M [00:03<00:04, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  44% 178M/405M [00:03<00:03, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  49% 199M/405M [00:03<00:03, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  52% 210M/405M [00:03<00:03, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  54% 220M/405M [00:04<00:03, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  57% 231M/405M [00:04<00:02, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  62% 252M/405M [00:04<00:02, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  65% 262M/405M [00:04<00:02, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  67% 273M/405M [00:05<00:02, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  70% 283M/405M [00:05<00:01, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  75% 304M/405M [00:05<00:01, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  78% 315M/405M [00:05<00:01, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  80% 325M/405M [00:06<00:01, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  85% 346M/405M [00:06<00:00, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  88% 357M/405M [00:06<00:00, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  91% 367M/405M [00:06<00:00, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  93% 377M/405M [00:06<00:00, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  96% 388M/405M [00:06<00:00, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin:  98% 398M/405M [00:07<00:00, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.5MB/s]\n",
            "Downloading shards:  24% 8/34 [01:08<03:37,  8.36s/it]\n",
            "pytorch_model-00009-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:   3% 10.5M/405M [00:03<02:05, 3.14MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:   5% 21.0M/405M [00:04<01:08, 5.60MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:   8% 31.5M/405M [00:04<00:44, 8.48MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  10% 41.9M/405M [00:05<00:30, 11.8MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  13% 52.4M/405M [00:05<00:22, 15.9MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  16% 62.9M/405M [00:05<00:16, 20.2MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  18% 73.4M/405M [00:05<00:12, 25.6MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  21% 83.9M/405M [00:05<00:10, 31.0MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  23% 94.4M/405M [00:06<00:08, 36.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  26% 105M/405M [00:06<00:07, 41.1MB/s] \u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  28% 115M/405M [00:06<00:06, 45.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  31% 126M/405M [00:06<00:05, 49.2MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  34% 136M/405M [00:06<00:04, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  36% 147M/405M [00:06<00:04, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  39% 157M/405M [00:07<00:04, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  41% 168M/405M [00:07<00:03, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  44% 178M/405M [00:07<00:03, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  47% 189M/405M [00:07<00:03, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  49% 199M/405M [00:07<00:03, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  52% 210M/405M [00:07<00:03, 64.0MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  54% 220M/405M [00:08<00:02, 64.0MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  57% 231M/405M [00:08<00:02, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  60% 241M/405M [00:08<00:02, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  62% 252M/405M [00:08<00:02, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  65% 262M/405M [00:08<00:02, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  67% 273M/405M [00:08<00:02, 64.9MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  70% 283M/405M [00:09<00:01, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  73% 294M/405M [00:09<00:01, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  75% 304M/405M [00:09<00:01, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  78% 315M/405M [00:09<00:01, 65.4MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  80% 325M/405M [00:09<00:01, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  83% 336M/405M [00:09<00:01, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  85% 346M/405M [00:10<00:00, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  88% 357M/405M [00:10<00:00, 62.5MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  91% 367M/405M [00:10<00:00, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  93% 377M/405M [00:10<00:00, 64.8MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  96% 388M/405M [00:10<00:00, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin:  98% 398M/405M [00:10<00:00, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00009-of-00034.bin: 100% 405M/405M [00:11<00:00, 36.6MB/s]\n",
            "Downloading shards:  26% 9/34 [01:19<03:54,  9.38s/it]\n",
            "pytorch_model-00010-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:   3% 10.5M/405M [00:00<00:29, 13.4MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:   5% 21.0M/405M [00:01<00:19, 19.4MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:   8% 31.5M/405M [00:01<00:14, 25.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  10% 41.9M/405M [00:01<00:11, 30.7MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  13% 52.4M/405M [00:01<00:09, 35.4MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  16% 62.9M/405M [00:02<00:08, 42.1MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  18% 73.4M/405M [00:02<00:07, 47.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  21% 83.9M/405M [00:02<00:06, 49.5MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  26% 105M/405M [00:02<00:05, 55.2MB/s] \u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  28% 115M/405M [00:02<00:05, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  31% 126M/405M [00:03<00:04, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  34% 136M/405M [00:03<00:04, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  36% 147M/405M [00:03<00:04, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  39% 157M/405M [00:03<00:04, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  41% 168M/405M [00:03<00:04, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  44% 178M/405M [00:04<00:04, 49.8MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  47% 189M/405M [00:04<00:04, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  49% 199M/405M [00:04<00:04, 48.6MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  52% 210M/405M [00:04<00:03, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  54% 220M/405M [00:04<00:03, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  57% 231M/405M [00:05<00:03, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  60% 241M/405M [00:05<00:03, 50.9MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  62% 252M/405M [00:05<00:02, 52.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  65% 262M/405M [00:05<00:02, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  67% 273M/405M [00:05<00:02, 54.1MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  70% 283M/405M [00:06<00:02, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  73% 294M/405M [00:06<00:02, 54.6MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  75% 304M/405M [00:06<00:01, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  78% 315M/405M [00:06<00:01, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  80% 325M/405M [00:06<00:01, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  83% 336M/405M [00:06<00:01, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  85% 346M/405M [00:07<00:01, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  88% 357M/405M [00:07<00:00, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  91% 367M/405M [00:07<00:00, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  93% 377M/405M [00:07<00:00, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  96% 388M/405M [00:07<00:00, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin:  98% 398M/405M [00:08<00:00, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00010-of-00034.bin: 100% 405M/405M [00:08<00:00, 49.8MB/s]\n",
            "Downloading shards:  29% 10/34 [01:28<03:40,  9.20s/it]\n",
            "pytorch_model-00011-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:   3% 10.5M/405M [00:00<00:23, 16.8MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:   5% 21.0M/405M [00:00<00:12, 29.6MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:   8% 31.5M/405M [00:00<00:08, 41.6MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  10% 41.9M/405M [00:01<00:06, 52.0MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  21% 83.9M/405M [00:01<00:06, 51.7MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  26% 105M/405M [00:02<00:05, 58.6MB/s] \u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  28% 115M/405M [00:02<00:04, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  31% 126M/405M [00:02<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  34% 136M/405M [00:02<00:04, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  36% 147M/405M [00:02<00:04, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  39% 157M/405M [00:02<00:04, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  41% 168M/405M [00:03<00:04, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  44% 178M/405M [00:03<00:03, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  49% 199M/405M [00:03<00:03, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  52% 210M/405M [00:03<00:03, 57.7MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  54% 220M/405M [00:04<00:03, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  57% 231M/405M [00:04<00:03, 54.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  60% 241M/405M [00:04<00:03, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  62% 252M/405M [00:04<00:02, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  65% 262M/405M [00:04<00:02, 51.7MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  67% 273M/405M [00:05<00:02, 52.5MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  70% 283M/405M [00:05<00:02, 48.8MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  73% 294M/405M [00:05<00:02, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  75% 304M/405M [00:05<00:01, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  78% 315M/405M [00:05<00:01, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  80% 325M/405M [00:06<00:01, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  83% 336M/405M [00:06<00:01, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  85% 346M/405M [00:06<00:01, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  88% 357M/405M [00:06<00:00, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  91% 367M/405M [00:06<00:00, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  93% 377M/405M [00:07<00:00, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  96% 388M/405M [00:07<00:00, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin:  98% 398M/405M [00:07<00:00, 54.6MB/s]\u001b[A\n",
            "pytorch_model-00011-of-00034.bin: 100% 405M/405M [00:07<00:00, 52.7MB/s]\n",
            "Downloading shards:  32% 11/34 [01:36<03:24,  8.90s/it]\n",
            "pytorch_model-00012-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:   3% 10.5M/405M [00:00<00:26, 14.6MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 24.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 33.8MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 43.8MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 66.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 62.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  26% 105M/405M [00:02<00:05, 59.0MB/s] \u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  28% 115M/405M [00:02<00:04, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  31% 126M/405M [00:02<00:04, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  34% 136M/405M [00:02<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  36% 147M/405M [00:02<00:04, 63.5MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  39% 157M/405M [00:03<00:04, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  41% 168M/405M [00:03<00:03, 64.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  44% 178M/405M [00:03<00:03, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  47% 189M/405M [00:03<00:03, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  49% 199M/405M [00:03<00:03, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  52% 210M/405M [00:03<00:03, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  54% 220M/405M [00:04<00:03, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  57% 231M/405M [00:04<00:03, 53.7MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  60% 241M/405M [00:04<00:03, 47.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  62% 252M/405M [00:04<00:02, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  65% 262M/405M [00:04<00:02, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  67% 273M/405M [00:05<00:02, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  70% 283M/405M [00:05<00:02, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  73% 294M/405M [00:05<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  75% 304M/405M [00:05<00:01, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  78% 315M/405M [00:05<00:01, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  80% 325M/405M [00:05<00:01, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  83% 336M/405M [00:06<00:01, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  85% 346M/405M [00:06<00:00, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  88% 357M/405M [00:06<00:00, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  91% 367M/405M [00:06<00:00, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  93% 377M/405M [00:06<00:00, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin:  96% 388M/405M [00:06<00:00, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00012-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.5MB/s]\n",
            "Downloading shards:  35% 12/34 [01:44<03:09,  8.63s/it]\n",
            "pytorch_model-00013-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 16.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 26.9MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:   8% 31.5M/405M [00:00<00:09, 38.4MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  18% 73.4M/405M [00:01<00:07, 46.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  21% 83.9M/405M [00:01<00:06, 49.5MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  26% 105M/405M [00:02<00:05, 55.8MB/s] \u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  28% 115M/405M [00:02<00:05, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  31% 126M/405M [00:02<00:04, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  34% 136M/405M [00:02<00:04, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  36% 147M/405M [00:02<00:03, 64.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  39% 157M/405M [00:03<00:03, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  41% 168M/405M [00:03<00:04, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  44% 178M/405M [00:03<00:04, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  47% 189M/405M [00:03<00:03, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  49% 199M/405M [00:03<00:03, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  52% 210M/405M [00:04<00:03, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  54% 220M/405M [00:04<00:03, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  57% 231M/405M [00:04<00:02, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  60% 241M/405M [00:04<00:02, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  62% 252M/405M [00:04<00:02, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  65% 262M/405M [00:04<00:02, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  67% 273M/405M [00:05<00:02, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  70% 283M/405M [00:05<00:02, 53.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  73% 294M/405M [00:05<00:02, 50.1MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  75% 304M/405M [00:05<00:01, 51.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  78% 315M/405M [00:06<00:01, 49.3MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  80% 325M/405M [00:06<00:01, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  83% 336M/405M [00:06<00:01, 49.2MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  85% 346M/405M [00:06<00:01, 50.3MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  88% 357M/405M [00:06<00:00, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  91% 367M/405M [00:07<00:00, 49.8MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  93% 377M/405M [00:07<00:00, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  96% 388M/405M [00:07<00:00, 49.4MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin:  98% 398M/405M [00:07<00:00, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00013-of-00034.bin: 100% 405M/405M [00:07<00:00, 51.9MB/s]\n",
            "Downloading shards:  38% 13/34 [01:53<02:59,  8.56s/it]\n",
            "pytorch_model-00014-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 15.8MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 25.6MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.1MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 41.2MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  13% 52.4M/405M [00:01<00:09, 38.5MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  16% 62.9M/405M [00:01<00:08, 40.2MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  18% 73.4M/405M [00:01<00:07, 44.1MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  21% 83.9M/405M [00:02<00:07, 43.6MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  23% 94.4M/405M [00:02<00:07, 43.9MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  26% 105M/405M [00:02<00:06, 46.4MB/s] \u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  28% 115M/405M [00:02<00:06, 46.1MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  31% 126M/405M [00:03<00:05, 47.9MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  34% 136M/405M [00:03<00:05, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  36% 147M/405M [00:03<00:05, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  39% 157M/405M [00:03<00:05, 49.5MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  41% 168M/405M [00:03<00:04, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  44% 178M/405M [00:04<00:04, 52.0MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  47% 189M/405M [00:04<00:04, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  49% 199M/405M [00:04<00:04, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  52% 210M/405M [00:04<00:03, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  54% 220M/405M [00:04<00:03, 53.1MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  57% 231M/405M [00:05<00:03, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  60% 241M/405M [00:05<00:03, 53.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  62% 252M/405M [00:05<00:02, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  65% 262M/405M [00:05<00:02, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  67% 273M/405M [00:05<00:02, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  70% 283M/405M [00:06<00:02, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  73% 294M/405M [00:06<00:02, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  75% 304M/405M [00:06<00:01, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  78% 315M/405M [00:06<00:01, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  80% 325M/405M [00:06<00:01, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  83% 336M/405M [00:06<00:01, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  85% 346M/405M [00:07<00:01, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  88% 357M/405M [00:07<00:00, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  91% 367M/405M [00:07<00:00, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  93% 377M/405M [00:07<00:00, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin:  96% 388M/405M [00:07<00:00, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00014-of-00034.bin: 100% 405M/405M [00:08<00:00, 49.3MB/s]\n",
            "Downloading shards:  41% 14/34 [02:02<02:52,  8.65s/it]\n",
            "pytorch_model-00015-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:   3% 10.5M/405M [00:00<00:23, 17.1MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:   5% 21.0M/405M [00:00<00:13, 29.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:   8% 31.5M/405M [00:00<00:09, 41.0MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 47.4MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  26% 105M/405M [00:02<00:05, 58.2MB/s] \u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  28% 115M/405M [00:02<00:05, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  34% 136M/405M [00:02<00:04, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  36% 147M/405M [00:02<00:04, 63.5MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  39% 157M/405M [00:03<00:04, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  41% 168M/405M [00:03<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  44% 178M/405M [00:03<00:03, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  47% 189M/405M [00:03<00:03, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  49% 199M/405M [00:03<00:03, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  52% 210M/405M [00:03<00:03, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  54% 220M/405M [00:04<00:03, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  57% 231M/405M [00:04<00:02, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  60% 241M/405M [00:04<00:02, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  62% 252M/405M [00:04<00:02, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  65% 262M/405M [00:04<00:03, 46.6MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  67% 273M/405M [00:05<00:02, 47.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  70% 283M/405M [00:05<00:02, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  73% 294M/405M [00:05<00:02, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  75% 304M/405M [00:05<00:01, 51.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  78% 315M/405M [00:05<00:01, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  80% 325M/405M [00:06<00:01, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  83% 336M/405M [00:06<00:01, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  85% 346M/405M [00:06<00:00, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  88% 357M/405M [00:06<00:00, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  91% 367M/405M [00:06<00:00, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  93% 377M/405M [00:06<00:00, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin:  96% 388M/405M [00:07<00:00, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00015-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.9MB/s]\n",
            "Downloading shards:  44% 15/34 [02:10<02:40,  8.45s/it]\n",
            "pytorch_model-00016-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:   3% 10.5M/405M [00:00<00:27, 14.2MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:   5% 21.0M/405M [00:00<00:16, 23.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 43.3MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  26% 105M/405M [00:02<00:05, 51.5MB/s] \u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  28% 115M/405M [00:02<00:05, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  31% 126M/405M [00:02<00:05, 55.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  34% 136M/405M [00:02<00:04, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  36% 147M/405M [00:03<00:04, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  39% 157M/405M [00:03<00:04, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  41% 168M/405M [00:03<00:04, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  44% 178M/405M [00:03<00:03, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  47% 189M/405M [00:03<00:03, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  49% 199M/405M [00:03<00:03, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  52% 210M/405M [00:04<00:03, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  54% 220M/405M [00:04<00:03, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  60% 241M/405M [00:04<00:02, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  62% 252M/405M [00:04<00:02, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  65% 262M/405M [00:04<00:02, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  67% 273M/405M [00:05<00:02, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  70% 283M/405M [00:05<00:02, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  73% 294M/405M [00:05<00:02, 49.8MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  75% 304M/405M [00:05<00:01, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  78% 315M/405M [00:06<00:01, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  80% 325M/405M [00:06<00:01, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  83% 336M/405M [00:06<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  85% 346M/405M [00:06<00:01, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  88% 357M/405M [00:06<00:00, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  91% 367M/405M [00:06<00:00, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  93% 377M/405M [00:07<00:00, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  96% 388M/405M [00:07<00:00, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin:  98% 398M/405M [00:07<00:00, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00016-of-00034.bin: 100% 405M/405M [00:07<00:00, 53.2MB/s]\n",
            "Downloading shards:  47% 16/34 [02:18<02:30,  8.37s/it]\n",
            "pytorch_model-00017-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 16.3MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:   5% 21.0M/405M [00:00<00:13, 27.6MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:   8% 31.5M/405M [00:00<00:09, 38.6MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 49.7MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  26% 105M/405M [00:02<00:05, 54.9MB/s] \u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  28% 115M/405M [00:02<00:05, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  31% 126M/405M [00:02<00:04, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  34% 136M/405M [00:02<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  36% 147M/405M [00:02<00:04, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  39% 157M/405M [00:03<00:04, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  41% 168M/405M [00:03<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  44% 178M/405M [00:03<00:03, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  49% 199M/405M [00:03<00:03, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  52% 210M/405M [00:03<00:03, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  54% 220M/405M [00:04<00:03, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  57% 231M/405M [00:04<00:03, 54.1MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  60% 241M/405M [00:04<00:03, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  62% 252M/405M [00:04<00:02, 54.9MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  65% 262M/405M [00:04<00:02, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  67% 273M/405M [00:05<00:02, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  70% 283M/405M [00:05<00:02, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  73% 294M/405M [00:05<00:01, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  75% 304M/405M [00:05<00:01, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  78% 315M/405M [00:05<00:01, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  80% 325M/405M [00:05<00:01, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  83% 336M/405M [00:06<00:01, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  85% 346M/405M [00:06<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  88% 357M/405M [00:06<00:00, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  91% 367M/405M [00:06<00:00, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  93% 377M/405M [00:06<00:00, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  96% 388M/405M [00:06<00:00, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin:  98% 398M/405M [00:07<00:00, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00017-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.7MB/s]\n",
            "Downloading shards:  50% 17/34 [02:26<02:19,  8.22s/it]\n",
            "pytorch_model-00018-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:   3% 10.5M/405M [00:00<00:31, 12.6MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:   5% 21.0M/405M [00:01<00:18, 20.4MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:   8% 31.5M/405M [00:01<00:12, 29.2MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  10% 41.9M/405M [00:01<00:09, 38.5MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  13% 52.4M/405M [00:01<00:07, 45.1MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  18% 73.4M/405M [00:01<00:04, 66.3MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  23% 94.4M/405M [00:01<00:04, 77.5MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  26% 105M/405M [00:02<00:04, 74.7MB/s] \u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  28% 115M/405M [00:02<00:04, 70.9MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  31% 126M/405M [00:02<00:03, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  34% 136M/405M [00:02<00:04, 65.3MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  36% 147M/405M [00:02<00:04, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  39% 157M/405M [00:02<00:03, 65.4MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  41% 168M/405M [00:03<00:03, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  44% 178M/405M [00:03<00:03, 65.1MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  47% 189M/405M [00:03<00:03, 63.0MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  49% 199M/405M [00:03<00:03, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  52% 210M/405M [00:03<00:03, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  54% 220M/405M [00:03<00:02, 62.5MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  57% 231M/405M [00:04<00:02, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  60% 241M/405M [00:04<00:02, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  62% 252M/405M [00:04<00:02, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  65% 262M/405M [00:04<00:02, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  67% 273M/405M [00:04<00:02, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  70% 283M/405M [00:05<00:02, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  73% 294M/405M [00:05<00:02, 46.2MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  75% 304M/405M [00:05<00:02, 45.1MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  78% 315M/405M [00:05<00:02, 43.7MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  80% 325M/405M [00:06<00:01, 40.6MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  83% 336M/405M [00:06<00:01, 37.9MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  85% 346M/405M [00:06<00:01, 34.4MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  88% 357M/405M [00:07<00:01, 32.2MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  91% 367M/405M [00:07<00:01, 30.9MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  93% 377M/405M [00:08<00:00, 30.2MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  96% 388M/405M [00:08<00:00, 31.0MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin:  98% 398M/405M [00:08<00:00, 30.2MB/s]\u001b[A\n",
            "pytorch_model-00018-of-00034.bin: 100% 405M/405M [00:08<00:00, 45.4MB/s]\n",
            "Downloading shards:  53% 18/34 [02:35<02:17,  8.60s/it]\n",
            "pytorch_model-00019-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.7MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 26.1MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 37.2MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 46.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 52.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 54.1MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  26% 105M/405M [00:02<00:05, 56.5MB/s] \u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  28% 115M/405M [00:02<00:05, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  34% 136M/405M [00:02<00:04, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  36% 147M/405M [00:02<00:04, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  39% 157M/405M [00:03<00:04, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  41% 168M/405M [00:03<00:04, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  44% 178M/405M [00:03<00:04, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  47% 189M/405M [00:03<00:03, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  49% 199M/405M [00:03<00:03, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  52% 210M/405M [00:04<00:03, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  54% 220M/405M [00:04<00:03, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  57% 231M/405M [00:04<00:02, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  60% 241M/405M [00:04<00:02, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  62% 252M/405M [00:04<00:02, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  65% 262M/405M [00:04<00:02, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  67% 273M/405M [00:05<00:02, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  70% 283M/405M [00:05<00:01, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  75% 304M/405M [00:05<00:01, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  78% 315M/405M [00:05<00:01, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  80% 325M/405M [00:05<00:01, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  83% 336M/405M [00:06<00:01, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  85% 346M/405M [00:06<00:00, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  88% 357M/405M [00:06<00:00, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  91% 367M/405M [00:06<00:00, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  93% 377M/405M [00:06<00:00, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  96% 388M/405M [00:07<00:00, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin:  98% 398M/405M [00:07<00:00, 51.7MB/s]\u001b[A\n",
            "pytorch_model-00019-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.5MB/s]\n",
            "Downloading shards:  56% 19/34 [02:43<02:06,  8.42s/it]\n",
            "pytorch_model-00020-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 26.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 36.9MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 47.1MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  13% 52.4M/405M [00:01<00:07, 50.2MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 50.2MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  26% 105M/405M [00:02<00:05, 53.3MB/s] \u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  28% 115M/405M [00:02<00:05, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  31% 126M/405M [00:02<00:04, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  34% 136M/405M [00:02<00:04, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  36% 147M/405M [00:03<00:04, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  39% 157M/405M [00:03<00:04, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  41% 168M/405M [00:03<00:03, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  44% 178M/405M [00:03<00:04, 52.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  47% 189M/405M [00:03<00:04, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  49% 199M/405M [00:03<00:03, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  52% 210M/405M [00:04<00:03, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  54% 220M/405M [00:04<00:03, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  62% 252M/405M [00:04<00:02, 62.9MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  65% 262M/405M [00:05<00:02, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  67% 273M/405M [00:05<00:02, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  70% 283M/405M [00:05<00:01, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  75% 304M/405M [00:05<00:01, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  78% 315M/405M [00:05<00:01, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  80% 325M/405M [00:06<00:01, 63.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  83% 336M/405M [00:06<00:01, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  85% 346M/405M [00:06<00:01, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  88% 357M/405M [00:06<00:00, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  91% 367M/405M [00:06<00:00, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  93% 377M/405M [00:06<00:00, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin:  96% 388M/405M [00:07<00:00, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00020-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.0MB/s]\n",
            "Downloading shards:  59% 20/34 [02:51<01:55,  8.27s/it]\n",
            "pytorch_model-00021-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.6MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.4MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 34.9MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 45.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 59.4MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  26% 105M/405M [00:02<00:04, 64.3MB/s] \u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  28% 115M/405M [00:02<00:04, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  34% 136M/405M [00:02<00:04, 65.5MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  36% 147M/405M [00:02<00:04, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  39% 157M/405M [00:02<00:04, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  41% 168M/405M [00:03<00:03, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  44% 178M/405M [00:03<00:03, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  47% 189M/405M [00:03<00:03, 65.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  49% 199M/405M [00:03<00:03, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  52% 210M/405M [00:03<00:03, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  54% 220M/405M [00:03<00:02, 64.9MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  60% 241M/405M [00:04<00:02, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  62% 252M/405M [00:04<00:02, 64.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  65% 262M/405M [00:04<00:02, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  67% 273M/405M [00:04<00:01, 66.1MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  70% 283M/405M [00:04<00:01, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  73% 294M/405M [00:05<00:01, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  75% 304M/405M [00:05<00:01, 63.5MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  78% 315M/405M [00:05<00:01, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  80% 325M/405M [00:05<00:01, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  83% 336M/405M [00:05<00:01, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  85% 346M/405M [00:05<00:00, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  88% 357M/405M [00:06<00:00, 59.4MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  91% 367M/405M [00:06<00:00, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  93% 377M/405M [00:06<00:00, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin:  96% 388M/405M [00:06<00:00, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00021-of-00034.bin: 100% 405M/405M [00:06<00:00, 57.8MB/s]\n",
            "Downloading shards:  62% 21/34 [02:58<01:44,  8.05s/it]\n",
            "pytorch_model-00022-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:   3% 10.5M/405M [00:00<00:27, 14.5MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 24.1MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 42.9MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  26% 105M/405M [00:02<00:05, 58.8MB/s] \u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  28% 115M/405M [00:02<00:04, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  31% 126M/405M [00:02<00:04, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  34% 136M/405M [00:02<00:04, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  36% 147M/405M [00:02<00:04, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  39% 157M/405M [00:03<00:04, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  41% 168M/405M [00:03<00:04, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  44% 178M/405M [00:03<00:03, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  49% 199M/405M [00:03<00:03, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  52% 210M/405M [00:03<00:03, 59.4MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  54% 220M/405M [00:04<00:03, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  62% 252M/405M [00:04<00:02, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  65% 262M/405M [00:04<00:02, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  67% 273M/405M [00:05<00:02, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  70% 283M/405M [00:05<00:02, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  75% 304M/405M [00:05<00:01, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  78% 315M/405M [00:05<00:01, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  80% 325M/405M [00:05<00:01, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  83% 336M/405M [00:06<00:01, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  85% 346M/405M [00:06<00:01, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  88% 357M/405M [00:06<00:00, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  91% 367M/405M [00:06<00:00, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  93% 377M/405M [00:06<00:00, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  96% 388M/405M [00:07<00:00, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin:  98% 398M/405M [00:07<00:00, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00022-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.4MB/s]\n",
            "Downloading shards:  65% 22/34 [03:06<01:35,  8.00s/it]\n",
            "pytorch_model-00023-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.1MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.8MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 51.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  21% 83.9M/405M [00:01<00:06, 52.0MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  26% 105M/405M [00:02<00:05, 52.5MB/s] \u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  28% 115M/405M [00:02<00:05, 51.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  31% 126M/405M [00:02<00:05, 51.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  34% 136M/405M [00:02<00:05, 52.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  36% 147M/405M [00:03<00:04, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  39% 157M/405M [00:03<00:04, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  41% 168M/405M [00:03<00:04, 51.9MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  44% 178M/405M [00:03<00:04, 48.0MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  47% 189M/405M [00:03<00:04, 49.6MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  49% 199M/405M [00:04<00:03, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  52% 210M/405M [00:04<00:04, 48.7MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  54% 220M/405M [00:04<00:03, 46.8MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  57% 231M/405M [00:04<00:03, 48.5MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  60% 241M/405M [00:05<00:03, 46.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  62% 252M/405M [00:05<00:03, 41.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  65% 262M/405M [00:05<00:03, 40.7MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  67% 273M/405M [00:06<00:03, 35.5MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  70% 283M/405M [00:06<00:03, 30.9MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  73% 294M/405M [00:06<00:03, 29.5MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  75% 304M/405M [00:07<00:03, 28.7MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  78% 315M/405M [00:07<00:03, 28.3MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  80% 325M/405M [00:08<00:02, 28.0MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  83% 336M/405M [00:08<00:02, 27.8MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  85% 346M/405M [00:08<00:02, 27.7MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  88% 357M/405M [00:09<00:01, 28.9MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  91% 367M/405M [00:09<00:01, 28.4MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  93% 377M/405M [00:09<00:00, 28.1MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  96% 388M/405M [00:10<00:00, 29.2MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin:  98% 398M/405M [00:10<00:00, 28.6MB/s]\u001b[A\n",
            "pytorch_model-00023-of-00034.bin: 100% 405M/405M [00:10<00:00, 37.5MB/s]\n",
            "Downloading shards:  68% 23/34 [03:18<01:38,  9.00s/it]\n",
            "pytorch_model-00024-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:   3% 10.5M/405M [00:00<00:27, 14.2MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:   5% 21.0M/405M [00:00<00:16, 23.5MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 32.8MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 41.7MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 66.2MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  26% 105M/405M [00:02<00:04, 60.2MB/s] \u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  28% 115M/405M [00:02<00:04, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  31% 126M/405M [00:02<00:04, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  34% 136M/405M [00:02<00:04, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  36% 147M/405M [00:02<00:04, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  39% 157M/405M [00:03<00:03, 62.5MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  41% 168M/405M [00:03<00:03, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  44% 178M/405M [00:03<00:03, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  47% 189M/405M [00:03<00:03, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  49% 199M/405M [00:03<00:03, 52.3MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  52% 210M/405M [00:04<00:03, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  54% 220M/405M [00:04<00:03, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  57% 231M/405M [00:04<00:02, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  62% 252M/405M [00:04<00:02, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  65% 262M/405M [00:04<00:02, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  67% 273M/405M [00:05<00:02, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  70% 283M/405M [00:05<00:02, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  73% 294M/405M [00:05<00:01, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  75% 304M/405M [00:05<00:01, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  78% 315M/405M [00:05<00:01, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  80% 325M/405M [00:05<00:01, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  83% 336M/405M [00:06<00:01, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  85% 346M/405M [00:06<00:00, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  88% 357M/405M [00:06<00:00, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  91% 367M/405M [00:06<00:00, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  93% 377M/405M [00:06<00:00, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  96% 388M/405M [00:07<00:00, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin:  98% 398M/405M [00:07<00:00, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00024-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.2MB/s]\n",
            "Downloading shards:  71% 24/34 [03:26<01:26,  8.68s/it]\n",
            "pytorch_model-00025-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:   3% 10.5M/405M [00:03<02:23, 2.76MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:   5% 21.0M/405M [00:04<01:14, 5.16MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:   8% 31.5M/405M [00:05<00:47, 7.79MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  10% 41.9M/405M [00:05<00:32, 11.2MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  13% 52.4M/405M [00:05<00:23, 14.8MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  16% 62.9M/405M [00:05<00:17, 19.1MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  18% 73.4M/405M [00:06<00:13, 24.3MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  21% 83.9M/405M [00:06<00:10, 29.6MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  23% 94.4M/405M [00:06<00:08, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  26% 105M/405M [00:06<00:07, 41.3MB/s] \u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  28% 115M/405M [00:06<00:05, 48.2MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  31% 126M/405M [00:06<00:05, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  34% 136M/405M [00:07<00:05, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  36% 147M/405M [00:07<00:04, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  39% 157M/405M [00:07<00:04, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  41% 168M/405M [00:07<00:03, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  44% 178M/405M [00:07<00:03, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  47% 189M/405M [00:08<00:03, 59.3MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  49% 199M/405M [00:08<00:03, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  52% 210M/405M [00:08<00:03, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  54% 220M/405M [00:08<00:03, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  60% 241M/405M [00:08<00:02, 64.9MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  62% 252M/405M [00:09<00:02, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  65% 262M/405M [00:09<00:02, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  67% 273M/405M [00:09<00:02, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  70% 283M/405M [00:09<00:02, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  73% 294M/405M [00:09<00:02, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  75% 304M/405M [00:10<00:01, 51.4MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  78% 315M/405M [00:10<00:01, 52.3MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  80% 325M/405M [00:10<00:01, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  83% 336M/405M [00:10<00:01, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  85% 346M/405M [00:10<00:01, 51.9MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  88% 357M/405M [00:11<00:00, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  91% 367M/405M [00:11<00:00, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  93% 377M/405M [00:11<00:00, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin:  96% 388M/405M [00:11<00:00, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00025-of-00034.bin: 100% 405M/405M [00:11<00:00, 34.1MB/s]\n",
            "Downloading shards:  74% 25/34 [03:38<01:28,  9.82s/it]\n",
            "pytorch_model-00026-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:   3% 10.5M/405M [00:00<00:26, 15.2MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 25.7MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 46.3MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 53.1MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  26% 105M/405M [00:02<00:05, 58.0MB/s] \u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  28% 115M/405M [00:02<00:05, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  31% 126M/405M [00:02<00:04, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  34% 136M/405M [00:02<00:04, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  36% 147M/405M [00:02<00:04, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  39% 157M/405M [00:03<00:04, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  41% 168M/405M [00:03<00:04, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  44% 178M/405M [00:03<00:03, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  47% 189M/405M [00:03<00:03, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  49% 199M/405M [00:03<00:03, 53.1MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  52% 210M/405M [00:04<00:03, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  54% 220M/405M [00:04<00:03, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  57% 231M/405M [00:04<00:03, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  60% 241M/405M [00:04<00:02, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  62% 252M/405M [00:04<00:02, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  65% 262M/405M [00:05<00:02, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  67% 273M/405M [00:05<00:02, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  70% 283M/405M [00:05<00:02, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  73% 294M/405M [00:05<00:01, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  75% 304M/405M [00:05<00:01, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  78% 315M/405M [00:05<00:01, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  80% 325M/405M [00:06<00:01, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  83% 336M/405M [00:06<00:01, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  85% 346M/405M [00:06<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  88% 357M/405M [00:06<00:00, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  91% 367M/405M [00:06<00:00, 55.7MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  93% 377M/405M [00:07<00:00, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  96% 388M/405M [00:07<00:00, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin:  98% 398M/405M [00:07<00:00, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00026-of-00034.bin: 100% 405M/405M [00:07<00:00, 53.9MB/s]\n",
            "Downloading shards:  76% 26/34 [03:46<01:14,  9.32s/it]\n",
            "pytorch_model-00027-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:   3% 10.5M/405M [00:00<00:26, 14.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.1MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.0MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 45.2MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 57.7MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  26% 105M/405M [00:02<00:04, 62.5MB/s] \u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  28% 115M/405M [00:02<00:04, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  31% 126M/405M [00:02<00:04, 57.7MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  34% 136M/405M [00:02<00:04, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  36% 147M/405M [00:02<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  39% 157M/405M [00:03<00:04, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  41% 168M/405M [00:03<00:03, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  44% 178M/405M [00:03<00:03, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  47% 189M/405M [00:03<00:03, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  49% 199M/405M [00:03<00:03, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  52% 210M/405M [00:03<00:03, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  54% 220M/405M [00:04<00:03, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  57% 231M/405M [00:04<00:03, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  60% 241M/405M [00:04<00:03, 53.1MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  62% 252M/405M [00:04<00:02, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  65% 262M/405M [00:04<00:02, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  67% 273M/405M [00:05<00:02, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  70% 283M/405M [00:05<00:02, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  75% 304M/405M [00:05<00:01, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  78% 315M/405M [00:05<00:01, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  80% 325M/405M [00:05<00:01, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  83% 336M/405M [00:06<00:01, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  85% 346M/405M [00:06<00:00, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  88% 357M/405M [00:06<00:00, 58.5MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  91% 367M/405M [00:06<00:00, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  93% 377M/405M [00:06<00:00, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  96% 388M/405M [00:07<00:00, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin:  98% 398M/405M [00:07<00:00, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00027-of-00034.bin: 100% 405M/405M [00:07<00:00, 55.2MB/s]\n",
            "Downloading shards:  79% 27/34 [03:54<01:02,  8.89s/it]\n",
            "pytorch_model-00028-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:   3% 10.5M/405M [00:00<00:26, 15.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 24.8MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.2MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  10% 41.9M/405M [00:01<00:08, 44.7MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  26% 105M/405M [00:02<00:05, 57.8MB/s] \u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  28% 115M/405M [00:02<00:05, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  31% 126M/405M [00:02<00:04, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  34% 136M/405M [00:02<00:04, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  36% 147M/405M [00:02<00:04, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  39% 157M/405M [00:03<00:04, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  41% 168M/405M [00:03<00:04, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  44% 178M/405M [00:03<00:04, 50.6MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  47% 189M/405M [00:03<00:04, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  49% 199M/405M [00:03<00:03, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  52% 210M/405M [00:04<00:03, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  54% 220M/405M [00:04<00:03, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  57% 231M/405M [00:04<00:02, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  60% 241M/405M [00:04<00:03, 51.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  62% 252M/405M [00:04<00:02, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  65% 262M/405M [00:05<00:02, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  67% 273M/405M [00:05<00:02, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  70% 283M/405M [00:05<00:02, 55.5MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  73% 294M/405M [00:05<00:02, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  75% 304M/405M [00:05<00:02, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  78% 315M/405M [00:06<00:01, 54.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  80% 325M/405M [00:06<00:01, 53.5MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  83% 336M/405M [00:06<00:01, 53.4MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  85% 346M/405M [00:06<00:01, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  88% 357M/405M [00:06<00:00, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  91% 367M/405M [00:07<00:00, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  93% 377M/405M [00:07<00:00, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  96% 388M/405M [00:07<00:00, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin:  98% 398M/405M [00:07<00:00, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00028-of-00034.bin: 100% 405M/405M [00:07<00:00, 52.9MB/s]\n",
            "Downloading shards:  82% 28/34 [04:02<00:52,  8.71s/it]\n",
            "pytorch_model-00029-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 26.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 36.7MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 48.3MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  26% 105M/405M [00:02<00:05, 55.9MB/s] \u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  28% 115M/405M [00:02<00:04, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  31% 126M/405M [00:02<00:04, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  34% 136M/405M [00:02<00:04, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  36% 147M/405M [00:02<00:04, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  39% 157M/405M [00:03<00:04, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  41% 168M/405M [00:03<00:03, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  44% 178M/405M [00:03<00:03, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  47% 189M/405M [00:03<00:03, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  49% 199M/405M [00:03<00:03, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  52% 210M/405M [00:03<00:03, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  54% 220M/405M [00:04<00:03, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  57% 231M/405M [00:04<00:02, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  62% 252M/405M [00:04<00:02, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  65% 262M/405M [00:04<00:02, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  67% 273M/405M [00:05<00:02, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  70% 283M/405M [00:05<00:01, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  73% 294M/405M [00:05<00:01, 58.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  75% 304M/405M [00:05<00:01, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  78% 315M/405M [00:05<00:01, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  80% 325M/405M [00:05<00:01, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  83% 336M/405M [00:06<00:01, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  85% 346M/405M [00:06<00:00, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  88% 357M/405M [00:06<00:00, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  91% 367M/405M [00:06<00:00, 61.9MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  93% 377M/405M [00:06<00:00, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  96% 388M/405M [00:07<00:00, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin:  98% 398M/405M [00:07<00:00, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00029-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.9MB/s]\n",
            "Downloading shards:  85% 29/34 [04:10<00:42,  8.48s/it]\n",
            "pytorch_model-00030-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:   8% 31.5M/405M [00:01<00:11, 33.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  10% 41.9M/405M [00:01<00:09, 38.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  13% 52.4M/405M [00:01<00:07, 45.4MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  16% 62.9M/405M [00:01<00:06, 49.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  18% 73.4M/405M [00:01<00:06, 50.0MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  21% 83.9M/405M [00:02<00:06, 50.9MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  23% 94.4M/405M [00:02<00:05, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  26% 105M/405M [00:02<00:05, 55.2MB/s] \u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  28% 115M/405M [00:02<00:05, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  31% 126M/405M [00:02<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  34% 136M/405M [00:02<00:04, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  36% 147M/405M [00:03<00:04, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  39% 157M/405M [00:03<00:04, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  41% 168M/405M [00:03<00:04, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  44% 178M/405M [00:03<00:03, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  47% 189M/405M [00:03<00:03, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  49% 199M/405M [00:03<00:03, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  52% 210M/405M [00:04<00:03, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  54% 220M/405M [00:04<00:03, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  60% 241M/405M [00:04<00:02, 58.8MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  62% 252M/405M [00:04<00:02, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  65% 262M/405M [00:05<00:02, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  67% 273M/405M [00:05<00:02, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  70% 283M/405M [00:05<00:01, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  73% 294M/405M [00:05<00:01, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  75% 304M/405M [00:05<00:01, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  78% 315M/405M [00:05<00:01, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  80% 325M/405M [00:06<00:01, 57.9MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  83% 336M/405M [00:06<00:01, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  85% 346M/405M [00:06<00:00, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  88% 357M/405M [00:06<00:00, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  91% 367M/405M [00:06<00:00, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  93% 377M/405M [00:06<00:00, 56.7MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  96% 388M/405M [00:07<00:00, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin:  98% 398M/405M [00:07<00:00, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00030-of-00034.bin: 100% 405M/405M [00:07<00:00, 54.3MB/s]\n",
            "Downloading shards:  88% 30/34 [04:19<00:33,  8.38s/it]\n",
            "pytorch_model-00031-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:   3% 10.5M/405M [00:00<00:25, 15.2MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:   5% 21.0M/405M [00:00<00:15, 25.6MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 35.4MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 45.9MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 57.5MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 63.0MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  18% 73.4M/405M [00:01<00:04, 67.3MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  26% 105M/405M [00:02<00:04, 64.5MB/s] \u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  28% 115M/405M [00:02<00:04, 62.8MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  31% 126M/405M [00:02<00:04, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  34% 136M/405M [00:02<00:04, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  36% 147M/405M [00:02<00:04, 62.5MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  39% 157M/405M [00:02<00:04, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  41% 168M/405M [00:03<00:04, 59.0MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  44% 178M/405M [00:03<00:03, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  47% 189M/405M [00:03<00:03, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  49% 199M/405M [00:03<00:03, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  52% 210M/405M [00:03<00:03, 58.9MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  54% 220M/405M [00:03<00:02, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  57% 231M/405M [00:04<00:02, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  60% 241M/405M [00:04<00:02, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  62% 252M/405M [00:04<00:02, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  65% 262M/405M [00:04<00:02, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  67% 273M/405M [00:04<00:02, 60.6MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  70% 283M/405M [00:04<00:01, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  73% 294M/405M [00:05<00:01, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  75% 304M/405M [00:05<00:01, 60.9MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  78% 315M/405M [00:05<00:01, 64.2MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  80% 325M/405M [00:05<00:01, 62.2MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  83% 336M/405M [00:05<00:01, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  85% 346M/405M [00:05<00:00, 65.2MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  88% 357M/405M [00:06<00:00, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  91% 367M/405M [00:06<00:00, 61.1MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  93% 377M/405M [00:06<00:00, 65.5MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin:  96% 388M/405M [00:06<00:00, 62.5MB/s]\u001b[A\n",
            "pytorch_model-00031-of-00034.bin: 100% 405M/405M [00:06<00:00, 58.6MB/s]\n",
            "Downloading shards:  91% 31/34 [04:27<00:25,  8.41s/it]\n",
            "pytorch_model-00032-of-00034.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:   3% 10.5M/405M [00:00<00:24, 15.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:   5% 21.0M/405M [00:00<00:14, 25.7MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:   8% 31.5M/405M [00:01<00:10, 36.1MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  10% 41.9M/405M [00:01<00:07, 45.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  13% 52.4M/405M [00:01<00:06, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  16% 62.9M/405M [00:01<00:05, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  18% 73.4M/405M [00:01<00:05, 63.7MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  21% 83.9M/405M [00:01<00:05, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  23% 94.4M/405M [00:01<00:05, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  26% 105M/405M [00:02<00:04, 63.4MB/s] \u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  28% 115M/405M [00:02<00:04, 61.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  31% 126M/405M [00:02<00:04, 65.4MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  34% 136M/405M [00:02<00:04, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  36% 147M/405M [00:02<00:04, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  39% 157M/405M [00:03<00:04, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  41% 168M/405M [00:03<00:04, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  44% 178M/405M [00:03<00:04, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  47% 189M/405M [00:03<00:04, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  49% 199M/405M [00:03<00:03, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  52% 210M/405M [00:04<00:03, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  54% 220M/405M [00:04<00:03, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  57% 231M/405M [00:04<00:03, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  60% 241M/405M [00:04<00:02, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  62% 252M/405M [00:04<00:02, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  65% 262M/405M [00:05<00:02, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  67% 273M/405M [00:05<00:02, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  70% 283M/405M [00:05<00:02, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  73% 294M/405M [00:05<00:01, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  75% 304M/405M [00:05<00:01, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  78% 315M/405M [00:05<00:01, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  80% 325M/405M [00:06<00:01, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  83% 336M/405M [00:06<00:01, 55.2MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  85% 346M/405M [00:06<00:01, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  88% 357M/405M [00:06<00:00, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  91% 367M/405M [00:06<00:00, 55.0MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  93% 377M/405M [00:07<00:00, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin:  96% 388M/405M [00:07<00:00, 56.5MB/s]\u001b[A\n",
            "pytorch_model-00032-of-00034.bin: 100% 405M/405M [00:07<00:00, 53.4MB/s]\n",
            "Downloading shards:  94% 32/34 [04:35<00:16,  8.36s/it]\n",
            "pytorch_model-00033-of-00034.bin:   0% 0.00/271M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:   4% 10.5M/271M [00:00<00:16, 15.7MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:   8% 21.0M/271M [00:00<00:09, 25.9MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  12% 31.5M/271M [00:01<00:06, 36.8MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  16% 41.9M/271M [00:01<00:04, 46.5MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  19% 52.4M/271M [00:01<00:03, 57.6MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  27% 73.4M/271M [00:01<00:02, 67.0MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  31% 83.9M/271M [00:01<00:02, 68.3MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  35% 94.4M/271M [00:01<00:02, 65.2MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  39% 105M/271M [00:02<00:02, 59.3MB/s] \u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  43% 115M/271M [00:02<00:02, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  47% 126M/271M [00:02<00:02, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  50% 136M/271M [00:02<00:02, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  54% 147M/271M [00:02<00:01, 67.2MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  58% 157M/271M [00:02<00:01, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  62% 168M/271M [00:02<00:01, 68.9MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  66% 178M/271M [00:03<00:01, 66.2MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  70% 189M/271M [00:03<00:01, 64.0MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  74% 199M/271M [00:03<00:01, 65.5MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  78% 210M/271M [00:03<00:01, 51.3MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  81% 220M/271M [00:03<00:00, 52.5MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  85% 231M/271M [00:04<00:00, 54.6MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  89% 241M/271M [00:04<00:00, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  93% 252M/271M [00:04<00:00, 61.2MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin:  97% 262M/271M [00:04<00:00, 58.7MB/s]\u001b[A\n",
            "pytorch_model-00033-of-00034.bin: 100% 271M/271M [00:04<00:00, 56.3MB/s]\n",
            "Downloading shards:  97% 33/34 [04:41<00:07,  7.46s/it]\n",
            "pytorch_model-00034-of-00034.bin:   0% 0.00/262M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:   4% 10.5M/262M [00:00<00:15, 16.0MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:   8% 21.0M/262M [00:00<00:09, 26.5MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  12% 31.5M/262M [00:01<00:06, 35.0MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  16% 41.9M/262M [00:01<00:05, 40.9MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  20% 52.4M/262M [00:01<00:04, 44.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  24% 62.9M/262M [00:01<00:04, 48.1MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  28% 73.4M/262M [00:01<00:03, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  32% 83.9M/262M [00:01<00:03, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  36% 94.4M/262M [00:02<00:03, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  40% 105M/262M [00:02<00:02, 55.2MB/s] \u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  44% 115M/262M [00:02<00:02, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  48% 126M/262M [00:02<00:02, 58.1MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  52% 136M/262M [00:02<00:02, 57.2MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  56% 147M/262M [00:03<00:02, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  60% 157M/262M [00:03<00:01, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  64% 168M/262M [00:03<00:01, 50.1MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  68% 178M/262M [00:03<00:01, 51.1MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  72% 189M/262M [00:03<00:01, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  76% 199M/262M [00:04<00:01, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  80% 210M/262M [00:04<00:01, 51.0MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  84% 220M/262M [00:04<00:00, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  88% 231M/262M [00:04<00:00, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  92% 241M/262M [00:04<00:00, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin:  96% 252M/262M [00:05<00:00, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00034-of-00034.bin: 100% 262M/262M [00:05<00:00, 49.5MB/s]\n",
            "Downloading shards: 100% 34/34 [04:46<00:00,  8.44s/it]\n",
            "Loading checkpoint shards: 100% 34/34 [00:06<00:00,  5.02it/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 973kB/s]\n",
            "100% 100/100 [06:21<00:00,  3.81s/it]\n",
            "0.13\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en_fact \\\n",
        " --modelname vicuna\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm sharpbai/vicuna-7b-v1.3 \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0PSB6VXR3cl",
        "outputId": "bc3542ad-75c5-4196-a40c-9c692ae78027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Loading checkpoint shards: 100% 4/4 [00:07<00:00,  1.91s/it]\n",
            "  0% 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 1/100 [00:17<29:28, 17.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 2/100 [00:34<28:26, 17.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 3/100 [00:52<27:54, 17.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 4/100 [01:08<27:08, 16.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 5/100 [01:25<27:01, 17.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 6/100 [01:43<26:49, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 7/100 [01:57<25:07, 16.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 8/100 [02:14<25:21, 16.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 9/100 [02:31<25:24, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 10/100 [02:49<25:22, 16.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 11/100 [03:06<25:13, 17.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 12/100 [03:23<25:02, 17.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 13/100 [03:40<24:49, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 14/100 [03:57<24:34, 17.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 15/100 [04:02<19:05, 13.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 16/100 [04:14<17:55, 12.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 17/100 [04:31<19:32, 14.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 18/100 [04:48<20:32, 15.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 19/100 [05:05<21:10, 15.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 20/100 [05:22<21:31, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 21/100 [05:40<21:40, 16.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 22/100 [05:57<21:41, 16.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 23/100 [06:14<21:36, 16.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 24/100 [06:31<21:28, 16.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 25/100 [06:48<21:17, 17.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 26/100 [07:06<21:04, 17.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 27/100 [07:23<20:49, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 28/100 [07:40<20:34, 17.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 29/100 [07:57<20:18, 17.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 30/100 [08:15<20:02, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 31/100 [08:32<19:45, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 32/100 [08:49<19:27, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 33/100 [09:06<19:10, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 34/100 [09:23<18:55, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 35/100 [09:41<18:40, 17.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 36/100 [09:53<16:47, 15.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 37/100 [10:10<17:01, 16.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 38/100 [10:17<13:54, 13.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 39/100 [10:34<14:50, 14.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 40/100 [10:52<15:23, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 41/100 [11:09<15:41, 15.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 42/100 [11:26<15:48, 16.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 43/100 [11:44<15:48, 16.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 44/100 [12:01<15:41, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 45/100 [12:18<15:31, 16.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 46/100 [12:35<15:19, 17.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 47/100 [12:52<15:05, 17.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 48/100 [13:10<14:50, 17.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 49/100 [13:27<14:33, 17.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 50/100 [13:44<14:18, 17.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 51/100 [14:01<14:01, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 52/100 [14:11<11:53, 14.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 53/100 [14:28<12:11, 15.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 54/100 [14:45<12:18, 16.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 55/100 [14:48<09:05, 12.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 56/100 [15:05<10:00, 13.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 57/100 [15:22<10:32, 14.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 58/100 [15:40<10:48, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 59/100 [15:55<10:30, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 60/100 [16:12<10:36, 15.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 61/100 [16:29<10:35, 16.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 62/100 [16:46<10:29, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 63/100 [17:04<10:20, 16.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 64/100 [17:21<10:08, 16.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 65/100 [17:38<09:55, 17.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 66/100 [17:55<09:40, 17.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 67/100 [18:13<09:24, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 68/100 [18:30<09:08, 17.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 69/100 [18:47<08:51, 17.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 70/100 [19:04<08:34, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 71/100 [19:21<08:18, 17.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 72/100 [19:39<08:01, 17.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 73/100 [19:47<06:37, 14.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 74/100 [20:05<06:41, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 75/100 [20:22<06:39, 15.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 76/100 [20:39<06:32, 16.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 77/100 [20:56<06:21, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 78/100 [21:13<06:08, 16.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 79/100 [21:31<05:54, 16.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 80/100 [21:48<05:39, 17.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 81/100 [22:03<05:12, 16.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 82/100 [22:20<05:00, 16.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 83/100 [22:37<04:46, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 84/100 [22:55<04:31, 16.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 85/100 [23:12<04:15, 17.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 86/100 [23:29<03:59, 17.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 87/100 [23:46<03:42, 17.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 88/100 [24:04<03:26, 17.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 89/100 [24:21<03:09, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 90/100 [24:38<02:52, 17.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 91/100 [24:50<02:20, 15.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 92/100 [25:07<02:09, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 93/100 [25:25<01:55, 16.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 94/100 [25:42<01:40, 16.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 95/100 [25:59<01:24, 16.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 96/100 [26:16<01:07, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 97/100 [26:34<00:51, 17.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 98/100 [26:51<00:34, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 99/100 [27:08<00:17, 17.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 100/100 [27:25<00:00, 16.46s/it]\n",
            "0.13\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en_fact \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm islam23/llama3-8b-RAG_News_Finance \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-SkpmQ4RA2l"
      },
      "outputs": [],
      "source": [
        "!python fact_evalue.py \\\n",
        " --dataset en_fact \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm islam23/llama3-8b-RAG_News_Finance \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca11j0iuS4BM"
      },
      "source": [
        "# Information Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7crZSw7SA2a",
        "outputId": "41c65059-0665-4f3b-8980-5e9597d4afe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 51.1k/51.1k [00:00<00:00, 142MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 5.36MB/s]\n",
            "special_tokens_map.json: 100% 335/335 [00:00<00:00, 2.56MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "config.json: 100% 1.19k/1.19k [00:00<00:00, 9.22MB/s]\n",
            "adapter_config.json: 100% 689/689 [00:00<00:00, 5.16MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 654/654 [00:00<00:00, 4.56MB/s]\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 82.1MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 41.9M/4.98G [00:00<00:12, 407MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 83.9M/4.98G [00:00<00:13, 357MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 126M/4.98G [00:00<00:13, 366MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 168M/4.98G [00:00<00:12, 374MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 220M/4.98G [00:00<00:11, 407MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 273M/4.98G [00:00<00:11, 425MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 325M/4.98G [00:00<00:10, 432MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 377M/4.98G [00:00<00:10, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 430M/4.98G [00:01<00:11, 397MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 472M/4.98G [00:01<00:11, 402MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 514M/4.98G [00:01<00:11, 392MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 566M/4.98G [00:01<00:10, 414MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 608M/4.98G [00:01<00:11, 377MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 661M/4.98G [00:01<00:10, 404MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 713M/4.98G [00:01<00:10, 420MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 765M/4.98G [00:01<00:10, 393MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 807M/4.98G [00:02<00:10, 380MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 860M/4.98G [00:02<00:10, 393MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 912M/4.98G [00:02<00:10, 399MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 954M/4.98G [00:02<00:10, 395MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 996M/4.98G [00:02<00:10, 385MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.04G/4.98G [00:02<00:10, 386MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.09G/4.98G [00:02<00:09, 403MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.13G/4.98G [00:02<00:10, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.17G/4.98G [00:03<00:10, 354MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.22G/4.98G [00:03<00:10, 365MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.26G/4.98G [00:03<00:11, 313MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.31G/4.98G [00:03<00:10, 349MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.36G/4.98G [00:03<00:09, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.42G/4.98G [00:03<00:08, 408MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.47G/4.98G [00:03<00:08, 424MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.52G/4.98G [00:03<00:07, 441MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.57G/4.98G [00:03<00:07, 458MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.63G/4.98G [00:04<00:07, 462MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.68G/4.98G [00:04<00:07, 470MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.73G/4.98G [00:04<00:06, 477MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.78G/4.98G [00:04<00:07, 445MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.84G/4.98G [00:04<00:07, 421MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:04<00:07, 390MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.93G/4.98G [00:04<00:08, 378MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.98G/4.98G [00:04<00:07, 408MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.03G/4.98G [00:05<00:06, 434MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.09G/4.98G [00:05<00:06, 456MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.14G/4.98G [00:05<00:06, 454MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.19G/4.98G [00:05<00:06, 464MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.24G/4.98G [00:05<00:06, 430MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.30G/4.98G [00:05<00:06, 446MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.35G/4.98G [00:05<00:05, 443MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.40G/4.98G [00:05<00:05, 435MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.45G/4.98G [00:06<00:05, 424MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.51G/4.98G [00:06<00:05, 419MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.56G/4.98G [00:06<00:05, 435MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.61G/4.98G [00:06<00:05, 421MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.66G/4.98G [00:06<00:05, 416MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.71G/4.98G [00:06<00:06, 376MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.76G/4.98G [00:06<00:05, 391MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.80G/4.98G [00:06<00:05, 397MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.85G/4.98G [00:06<00:05, 403MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.89G/4.98G [00:07<00:05, 376MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.94G/4.98G [00:07<00:05, 367MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.98G/4.98G [00:07<00:05, 369MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.02G/4.98G [00:07<00:05, 353MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.06G/4.98G [00:07<00:05, 349MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.10G/4.98G [00:07<00:05, 348MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.15G/4.98G [00:07<00:05, 349MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.19G/4.98G [00:07<00:04, 361MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.23G/4.98G [00:08<00:04, 376MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.27G/4.98G [00:08<00:04, 362MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.31G/4.98G [00:08<00:04, 370MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.37G/4.98G [00:08<00:04, 392MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.41G/4.98G [00:08<00:03, 392MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.46G/4.98G [00:08<00:03, 406MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.51G/4.98G [00:08<00:03, 417MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.57G/4.98G [00:08<00:03, 425MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 3.62G/4.98G [00:08<00:03, 429MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.67G/4.98G [00:09<00:03, 419MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.72G/4.98G [00:09<00:03, 418MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.76G/4.98G [00:09<00:02, 414MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.81G/4.98G [00:09<00:02, 413MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.85G/4.98G [00:09<00:02, 408MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.90G/4.98G [00:09<00:02, 413MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.95G/4.98G [00:09<00:02, 417MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 4.01G/4.98G [00:09<00:02, 421MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.06G/4.98G [00:10<00:02, 424MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.11G/4.98G [00:10<00:02, 427MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.16G/4.98G [00:10<00:01, 416MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.22G/4.98G [00:10<00:01, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.27G/4.98G [00:10<00:01, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.32G/4.98G [00:10<00:01, 426MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.37G/4.98G [00:10<00:01, 405MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.41G/4.98G [00:10<00:01, 406MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.46G/4.98G [00:11<00:01, 402MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.50G/4.98G [00:11<00:01, 399MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.55G/4.98G [00:11<00:01, 407MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.60G/4.98G [00:11<00:00, 411MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.66G/4.98G [00:11<00:00, 414MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.71G/4.98G [00:11<00:00, 412MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.75G/4.98G [00:11<00:00, 410MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.79G/4.98G [00:11<00:00, 412MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.83G/4.98G [00:11<00:00, 411MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.88G/4.98G [00:12<00:00, 412MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.92G/4.98G [00:12<00:00, 413MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:12<00:00, 405MB/s]\n",
            "Downloading shards:  25% 1/4 [00:12<00:37, 12.63s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 31.5M/5.00G [00:00<00:17, 278MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 62.9M/5.00G [00:00<00:19, 258MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 105M/5.00G [00:00<00:16, 305MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 147M/5.00G [00:00<00:15, 323MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 189M/5.00G [00:00<00:13, 352MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 241M/5.00G [00:00<00:12, 376MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 283M/5.00G [00:00<00:12, 371MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 325M/5.00G [00:00<00:12, 366MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 367M/5.00G [00:01<00:12, 371MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 409M/5.00G [00:01<00:12, 383MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 451M/5.00G [00:01<00:11, 391MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 503M/5.00G [00:01<00:11, 402MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11% 556M/5.00G [00:01<00:10, 409MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 598M/5.00G [00:01<00:10, 410MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 640M/5.00G [00:01<00:16, 270MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 692M/5.00G [00:02<00:13, 308MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 744M/5.00G [00:02<00:12, 338MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 797M/5.00G [00:02<00:11, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 849M/5.00G [00:02<00:10, 377MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 902M/5.00G [00:02<00:10, 391MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 944M/5.00G [00:02<00:10, 398MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 986M/5.00G [00:02<00:09, 402MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.03G/5.00G [00:02<00:09, 406MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.07G/5.00G [00:02<00:09, 409MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.11G/5.00G [00:03<00:09, 411MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.16G/5.00G [00:03<00:09, 416MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.21G/5.00G [00:03<00:09, 414MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.25G/5.00G [00:03<00:09, 413MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.29G/5.00G [00:03<00:08, 413MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.33G/5.00G [00:03<00:08, 413MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.37G/5.00G [00:03<00:08, 412MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.42G/5.00G [00:03<00:08, 413MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.46G/5.00G [00:03<00:08, 414MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.51G/5.00G [00:03<00:08, 428MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.56G/5.00G [00:04<00:07, 455MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.61G/5.00G [00:04<00:07, 431MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.67G/5.00G [00:04<00:07, 427MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.72G/5.00G [00:04<00:08, 404MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.77G/5.00G [00:04<00:07, 421MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.82G/5.00G [00:04<00:07, 436MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.88G/5.00G [00:04<00:07, 426MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.93G/5.00G [00:04<00:06, 441MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.98G/5.00G [00:05<00:06, 457MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 2.03G/5.00G [00:05<00:06, 475MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.09G/5.00G [00:05<00:06, 483MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.14G/5.00G [00:05<00:05, 480MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.19G/5.00G [00:05<00:05, 480MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.24G/5.00G [00:05<00:06, 458MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.30G/5.00G [00:05<00:06, 431MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.35G/5.00G [00:05<00:06, 389MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.39G/5.00G [00:05<00:06, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.44G/5.00G [00:06<00:06, 419MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.51G/5.00G [00:06<00:05, 432MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.56G/5.00G [00:06<00:05, 410MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.60G/5.00G [00:06<00:05, 401MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.64G/5.00G [00:06<00:05, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.68G/5.00G [00:06<00:05, 391MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.73G/5.00G [00:06<00:05, 388MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.77G/5.00G [00:06<00:05, 385MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.81G/5.00G [00:07<00:06, 351MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.86G/5.00G [00:07<00:05, 374MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.90G/5.00G [00:07<00:05, 358MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.95G/5.00G [00:07<00:05, 373MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 2.99G/5.00G [00:07<00:05, 372MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.03G/5.00G [00:07<00:05, 378MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:07<00:05, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.11G/5.00G [00:08<00:06, 280MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.16G/5.00G [00:08<00:05, 308MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.20G/5.00G [00:08<00:05, 334MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.25G/5.00G [00:08<00:04, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.29G/5.00G [00:08<00:04, 363MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.33G/5.00G [00:08<00:04, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.38G/5.00G [00:08<00:04, 353MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.42G/5.00G [00:08<00:04, 361MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.47G/5.00G [00:08<00:03, 383MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.51G/5.00G [00:09<00:03, 387MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.55G/5.00G [00:09<00:03, 377MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.61G/5.00G [00:09<00:03, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.66G/5.00G [00:09<00:03, 410MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.71G/5.00G [00:09<00:03, 408MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.75G/5.00G [00:09<00:03, 373MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.80G/5.00G [00:09<00:03, 370MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.85G/5.00G [00:09<00:02, 391MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.90G/5.00G [00:10<00:02, 404MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.95G/5.00G [00:10<00:02, 411MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80% 4.00G/5.00G [00:10<00:02, 397MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.04G/5.00G [00:10<00:02, 394MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.08G/5.00G [00:10<00:02, 394MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.12G/5.00G [00:10<00:02, 395MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.16G/5.00G [00:10<00:02, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.22G/5.00G [00:10<00:01, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [00:10<00:01, 376MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.30G/5.00G [00:11<00:01, 379MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.35G/5.00G [00:11<00:01, 394MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.39G/5.00G [00:11<00:01, 386MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.44G/5.00G [00:11<00:01, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.48G/5.00G [00:11<00:01, 384MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.52G/5.00G [00:11<00:01, 364MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:11<00:01, 361MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.62G/5.00G [00:11<00:00, 378MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.67G/5.00G [00:12<00:01, 296MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.72G/5.00G [00:12<00:00, 330MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.76G/5.00G [00:12<00:00, 330MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.80G/5.00G [00:12<00:00, 336MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.84G/5.00G [00:12<00:00, 341MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.89G/5.00G [00:12<00:00, 353MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99% 4.93G/5.00G [00:12<00:00, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:13<00:00, 384MB/s]\n",
            "Downloading shards:  50% 2/4 [00:25<00:26, 13.01s/it]\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0% 10.5M/4.92G [00:00<00:48, 101MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0% 21.0M/4.92G [00:00<00:47, 103MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 62.9M/4.92G [00:00<00:20, 235MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 115M/4.92G [00:00<00:15, 316MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 168M/4.92G [00:00<00:13, 358MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 210M/4.92G [00:00<00:14, 331MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 252M/4.92G [00:00<00:13, 351MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 304M/4.92G [00:00<00:12, 374MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 346M/4.92G [00:01<00:12, 366MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 388M/4.92G [00:01<00:12, 377MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 430M/4.92G [00:01<00:14, 318MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 472M/4.92G [00:01<00:20, 221MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 503M/4.92G [00:01<00:18, 237MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 535M/4.92G [00:01<00:17, 252MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 587M/4.92G [00:01<00:14, 297MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 640M/4.92G [00:02<00:12, 333MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 692M/4.92G [00:02<00:11, 359MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 744M/4.92G [00:02<00:10, 382MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 797M/4.92G [00:02<00:10, 400MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 849M/4.92G [00:02<00:09, 413MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 902M/4.92G [00:02<00:09, 424MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 954M/4.92G [00:02<00:09, 426MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 1.01G/4.92G [00:02<00:09, 431MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.06G/4.92G [00:03<00:08, 437MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.11G/4.92G [00:03<00:08, 440MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.16G/4.92G [00:03<00:08, 442MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.22G/4.92G [00:03<00:08, 458MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.27G/4.92G [00:03<00:08, 443MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.32G/4.92G [00:03<00:08, 427MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.37G/4.92G [00:03<00:07, 443MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.43G/4.92G [00:03<00:08, 402MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.47G/4.92G [00:04<00:08, 394MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.52G/4.92G [00:04<00:08, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.57G/4.92G [00:04<00:08, 412MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.61G/4.92G [00:04<00:08, 412MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.66G/4.92G [00:04<00:08, 404MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.71G/4.92G [00:04<00:07, 430MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.76G/4.92G [00:04<00:07, 442MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.81G/4.92G [00:04<00:06, 464MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.87G/4.92G [00:04<00:06, 454MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.92G/4.92G [00:05<00:06, 441MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.97G/4.92G [00:05<00:06, 455MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 2.02G/4.92G [00:05<00:06, 461MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.08G/4.92G [00:05<00:06, 463MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43% 2.13G/4.92G [00:05<00:06, 454MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.18G/4.92G [00:05<00:06, 451MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.23G/4.92G [00:05<00:06, 420MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.29G/4.92G [00:05<00:06, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.33G/4.92G [00:06<00:06, 384MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.37G/4.92G [00:06<00:06, 376MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.41G/4.92G [00:06<00:06, 379MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50% 2.45G/4.92G [00:06<00:06, 373MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.50G/4.92G [00:06<00:06, 361MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.54G/4.92G [00:06<00:06, 352MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53% 2.59G/4.92G [00:06<00:06, 381MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.64G/4.92G [00:06<00:05, 412MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.69G/4.92G [00:06<00:05, 436MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.75G/4.92G [00:07<00:04, 449MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.80G/4.92G [00:07<00:04, 461MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.85G/4.92G [00:07<00:04, 435MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.90G/4.92G [00:07<00:07, 266MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.95G/4.92G [00:08<00:10, 194MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.98G/4.92G [00:08<00:10, 184MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 3.01G/4.92G [00:08<00:09, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.04G/4.92G [00:08<00:09, 208MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.07G/4.92G [00:08<00:08, 226MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63% 3.11G/4.92G [00:08<00:06, 267MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 3.17G/4.92G [00:08<00:05, 313MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.22G/4.92G [00:08<00:04, 345MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 3.26G/4.92G [00:09<00:04, 362MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.30G/4.92G [00:09<00:04, 375MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.36G/4.92G [00:09<00:04, 388MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 3.40G/4.92G [00:09<00:03, 393MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.44G/4.92G [00:09<00:03, 399MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.48G/4.92G [00:09<00:03, 405MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.53G/4.92G [00:09<00:03, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.58G/4.92G [00:09<00:03, 393MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.63G/4.92G [00:09<00:03, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.67G/4.92G [00:10<00:03, 408MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.72G/4.92G [00:10<00:02, 419MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.76G/4.92G [00:10<00:03, 304MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.82G/4.92G [00:10<00:03, 335MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.87G/4.92G [00:10<00:02, 361MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.92G/4.92G [00:10<00:02, 380MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.97G/4.92G [00:10<00:02, 398MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.03G/4.92G [00:11<00:02, 408MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.08G/4.92G [00:11<00:01, 421MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.13G/4.92G [00:11<00:01, 434MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.18G/4.92G [00:11<00:01, 424MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.24G/4.92G [00:11<00:01, 430MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.29G/4.92G [00:11<00:01, 439MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 4.34G/4.92G [00:11<00:01, 442MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.39G/4.92G [00:11<00:01, 444MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.45G/4.92G [00:12<00:01, 426MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.50G/4.92G [00:12<00:00, 419MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.55G/4.92G [00:12<00:00, 428MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.60G/4.92G [00:12<00:00, 433MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95% 4.66G/4.92G [00:12<00:00, 424MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.71G/4.92G [00:12<00:00, 430MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 4.76G/4.92G [00:12<00:00, 434MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.81G/4.92G [00:12<00:00, 428MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.87G/4.92G [00:13<00:00, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:13<00:00, 373MB/s]\n",
            "Downloading shards:  75% 3/4 [00:39<00:13, 13.20s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   4% 52.4M/1.17G [00:00<00:02, 438MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   9% 105M/1.17G [00:00<00:02, 452MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 157M/1.17G [00:00<00:02, 401MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17% 199M/1.17G [00:00<00:02, 380MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21% 241M/1.17G [00:00<00:02, 377MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24% 283M/1.17G [00:00<00:02, 355MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  29% 336M/1.17G [00:00<00:02, 396MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32% 377M/1.17G [00:00<00:02, 375MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  37% 430M/1.17G [00:01<00:01, 395MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  41% 482M/1.17G [00:01<00:01, 416MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46% 535M/1.17G [00:01<00:01, 405MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  50% 587M/1.17G [00:01<00:01, 411MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  54% 629M/1.17G [00:01<00:01, 392MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57% 671M/1.17G [00:01<00:01, 392MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  62% 724M/1.17G [00:01<00:01, 409MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66% 776M/1.17G [00:01<00:00, 418MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  71% 828M/1.17G [00:02<00:00, 405MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75% 870M/1.17G [00:02<00:00, 369MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78% 912M/1.17G [00:02<00:00, 372MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83% 965M/1.17G [00:02<00:00, 389MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86% 1.01G/1.17G [00:02<00:00, 367MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  90% 1.05G/1.17G [00:02<00:00, 352MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  93% 1.09G/1.17G [00:02<00:00, 357MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:03<00:00, 387MB/s]\n",
            "Downloading shards: 100% 4/4 [00:42<00:00, 10.65s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:07<00:00,  1.94s/it]\n",
            "generation_config.json: 100% 187/187 [00:00<00:00, 1.48MB/s]\n",
            "adapter_model.safetensors: 100% 54.6M/54.6M [00:00<00:00, 140MB/s]\n",
            "  0% 0/100 [00:00<?, ?it/s]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 1/100 [00:19<31:37, 19.17s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 2/100 [00:37<30:47, 18.85s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 3/100 [00:56<30:18, 18.74s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 4/100 [01:15<30:18, 18.94s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 5/100 [01:18<20:32, 12.97s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 6/100 [01:36<23:01, 14.70s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 7/100 [01:54<24:34, 15.85s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 8/100 [02:12<25:38, 16.72s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 9/100 [02:31<26:06, 17.21s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 10/100 [02:49<26:29, 17.66s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 11/100 [03:08<26:41, 18.00s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 12/100 [03:26<26:27, 18.04s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 13/100 [03:44<26:02, 17.96s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 14/100 [04:03<26:15, 18.32s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 15/100 [04:22<26:18, 18.57s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 16/100 [04:25<19:27, 13.90s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 17/100 [04:43<20:52, 15.09s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 18/100 [05:02<21:57, 16.07s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 19/100 [05:20<22:45, 16.85s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 20/100 [05:39<23:09, 17.37s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 21/100 [05:58<23:22, 17.76s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 22/100 [06:16<23:32, 18.11s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 23/100 [06:35<23:26, 18.27s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 24/100 [06:54<23:18, 18.40s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 25/100 [07:12<23:05, 18.47s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 26/100 [07:30<22:37, 18.34s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 27/100 [07:48<22:07, 18.18s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 28/100 [08:07<21:50, 18.20s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 29/100 [08:25<21:33, 18.22s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 30/100 [08:43<21:24, 18.35s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 31/100 [09:02<21:13, 18.45s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 32/100 [09:20<20:51, 18.40s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 33/100 [09:39<20:37, 18.47s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 34/100 [09:58<20:31, 18.66s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 35/100 [10:16<19:56, 18.41s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 36/100 [10:18<14:26, 13.53s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 37/100 [10:22<11:05, 10.56s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 38/100 [10:40<13:18, 12.88s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 39/100 [10:59<14:49, 14.58s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 40/100 [11:16<15:34, 15.57s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 41/100 [11:36<16:20, 16.61s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 42/100 [11:54<16:39, 17.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 43/100 [12:14<16:58, 17.88s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 44/100 [12:33<17:04, 18.29s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 45/100 [12:52<17:02, 18.59s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 46/100 [13:10<16:38, 18.50s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 47/100 [13:29<16:22, 18.55s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 48/100 [13:48<16:06, 18.59s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 49/100 [14:06<15:36, 18.36s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 50/100 [14:24<15:23, 18.47s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 51/100 [14:44<15:18, 18.74s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 52/100 [14:54<12:57, 16.19s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 53/100 [15:13<13:16, 16.94s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 54/100 [15:32<13:27, 17.55s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 55/100 [15:50<13:26, 17.92s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 56/100 [16:09<13:22, 18.23s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 57/100 [16:28<13:09, 18.37s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 58/100 [16:47<12:53, 18.42s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 59/100 [17:05<12:34, 18.40s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 60/100 [17:24<12:22, 18.57s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 61/100 [17:43<12:06, 18.62s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 62/100 [18:01<11:47, 18.62s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 63/100 [18:19<11:22, 18.44s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 64/100 [18:37<10:56, 18.25s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 65/100 [18:55<10:33, 18.11s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 66/100 [19:13<10:17, 18.15s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 67/100 [19:32<10:03, 18.30s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 68/100 [19:36<07:28, 14.03s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 69/100 [19:54<07:56, 15.36s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 70/100 [20:13<08:07, 16.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 71/100 [20:30<08:01, 16.59s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 72/100 [20:49<08:02, 17.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 73/100 [20:59<06:52, 15.26s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 74/100 [21:17<06:58, 16.11s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 75/100 [21:36<07:04, 16.96s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 76/100 [21:55<06:57, 17.40s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 77/100 [22:13<06:44, 17.59s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 78/100 [22:31<06:31, 17.79s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 79/100 [22:50<06:19, 18.06s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 80/100 [23:09<06:06, 18.32s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 81/100 [23:27<05:47, 18.30s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 82/100 [23:46<05:32, 18.47s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 83/100 [24:05<05:17, 18.68s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 84/100 [24:23<04:56, 18.55s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 85/100 [24:42<04:41, 18.75s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 86/100 [25:02<04:24, 18.90s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 87/100 [25:20<04:01, 18.57s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 88/100 [25:37<03:40, 18.34s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 89/100 [25:56<03:22, 18.44s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 90/100 [26:14<03:02, 18.27s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 91/100 [26:33<02:45, 18.39s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 92/100 [26:35<01:49, 13.65s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 93/100 [26:53<01:45, 15.06s/it]3\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 94/100 [27:12<01:36, 16.05s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 95/100 [27:31<01:24, 16.83s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 96/100 [27:50<01:09, 17.48s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 97/100 [28:08<00:53, 17.78s/it]6\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 98/100 [28:28<00:36, 18.36s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 99/100 [28:46<00:18, 18.45s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 100/100 [29:05<00:00, 17.46s/it]\n",
            "0.67\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en_int \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0 \\\n",
        " --plm islam23/llama3-8b-RAG_News_Finance \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9du_uJQpSBrf",
        "outputId": "a227d1f3-60ed-48b9-c3a5-ba819cc43e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:07<00:00,  2.57s/it]\n",
            "  0% 0/100 [00:00<?, ?it/s]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1% 1/100 [00:03<05:20,  3.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  2% 2/100 [00:07<05:55,  3.63s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3% 3/100 [00:10<05:43,  3.55s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4% 4/100 [00:12<04:55,  3.08s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  5% 5/100 [00:15<04:39,  2.94s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6% 6/100 [00:19<05:09,  3.30s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  7% 7/100 [00:22<04:49,  3.12s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8% 8/100 [00:27<05:43,  3.74s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9% 9/100 [00:29<04:50,  3.19s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10% 10/100 [00:35<05:59,  3.99s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 11% 11/100 [00:38<05:34,  3.76s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12% 12/100 [00:45<06:49,  4.65s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13% 13/100 [00:47<05:43,  3.95s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14% 14/100 [00:50<05:12,  3.63s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 15% 15/100 [00:54<05:11,  3.67s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 16% 16/100 [00:57<04:58,  3.56s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17% 17/100 [01:00<04:40,  3.38s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18% 18/100 [01:03<04:26,  3.26s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19% 19/100 [01:06<04:13,  3.13s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 20% 20/100 [01:12<05:34,  4.19s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21% 21/100 [01:16<05:08,  3.91s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22% 22/100 [01:19<04:59,  3.83s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23% 23/100 [01:23<04:46,  3.71s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24% 24/100 [01:27<04:49,  3.81s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 25% 25/100 [01:30<04:34,  3.66s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26% 26/100 [01:36<05:14,  4.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27% 27/100 [01:38<04:37,  3.80s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28% 28/100 [01:48<06:33,  5.46s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29% 29/100 [01:50<05:20,  4.51s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 30% 30/100 [01:55<05:34,  4.78s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31% 31/100 [01:58<04:48,  4.19s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32% 32/100 [02:01<04:19,  3.81s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33% 33/100 [02:03<03:42,  3.31s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 34% 34/100 [02:07<03:36,  3.28s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 35% 35/100 [02:10<03:36,  3.33s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36% 36/100 [02:12<03:14,  3.04s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37% 37/100 [02:17<03:33,  3.39s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38% 38/100 [02:21<03:43,  3.60s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 39% 39/100 [02:24<03:33,  3.50s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40% 40/100 [02:29<03:56,  3.94s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41% 41/100 [02:33<03:56,  4.02s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42% 42/100 [02:35<03:16,  3.38s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 43% 43/100 [02:38<03:09,  3.32s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44% 44/100 [02:41<02:59,  3.20s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 45% 45/100 [02:46<03:28,  3.80s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46% 46/100 [02:49<03:00,  3.35s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47% 47/100 [02:51<02:44,  3.10s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 48% 48/100 [02:55<02:46,  3.20s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49% 49/100 [02:57<02:26,  2.88s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50% 50/100 [02:59<02:10,  2.60s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51% 51/100 [03:02<02:18,  2.83s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 52% 52/100 [03:05<02:12,  2.75s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53% 53/100 [03:09<02:39,  3.39s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54% 54/100 [03:13<02:34,  3.37s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 55% 55/100 [03:15<02:19,  3.10s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56% 56/100 [03:19<02:26,  3.33s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 57% 57/100 [03:22<02:19,  3.25s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58% 58/100 [03:28<02:43,  3.90s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59% 59/100 [03:33<02:57,  4.34s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60% 60/100 [03:38<03:03,  4.58s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 61% 61/100 [03:42<02:47,  4.28s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62% 62/100 [03:44<02:16,  3.58s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63% 63/100 [03:46<01:57,  3.18s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64% 64/100 [03:49<01:56,  3.23s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 65% 65/100 [03:52<01:50,  3.15s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 66% 66/100 [03:55<01:45,  3.09s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67% 67/100 [03:59<01:51,  3.37s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68% 68/100 [04:02<01:40,  3.13s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69% 69/100 [04:05<01:34,  3.06s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 70% 70/100 [04:08<01:33,  3.10s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71% 71/100 [04:11<01:28,  3.05s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72% 72/100 [04:28<03:25,  7.35s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73% 73/100 [04:31<02:38,  5.87s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74% 74/100 [04:32<01:59,  4.61s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 75% 75/100 [04:34<01:37,  3.91s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76% 76/100 [04:38<01:29,  3.75s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77% 77/100 [04:40<01:12,  3.16s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78% 78/100 [04:42<01:04,  2.93s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79% 79/100 [04:47<01:15,  3.62s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 80% 80/100 [04:53<01:24,  4.20s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81% 81/100 [04:55<01:09,  3.68s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82% 82/100 [04:59<01:06,  3.71s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83% 83/100 [05:04<01:11,  4.21s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 84% 84/100 [05:07<00:58,  3.66s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 85% 85/100 [05:12<01:01,  4.07s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86% 86/100 [05:15<00:54,  3.91s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87% 87/100 [05:18<00:44,  3.46s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88% 88/100 [05:20<00:37,  3.08s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 89% 89/100 [05:23<00:32,  2.91s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90% 90/100 [05:26<00:29,  2.98s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91% 91/100 [05:29<00:28,  3.12s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92% 92/100 [05:33<00:26,  3.26s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 93% 93/100 [05:36<00:22,  3.28s/it]3\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94% 94/100 [05:39<00:18,  3.12s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 95% 95/100 [05:41<00:14,  2.88s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96% 96/100 [05:44<00:11,  2.80s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97% 97/100 [05:45<00:07,  2.37s/it]6\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 98% 98/100 [05:52<00:07,  3.68s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99% 99/100 [05:54<00:03,  3.24s/it]2\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "100% 100/100 [05:57<00:00,  3.57s/it]\n",
            "0.66\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en_int \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0 \\\n",
        " --plm mistralai/Mistral-7B-Instruct-v0.3 \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaVlLM_nS0v8"
      },
      "source": [
        "## Noise Rejection :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-C4x584SwA9",
        "outputId": "7f8ace3d-8424-4356-859a-34ffbe6f2c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   2% 83.9M/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 94.4M/4.98G [00:00<00:46, 104MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 115M/4.98G [00:00<00:36, 132MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 168M/4.98G [00:00<00:17, 271MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 220M/4.98G [00:00<00:13, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 273M/4.98G [00:00<00:11, 402MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 325M/4.98G [00:00<00:11, 402MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 367M/4.98G [00:00<00:11, 394MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 409M/4.98G [00:00<00:11, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 461M/4.98G [00:01<00:11, 406MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 503M/4.98G [00:01<00:11, 406MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 556M/4.98G [00:01<00:10, 418MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 608M/4.98G [00:01<00:10, 425MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 661M/4.98G [00:01<00:10, 394MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 703M/4.98G [00:01<00:10, 398MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15% 755M/4.98G [00:01<00:10, 420MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 807M/4.98G [00:01<00:09, 437MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17% 860M/4.98G [00:01<00:09, 429MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 912M/4.98G [00:02<00:09, 427MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 965M/4.98G [00:02<00:09, 437MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 1.02G/4.98G [00:02<00:09, 424MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21% 1.07G/4.98G [00:02<00:09, 417MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.12G/4.98G [00:02<00:08, 433MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.17G/4.98G [00:02<00:08, 431MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25% 1.23G/4.98G [00:02<00:08, 427MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.28G/4.98G [00:02<00:08, 438MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.33G/4.98G [00:03<00:08, 434MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.38G/4.98G [00:03<00:08, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29% 1.44G/4.98G [00:03<00:08, 410MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.49G/4.98G [00:03<00:08, 418MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31% 1.54G/4.98G [00:03<00:08, 396MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.58G/4.98G [00:03<00:08, 395MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33% 1.63G/4.98G [00:03<00:08, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.68G/4.98G [00:03<00:08, 405MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.72G/4.98G [00:04<00:08, 391MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.76G/4.98G [00:04<00:08, 363MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.80G/4.98G [00:04<00:08, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.85G/4.98G [00:04<00:09, 334MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:04<00:09, 325MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39% 1.94G/4.98G [00:04<00:08, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40% 1.98G/4.98G [00:04<00:08, 354MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.02G/4.98G [00:04<00:08, 354MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.07G/4.98G [00:05<00:07, 368MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.11G/4.98G [00:05<00:07, 375MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.15G/4.98G [00:05<00:07, 381MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.20G/4.98G [00:05<00:07, 395MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.25G/4.98G [00:05<00:06, 415MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.31G/4.98G [00:05<00:06, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.36G/4.98G [00:05<00:06, 428MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48% 2.41G/4.98G [00:05<00:06, 418MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.45G/4.98G [00:06<00:06, 415MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.50G/4.98G [00:06<00:06, 378MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.55G/4.98G [00:06<00:06, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.59G/4.98G [00:06<00:06, 377MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.63G/4.98G [00:06<00:06, 379MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.67G/4.98G [00:06<00:06, 372MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.73G/4.98G [00:06<00:05, 396MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.77G/4.98G [00:06<00:05, 402MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.81G/4.98G [00:06<00:05, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57% 2.85G/4.98G [00:07<00:05, 389MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.89G/4.98G [00:07<00:05, 373MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.94G/4.98G [00:07<00:05, 361MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.98G/4.98G [00:07<00:05, 373MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.02G/4.98G [00:07<00:05, 339MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.07G/4.98G [00:07<00:05, 370MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 3.12G/4.98G [00:07<00:04, 388MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.17G/4.98G [00:07<00:04, 383MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.21G/4.98G [00:08<00:04, 381MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65% 3.25G/4.98G [00:08<00:04, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.29G/4.98G [00:08<00:04, 348MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 3.34G/4.98G [00:08<00:04, 372MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.40G/4.98G [00:08<00:04, 390MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.45G/4.98G [00:08<00:03, 406MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.50G/4.98G [00:08<00:03, 415MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.55G/4.98G [00:08<00:03, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.61G/4.98G [00:09<00:03, 427MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.66G/4.98G [00:09<00:03, 375MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.70G/4.98G [00:09<00:03, 367MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.75G/4.98G [00:09<00:03, 385MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.81G/4.98G [00:09<00:02, 400MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.86G/4.98G [00:09<00:02, 412MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.91G/4.98G [00:09<00:02, 417MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.96G/4.98G [00:09<00:02, 421MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.02G/4.98G [00:10<00:02, 426MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.07G/4.98G [00:10<00:02, 432MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83% 4.12G/4.98G [00:10<00:02, 319MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.16G/4.98G [00:10<00:02, 323MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.22G/4.98G [00:10<00:02, 350MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 4.27G/4.98G [00:10<00:01, 376MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.31G/4.98G [00:10<00:01, 381MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.36G/4.98G [00:11<00:01, 399MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.41G/4.98G [00:11<00:01, 413MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90% 4.47G/4.98G [00:11<00:01, 420MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.52G/4.98G [00:11<00:01, 428MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 4.57G/4.98G [00:11<00:00, 433MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.62G/4.98G [00:11<00:00, 436MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94% 4.68G/4.98G [00:11<00:00, 437MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.73G/4.98G [00:11<00:00, 439MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.78G/4.98G [00:11<00:00, 441MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.83G/4.98G [00:12<00:00, 452MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98% 4.89G/4.98G [00:12<00:00, 458MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:12<00:00, 395MB/s]\n",
            "Downloading shards:  25% 1/4 [00:12<00:38, 12.71s/it]\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1% 41.9M/5.00G [00:00<00:12, 383MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2% 94.4M/5.00G [00:00<00:11, 426MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3% 147M/5.00G [00:00<00:12, 398MB/s] \u001b[A\n",
            "model-00002-of-00004.safetensors:   4% 189M/5.00G [00:00<00:12, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 231M/5.00G [00:00<00:12, 374MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5% 273M/5.00G [00:00<00:12, 379MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6% 315M/5.00G [00:00<00:12, 361MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7% 357M/5.00G [00:00<00:13, 344MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8% 398M/5.00G [00:01<00:13, 338MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9% 440M/5.00G [00:01<00:14, 319MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 482M/5.00G [00:01<00:14, 309MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10% 524M/5.00G [00:01<00:13, 326MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 577M/5.00G [00:01<00:12, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12% 619M/5.00G [00:01<00:11, 373MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13% 661M/5.00G [00:01<00:11, 364MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14% 703M/5.00G [00:01<00:12, 349MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15% 744M/5.00G [00:02<00:12, 334MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16% 786M/5.00G [00:02<00:12, 330MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 828M/5.00G [00:02<00:12, 338MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17% 870M/5.00G [00:02<00:12, 342MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18% 912M/5.00G [00:02<00:11, 346MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19% 954M/5.00G [00:02<00:12, 326MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20% 1.01G/5.00G [00:02<00:11, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21% 1.05G/5.00G [00:02<00:10, 373MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22% 1.09G/5.00G [00:03<00:10, 366MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23% 1.14G/5.00G [00:03<00:10, 386MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24% 1.18G/5.00G [00:03<00:11, 346MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25% 1.24G/5.00G [00:03<00:10, 368MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.28G/5.00G [00:03<00:11, 336MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26% 1.32G/5.00G [00:03<00:11, 313MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27% 1.36G/5.00G [00:03<00:10, 335MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28% 1.42G/5.00G [00:04<00:09, 367MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29% 1.47G/5.00G [00:04<00:08, 396MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30% 1.52G/5.00G [00:04<00:08, 418MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31% 1.57G/5.00G [00:04<00:08, 412MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32% 1.61G/5.00G [00:04<00:09, 371MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33% 1.66G/5.00G [00:04<00:09, 354MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34% 1.70G/5.00G [00:04<00:09, 354MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35% 1.74G/5.00G [00:04<00:10, 321MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36% 1.79G/5.00G [00:05<00:09, 356MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37% 1.85G/5.00G [00:05<00:08, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38% 1.89G/5.00G [00:05<00:08, 362MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39% 1.94G/5.00G [00:05<00:07, 387MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40% 1.98G/5.00G [00:05<00:07, 387MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41% 2.03G/5.00G [00:05<00:07, 419MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42% 2.09G/5.00G [00:05<00:06, 444MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43% 2.14G/5.00G [00:05<00:06, 453MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44% 2.19G/5.00G [00:06<00:07, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45% 2.23G/5.00G [00:06<00:07, 369MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.28G/5.00G [00:06<00:07, 367MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46% 2.32G/5.00G [00:06<00:07, 375MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47% 2.36G/5.00G [00:06<00:06, 385MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48% 2.41G/5.00G [00:06<00:06, 416MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49% 2.46G/5.00G [00:06<00:05, 435MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50% 2.52G/5.00G [00:06<00:05, 449MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51% 2.57G/5.00G [00:06<00:05, 458MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52% 2.62G/5.00G [00:07<00:06, 371MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53% 2.66G/5.00G [00:07<00:07, 322MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54% 2.71G/5.00G [00:07<00:08, 283MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55% 2.74G/5.00G [00:07<00:11, 197MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56% 2.79G/5.00G [00:07<00:08, 247MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57% 2.83G/5.00G [00:08<00:07, 275MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58% 2.88G/5.00G [00:08<00:06, 314MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.93G/5.00G [00:08<00:06, 335MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59% 2.97G/5.00G [00:08<00:05, 348MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60% 3.01G/5.00G [00:08<00:05, 350MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61% 3.05G/5.00G [00:08<00:05, 340MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62% 3.09G/5.00G [00:08<00:05, 354MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63% 3.15G/5.00G [00:08<00:04, 387MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64% 3.20G/5.00G [00:08<00:04, 411MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65% 3.25G/5.00G [00:09<00:04, 412MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66% 3.30G/5.00G [00:09<00:04, 421MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67% 3.36G/5.00G [00:09<00:04, 410MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68% 3.41G/5.00G [00:09<00:03, 421MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69% 3.46G/5.00G [00:09<00:03, 434MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70% 3.51G/5.00G [00:09<00:03, 435MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71% 3.57G/5.00G [00:09<00:03, 432MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72% 3.62G/5.00G [00:09<00:03, 404MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73% 3.66G/5.00G [00:10<00:03, 405MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74% 3.71G/5.00G [00:10<00:03, 422MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75% 3.76G/5.00G [00:10<00:02, 433MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76% 3.82G/5.00G [00:10<00:02, 443MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77% 3.87G/5.00G [00:10<00:02, 445MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78% 3.92G/5.00G [00:10<00:02, 446MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79% 3.97G/5.00G [00:10<00:02, 423MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.03G/5.00G [00:10<00:02, 400MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81% 4.07G/5.00G [00:11<00:02, 398MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82% 4.11G/5.00G [00:11<00:02, 399MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83% 4.16G/5.00G [00:11<00:02, 415MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84% 4.20G/5.00G [00:11<00:02, 386MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [00:11<00:01, 390MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86% 4.30G/5.00G [00:11<00:01, 393MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87% 4.34G/5.00G [00:11<00:01, 362MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88% 4.39G/5.00G [00:11<00:01, 383MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89% 4.44G/5.00G [00:11<00:01, 379MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90% 4.48G/5.00G [00:12<00:01, 358MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.53G/5.00G [00:12<00:01, 378MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91% 4.57G/5.00G [00:12<00:01, 374MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92% 4.61G/5.00G [00:12<00:01, 369MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93% 4.66G/5.00G [00:12<00:00, 373MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94% 4.70G/5.00G [00:12<00:00, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95% 4.74G/5.00G [00:12<00:00, 313MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.78G/5.00G [00:13<00:00, 275MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96% 4.82G/5.00G [00:13<00:00, 305MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97% 4.87G/5.00G [00:13<00:00, 260MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98% 4.91G/5.00G [00:13<00:00, 293MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:13<00:00, 365MB/s]\n",
            "Downloading shards:  50% 2/4 [00:26<00:26, 13.47s/it]\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1% 52.4M/4.92G [00:00<00:11, 425MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2% 105M/4.92G [00:00<00:17, 282MB/s] \u001b[A\n",
            "model-00003-of-00004.safetensors:   3% 147M/4.92G [00:00<00:15, 317MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4% 189M/4.92G [00:00<00:13, 342MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5% 241M/4.92G [00:00<00:12, 375MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6% 294M/4.92G [00:00<00:11, 389MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7% 336M/4.92G [00:00<00:12, 355MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8% 377M/4.92G [00:01<00:14, 321MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 419M/4.92G [00:01<00:13, 329MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9% 461M/4.92G [00:01<00:13, 326MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10% 503M/4.92G [00:01<00:13, 322MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11% 545M/4.92G [00:01<00:12, 336MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12% 587M/4.92G [00:01<00:12, 342MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13% 629M/4.92G [00:01<00:12, 345MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14% 671M/4.92G [00:01<00:11, 364MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15% 713M/4.92G [00:02<00:12, 335MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16% 765M/4.92G [00:02<00:11, 368MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17% 818M/4.92G [00:02<00:10, 400MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18% 870M/4.92G [00:02<00:09, 424MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19% 923M/4.92G [00:02<00:09, 404MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20% 965M/4.92G [00:02<00:09, 403MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21% 1.02G/4.92G [00:02<00:09, 413MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22% 1.07G/4.92G [00:02<00:08, 428MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23% 1.12G/4.92G [00:03<00:08, 436MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24% 1.17G/4.92G [00:03<00:08, 440MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25% 1.23G/4.92G [00:03<00:08, 435MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26% 1.28G/4.92G [00:03<00:08, 439MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27% 1.33G/4.92G [00:03<00:12, 291MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28% 1.37G/4.92G [00:03<00:11, 304MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29% 1.42G/4.92G [00:03<00:10, 324MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30% 1.46G/4.92G [00:04<00:11, 310MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31% 1.51G/4.92G [00:04<00:10, 337MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32% 1.55G/4.92G [00:04<00:09, 345MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33% 1.60G/4.92G [00:04<00:08, 374MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34% 1.66G/4.92G [00:04<00:08, 399MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35% 1.71G/4.92G [00:04<00:07, 419MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36% 1.76G/4.92G [00:04<00:07, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37% 1.81G/4.92G [00:04<00:07, 425MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38% 1.87G/4.92G [00:05<00:07, 388MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39% 1.91G/4.92G [00:05<00:08, 361MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40% 1.95G/4.92G [00:05<00:08, 343MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41% 1.99G/4.92G [00:05<00:08, 351MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.04G/4.92G [00:05<00:08, 336MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42% 2.09G/4.92G [00:05<00:08, 328MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44% 2.14G/4.92G [00:05<00:07, 367MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45% 2.19G/4.92G [00:05<00:06, 402MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46% 2.24G/4.92G [00:06<00:06, 423MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47% 2.30G/4.92G [00:06<00:06, 393MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.34G/4.92G [00:06<00:06, 378MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48% 2.38G/4.92G [00:06<00:06, 380MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49% 2.43G/4.92G [00:06<00:06, 395MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51% 2.49G/4.92G [00:06<00:05, 408MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.54G/4.92G [00:06<00:05, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52% 2.58G/4.92G [00:06<00:05, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54% 2.63G/4.92G [00:07<00:05, 430MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55% 2.68G/4.92G [00:07<00:05, 442MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56% 2.74G/4.92G [00:07<00:05, 432MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57% 2.79G/4.92G [00:07<00:05, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58% 2.83G/4.92G [00:07<00:05, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59% 2.88G/4.92G [00:07<00:04, 407MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60% 2.93G/4.92G [00:07<00:05, 393MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 2.98G/4.92G [00:07<00:04, 416MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61% 3.02G/4.92G [00:08<00:04, 412MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62% 3.07G/4.92G [00:08<00:04, 418MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64% 3.12G/4.92G [00:08<00:04, 429MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65% 3.18G/4.92G [00:08<00:03, 445MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66% 3.23G/4.92G [00:08<00:03, 453MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67% 3.28G/4.92G [00:08<00:03, 422MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68% 3.33G/4.92G [00:08<00:03, 435MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69% 3.39G/4.92G [00:08<00:03, 424MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70% 3.44G/4.92G [00:09<00:03, 404MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71% 3.49G/4.92G [00:09<00:03, 417MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72% 3.54G/4.92G [00:09<00:03, 429MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73% 3.60G/4.92G [00:09<00:03, 427MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74% 3.65G/4.92G [00:09<00:03, 402MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75% 3.69G/4.92G [00:09<00:03, 402MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76% 3.74G/4.92G [00:09<00:02, 399MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77% 3.79G/4.92G [00:09<00:02, 401MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78% 3.84G/4.92G [00:09<00:02, 414MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79% 3.88G/4.92G [00:10<00:02, 410MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80% 3.92G/4.92G [00:10<00:02, 392MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 3.96G/4.92G [00:10<00:02, 400MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81% 4.01G/4.92G [00:10<00:02, 402MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82% 4.05G/4.92G [00:10<00:02, 406MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83% 4.09G/4.92G [00:10<00:02, 410MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84% 4.13G/4.92G [00:10<00:01, 409MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85% 4.17G/4.92G [00:10<00:01, 404MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86% 4.22G/4.92G [00:10<00:01, 397MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87% 4.27G/4.92G [00:11<00:01, 400MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88% 4.31G/4.92G [00:11<00:01, 398MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.35G/4.92G [00:11<00:01, 346MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89% 4.39G/4.92G [00:11<00:01, 362MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90% 4.45G/4.92G [00:11<00:01, 384MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:11<00:01, 324MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92% 4.54G/4.92G [00:11<00:01, 352MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93% 4.59G/4.92G [00:11<00:00, 375MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94% 4.65G/4.92G [00:12<00:00, 389MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96% 4.70G/4.92G [00:12<00:00, 399MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97% 4.75G/4.92G [00:12<00:00, 407MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98% 4.80G/4.92G [00:12<00:00, 417MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99% 4.85G/4.92G [00:12<00:00, 421MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:12<00:00, 387MB/s]\n",
            "Downloading shards:  75% 3/4 [00:40<00:13, 13.43s/it]\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   4% 41.9M/1.17G [00:00<00:02, 400MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   8% 94.4M/1.17G [00:00<00:02, 443MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13% 147M/1.17G [00:00<00:02, 383MB/s] \u001b[A\n",
            "model-00004-of-00004.safetensors:  16% 189M/1.17G [00:00<00:02, 349MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  20% 231M/1.17G [00:00<00:02, 349MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  23% 273M/1.17G [00:00<00:02, 341MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27% 315M/1.17G [00:00<00:02, 341MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31% 357M/1.17G [00:00<00:02, 359MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  34% 398M/1.17G [00:01<00:02, 372MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  38% 440M/1.17G [00:01<00:01, 382MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  41% 482M/1.17G [00:01<00:01, 368MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46% 535M/1.17G [00:01<00:01, 387MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  50% 587M/1.17G [00:01<00:01, 412MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  55% 640M/1.17G [00:01<00:01, 436MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  59% 692M/1.17G [00:01<00:01, 448MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  64% 744M/1.17G [00:01<00:00, 453MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  68% 797M/1.17G [00:01<00:00, 463MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73% 849M/1.17G [00:02<00:00, 434MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  77% 902M/1.17G [00:02<00:00, 442MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82% 954M/1.17G [00:02<00:00, 297MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86% 1.01G/1.17G [00:02<00:00, 335MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  91% 1.06G/1.17G [00:02<00:00, 361MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95% 1.11G/1.17G [00:02<00:00, 378MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:03<00:00, 380MB/s]\n",
            "Downloading shards: 100% 4/4 [00:43<00:00, 10.93s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:07<00:00,  1.87s/it]\n",
            "generation_config.json: 100% 187/187 [00:00<00:00, 1.34MB/s]\n",
            "adapter_model.safetensors: 100% 54.6M/54.6M [00:00<00:00, 287MB/s]\n",
            "  0% 0/300 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  0% 1/300 [00:06<34:01,  6.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 2/300 [00:25<1:09:14, 13.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 3/300 [00:44<1:19:49, 16.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 4/300 [01:03<1:24:46, 17.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 5/300 [01:22<1:27:44, 17.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 6/300 [01:41<1:29:33, 18.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 7/300 [02:00<1:30:37, 18.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 8/300 [02:19<1:30:46, 18.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 9/300 [02:38<1:31:03, 18.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 10/300 [02:57<1:31:19, 18.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 11/300 [03:00<1:07:43, 14.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 12/300 [03:19<1:13:40, 15.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 13/300 [03:38<1:19:05, 16.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 14/300 [03:57<1:22:32, 17.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 15/300 [04:03<1:06:16, 13.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 16/300 [04:22<1:13:09, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 17/300 [04:41<1:18:08, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 18/300 [05:00<1:21:35, 17.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 19/300 [05:19<1:23:48, 17.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 20/300 [05:39<1:25:19, 18.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 21/300 [05:58<1:26:22, 18.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 22/300 [06:17<1:26:47, 18.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 23/300 [06:36<1:27:08, 18.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 24/300 [06:55<1:26:51, 18.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 25/300 [07:14<1:26:31, 18.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 26/300 [07:17<1:04:43, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 27/300 [07:36<1:11:26, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 28/300 [07:56<1:16:03, 16.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 29/300 [08:15<1:19:06, 17.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 30/300 [08:34<1:21:05, 18.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 31/300 [08:53<1:22:13, 18.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 32/300 [09:02<1:09:29, 15.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 33/300 [09:21<1:13:51, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 34/300 [09:41<1:17:04, 17.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 35/300 [10:00<1:19:01, 17.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 36/300 [10:19<1:20:08, 18.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 37/300 [10:38<1:20:59, 18.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 38/300 [10:57<1:21:39, 18.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 39/300 [11:16<1:22:03, 18.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 40/300 [11:35<1:21:35, 18.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 41/300 [11:52<1:18:30, 18.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 42/300 [12:11<1:19:29, 18.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 43/300 [12:30<1:19:53, 18.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 44/300 [12:34<1:00:48, 14.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 45/300 [12:53<1:06:51, 15.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 46/300 [13:12<1:10:55, 16.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 47/300 [13:31<1:13:42, 17.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 48/300 [13:50<1:15:12, 17.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 49/300 [14:09<1:16:32, 18.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 50/300 [14:29<1:17:24, 18.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 51/300 [14:48<1:17:58, 18.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 52/300 [15:07<1:18:15, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 53/300 [15:26<1:18:00, 18.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 54/300 [15:45<1:17:55, 19.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 55/300 [16:04<1:17:20, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 56/300 [16:23<1:17:15, 19.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 57/300 [16:42<1:17:03, 19.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 58/300 [17:01<1:16:30, 18.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 59/300 [17:20<1:16:10, 18.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 60/300 [17:39<1:16:02, 19.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 61/300 [17:58<1:15:53, 19.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 62/300 [18:17<1:15:29, 19.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 63/300 [18:37<1:15:21, 19.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 64/300 [18:56<1:15:10, 19.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 65/300 [19:15<1:15:03, 19.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 66/300 [19:34<1:14:33, 19.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 67/300 [19:53<1:14:19, 19.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 68/300 [20:13<1:14:08, 19.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 69/300 [20:14<53:20, 13.85s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 70/300 [20:33<59:15, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 71/300 [20:52<1:03:12, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 72/300 [21:12<1:05:59, 17.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 73/300 [21:31<1:07:31, 17.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 74/300 [21:50<1:08:48, 18.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 75/300 [22:04<1:03:47, 17.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 76/300 [22:23<1:05:59, 17.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 77/300 [22:42<1:07:32, 18.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 78/300 [23:02<1:08:26, 18.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 79/300 [23:21<1:08:58, 18.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 80/300 [23:40<1:09:07, 18.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 81/300 [23:59<1:08:46, 18.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 82/300 [24:18<1:08:29, 18.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 83/300 [24:37<1:08:25, 18.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 84/300 [24:56<1:08:18, 18.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 85/300 [25:08<1:01:03, 17.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 86/300 [25:27<1:02:39, 17.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 87/300 [25:47<1:04:33, 18.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 88/300 [26:06<1:05:03, 18.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 89/300 [26:25<1:05:10, 18.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 90/300 [26:44<1:05:22, 18.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 91/300 [27:03<1:05:38, 18.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 92/300 [27:22<1:05:34, 18.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 93/300 [27:41<1:05:32, 19.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 94/300 [28:00<1:05:29, 19.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 95/300 [28:20<1:05:19, 19.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 96/300 [28:39<1:05:08, 19.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 97/300 [28:58<1:04:53, 19.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 98/300 [29:17<1:04:37, 19.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 99/300 [29:37<1:04:20, 19.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 100/300 [29:56<1:04:04, 19.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 101/300 [30:15<1:03:47, 19.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 102/300 [30:34<1:03:08, 19.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 103/300 [30:53<1:02:57, 19.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 104/300 [31:12<1:02:28, 19.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 105/300 [31:31<1:02:00, 19.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 106/300 [31:50<1:01:28, 19.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 107/300 [32:09<1:01:04, 18.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 108/300 [32:28<1:01:04, 19.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 109/300 [32:47<1:00:40, 19.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 110/300 [33:06<1:00:08, 18.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 111/300 [33:25<59:48, 18.99s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 112/300 [33:44<59:25, 18.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 113/300 [34:03<59:25, 19.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 114/300 [34:10<47:10, 15.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 115/300 [34:20<42:08, 13.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 116/300 [34:38<46:05, 15.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 117/300 [34:57<49:34, 16.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 118/300 [35:16<51:46, 17.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 119/300 [35:35<53:02, 17.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 120/300 [35:54<54:02, 18.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 121/300 [36:12<54:20, 18.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 122/300 [36:32<54:51, 18.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 123/300 [36:50<54:51, 18.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 124/300 [37:10<55:03, 18.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 125/300 [37:28<54:22, 18.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 126/300 [37:47<54:29, 18.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 127/300 [38:06<54:25, 18.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 128/300 [38:25<54:22, 18.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 129/300 [38:45<54:13, 19.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 130/300 [39:03<53:44, 18.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 131/300 [39:23<53:38, 19.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 132/300 [39:32<45:17, 16.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 133/300 [39:51<47:36, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 134/300 [40:11<49:07, 17.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 135/300 [40:30<49:57, 18.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 136/300 [40:49<50:27, 18.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 137/300 [41:08<50:45, 18.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 138/300 [41:13<39:03, 14.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 139/300 [41:32<42:36, 15.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 140/300 [41:51<44:55, 16.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 141/300 [42:10<46:29, 17.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 142/300 [42:29<47:25, 18.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 143/300 [42:48<47:50, 18.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 144/300 [43:07<48:17, 18.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 145/300 [43:15<39:18, 15.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 146/300 [43:34<41:55, 16.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 147/300 [43:53<43:51, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 148/300 [44:12<45:04, 17.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 149/300 [44:31<45:44, 18.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 150/300 [44:50<46:15, 18.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 151/300 [45:10<46:30, 18.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 152/300 [45:29<46:22, 18.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 153/300 [45:33<35:17, 14.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 154/300 [45:35<26:10, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 155/300 [45:54<31:52, 13.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 156/300 [46:13<35:50, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 157/300 [46:32<38:39, 16.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 158/300 [46:51<40:21, 17.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 159/300 [47:10<41:25, 17.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 160/300 [47:29<42:14, 18.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 161/300 [47:48<42:37, 18.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 162/300 [48:08<42:58, 18.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 163/300 [48:13<33:11, 14.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 164/300 [48:31<35:39, 15.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 165/300 [48:50<37:45, 16.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 166/300 [49:09<39:01, 17.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 167/300 [49:28<39:42, 17.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 168/300 [49:48<40:17, 18.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 169/300 [50:07<40:34, 18.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 170/300 [50:26<40:37, 18.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 171/300 [50:38<36:12, 16.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 172/300 [50:58<37:22, 17.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 173/300 [51:17<38:10, 18.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 174/300 [51:21<29:28, 14.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 175/300 [51:40<32:21, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 176/300 [51:42<23:17, 11.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 177/300 [52:01<28:00, 13.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 178/300 [52:20<30:54, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 179/300 [52:39<32:52, 16.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 180/300 [52:58<34:18, 17.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 181/300 [53:17<35:11, 17.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 182/300 [53:36<35:35, 18.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 183/300 [53:54<35:34, 18.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 184/300 [54:14<35:49, 18.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 185/300 [54:32<35:31, 18.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 186/300 [54:51<35:28, 18.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 187/300 [55:10<35:16, 18.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 188/300 [55:29<34:56, 18.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 189/300 [55:48<34:54, 18.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 190/300 [56:07<34:48, 18.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 191/300 [56:26<34:34, 19.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 192/300 [56:46<34:23, 19.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 193/300 [57:04<33:55, 19.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 194/300 [57:24<33:42, 19.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 195/300 [57:43<33:17, 19.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 196/300 [58:02<33:07, 19.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 197/300 [58:21<32:51, 19.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 198/300 [58:40<32:24, 19.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 199/300 [58:59<32:06, 19.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 200/300 [59:18<31:43, 19.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 201/300 [59:37<31:30, 19.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 202/300 [59:56<31:11, 19.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 203/300 [1:00:16<30:56, 19.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 204/300 [1:00:17<21:59, 13.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 205/300 [1:00:36<24:16, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 206/300 [1:00:55<25:51, 16.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 207/300 [1:01:14<26:47, 17.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 208/300 [1:01:33<27:09, 17.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 209/300 [1:01:52<27:31, 18.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 210/300 [1:02:04<24:28, 16.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 211/300 [1:02:23<25:31, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 212/300 [1:02:43<26:08, 17.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 213/300 [1:02:52<22:07, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 214/300 [1:03:11<23:36, 16.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 215/300 [1:03:30<24:25, 17.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 216/300 [1:03:49<24:42, 17.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 217/300 [1:04:08<24:55, 18.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 218/300 [1:04:27<24:57, 18.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 219/300 [1:04:46<25:00, 18.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 220/300 [1:05:04<24:48, 18.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 221/300 [1:05:19<23:04, 17.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 222/300 [1:05:36<22:19, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 223/300 [1:05:55<22:47, 17.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 224/300 [1:06:14<23:04, 18.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 225/300 [1:06:34<23:09, 18.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 226/300 [1:06:52<22:50, 18.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 227/300 [1:06:59<18:17, 15.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 228/300 [1:07:18<19:29, 16.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 229/300 [1:07:37<20:08, 17.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 230/300 [1:07:56<20:28, 17.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 231/300 [1:08:15<20:46, 18.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 232/300 [1:08:17<15:09, 13.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 233/300 [1:08:37<16:54, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 234/300 [1:08:56<17:56, 16.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 235/300 [1:09:14<18:12, 16.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 236/300 [1:09:33<18:43, 17.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 237/300 [1:09:52<18:55, 18.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 238/300 [1:10:11<19:00, 18.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 239/300 [1:10:30<18:55, 18.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 240/300 [1:10:44<17:00, 17.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 241/300 [1:11:03<17:22, 17.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 242/300 [1:11:22<17:32, 18.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 243/300 [1:11:41<17:27, 18.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 244/300 [1:12:00<17:20, 18.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 245/300 [1:12:13<15:29, 16.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 246/300 [1:12:32<15:48, 17.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 247/300 [1:12:51<15:54, 18.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 248/300 [1:13:10<15:53, 18.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 249/300 [1:13:30<15:48, 18.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 250/300 [1:13:49<15:40, 18.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 251/300 [1:13:57<12:42, 15.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 252/300 [1:14:16<13:12, 16.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 253/300 [1:14:34<13:26, 17.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 254/300 [1:14:42<10:57, 14.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 255/300 [1:15:01<11:46, 15.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 256/300 [1:15:20<12:14, 16.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 257/300 [1:15:39<12:31, 17.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 258/300 [1:15:58<12:32, 17.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 259/300 [1:16:17<12:30, 18.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 260/300 [1:16:37<12:23, 18.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 261/300 [1:16:56<12:13, 18.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 262/300 [1:17:15<11:59, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 263/300 [1:17:34<11:44, 19.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 264/300 [1:17:54<11:27, 19.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 265/300 [1:17:58<08:33, 14.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 266/300 [1:18:17<09:03, 15.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 267/300 [1:18:36<09:18, 16.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 268/300 [1:18:55<09:21, 17.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 269/300 [1:19:14<09:14, 17.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 270/300 [1:19:33<09:07, 18.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 271/300 [1:19:52<08:56, 18.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 272/300 [1:20:10<08:36, 18.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 273/300 [1:20:29<08:23, 18.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 274/300 [1:20:48<08:04, 18.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 275/300 [1:21:07<07:50, 18.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 276/300 [1:21:26<07:33, 18.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 277/300 [1:21:46<07:16, 18.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 278/300 [1:22:04<06:56, 18.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 279/300 [1:22:24<06:38, 19.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 280/300 [1:22:42<06:16, 18.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 281/300 [1:23:01<05:59, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 282/300 [1:23:20<05:41, 18.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 283/300 [1:23:39<05:22, 18.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 284/300 [1:23:58<05:03, 18.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 285/300 [1:24:17<04:45, 19.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 286/300 [1:24:36<04:26, 19.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 287/300 [1:24:56<04:08, 19.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 288/300 [1:25:15<03:48, 19.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 289/300 [1:25:23<02:56, 16.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 290/300 [1:25:43<02:49, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 291/300 [1:25:59<02:31, 16.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 292/300 [1:26:08<01:55, 14.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 293/300 [1:26:27<01:50, 15.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 294/300 [1:26:46<01:40, 16.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 295/300 [1:27:05<01:27, 17.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 296/300 [1:27:24<01:11, 17.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 297/300 [1:27:43<00:54, 18.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 298/300 [1:27:53<00:31, 15.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 299/300 [1:28:12<00:16, 16.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 300/300 [1:28:32<00:00, 17.71s/it]\n",
            "0.33666666666666667\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 1 \\\n",
        " --plm islam23/llama3-8b-RAG_News_Finance \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9brxJUorS0Po",
        "outputId": "14b35505-be8b-472b-8158-457df78b1eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Loading checkpoint shards: 100% 3/3 [00:06<00:00,  2.31s/it]\n",
            "  0% 0/300 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  0% 1/300 [00:04<22:06,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1% 2/300 [00:06<13:57,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1% 3/300 [00:07<11:35,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  1% 4/300 [00:09<10:04,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  2% 5/300 [00:11<10:07,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  2% 6/300 [00:13<09:37,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  2% 7/300 [00:15<09:54,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3% 8/300 [00:17<09:36,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3% 9/300 [00:19<09:31,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  3% 10/300 [00:22<11:45,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4% 11/300 [00:28<16:13,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4% 12/300 [00:29<13:27,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  4% 13/300 [00:31<12:13,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  5% 14/300 [00:34<12:01,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  5% 15/300 [00:37<13:03,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  5% 16/300 [00:39<12:38,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6% 17/300 [00:41<11:17,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6% 18/300 [00:44<11:06,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  6% 19/300 [00:46<10:41,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  7% 20/300 [00:48<10:47,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  7% 21/300 [00:50<10:37,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  7% 22/300 [00:53<11:42,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8% 23/300 [00:55<10:32,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8% 24/300 [00:57<10:33,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  8% 25/300 [00:59<10:02,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9% 26/300 [01:02<10:44,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9% 27/300 [01:04<09:52,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "  9% 28/300 [01:13<19:09,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10% 29/300 [01:15<15:59,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10% 30/300 [01:17<14:13,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 10% 31/300 [01:20<13:49,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 11% 32/300 [01:23<14:14,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 11% 33/300 [01:25<12:15,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 11% 34/300 [01:29<14:16,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12% 35/300 [01:31<12:31,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12% 36/300 [01:33<10:50,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 12% 37/300 [01:38<14:45,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13% 38/300 [01:41<13:49,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13% 39/300 [01:43<12:15,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 13% 40/300 [01:45<11:29,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14% 41/300 [01:54<18:56,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14% 42/300 [01:56<15:24,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 14% 43/300 [01:57<13:14,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 15% 44/300 [02:02<15:24,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 15% 45/300 [02:04<13:08,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 15% 46/300 [02:10<17:08,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 16% 47/300 [02:13<14:37,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 16% 48/300 [02:15<13:23,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 16% 49/300 [02:17<11:13,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17% 50/300 [02:18<09:06,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17% 51/300 [02:20<08:50,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 17% 52/300 [02:22<08:50,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18% 53/300 [02:28<14:04,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18% 54/300 [02:30<12:33,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 18% 55/300 [02:33<12:05,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19% 56/300 [02:35<10:52,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19% 57/300 [02:37<10:01,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 19% 58/300 [02:40<09:58,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 20% 59/300 [02:44<12:01,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 20% 60/300 [02:47<11:46,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 20% 61/300 [02:51<13:25,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21% 62/300 [02:54<13:24,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21% 63/300 [02:57<12:08,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 21% 64/300 [02:59<11:00,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22% 65/300 [03:02<10:46,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22% 66/300 [03:05<11:59,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 22% 67/300 [03:08<11:01,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23% 68/300 [03:10<10:16,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23% 69/300 [03:13<10:25,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 23% 70/300 [03:15<09:58,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24% 71/300 [03:17<09:34,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24% 72/300 [03:20<09:05,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 24% 73/300 [03:23<09:44,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 25% 74/300 [03:24<08:29,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 25% 75/300 [03:27<08:47,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 25% 76/300 [03:30<10:12,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26% 77/300 [03:32<09:27,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26% 78/300 [03:40<14:35,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 26% 79/300 [03:42<12:34,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27% 80/300 [03:46<13:05,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27% 81/300 [03:51<15:26,  4.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 27% 82/300 [03:55<14:10,  3.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28% 83/300 [03:57<12:03,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28% 84/300 [03:59<10:55,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 28% 85/300 [04:04<13:19,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29% 86/300 [04:08<13:08,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29% 87/300 [04:10<11:44,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 29% 88/300 [04:12<10:09,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 30% 89/300 [04:15<09:55,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 30% 90/300 [04:17<08:43,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 30% 91/300 [04:19<08:15,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31% 92/300 [04:20<07:29,  2.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31% 93/300 [04:22<06:54,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 31% 94/300 [04:25<07:35,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32% 95/300 [04:27<08:02,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32% 96/300 [04:32<09:56,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 32% 97/300 [04:34<09:24,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33% 98/300 [04:37<09:04,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33% 99/300 [04:39<08:50,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 33% 100/300 [04:42<09:36,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 34% 101/300 [04:45<09:15,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 34% 102/300 [04:47<08:10,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 34% 103/300 [04:49<08:17,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 35% 104/300 [04:58<14:14,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 35% 105/300 [05:01<12:34,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 35% 106/300 [05:10<17:16,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36% 107/300 [05:12<14:01,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36% 108/300 [05:17<14:34,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 36% 109/300 [05:18<11:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37% 110/300 [05:23<13:02,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37% 111/300 [05:30<15:00,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 37% 112/300 [05:31<11:57,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38% 113/300 [05:38<14:57,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38% 114/300 [05:40<12:10,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 38% 115/300 [05:42<10:04,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 39% 116/300 [05:43<08:04,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 39% 117/300 [05:45<07:16,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 39% 118/300 [05:55<14:14,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40% 119/300 [05:57<11:55,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40% 120/300 [06:01<11:51,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 40% 121/300 [06:04<10:47,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41% 122/300 [06:08<10:43,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41% 123/300 [06:10<09:17,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 41% 124/300 [06:11<07:56,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42% 125/300 [06:14<07:34,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42% 126/300 [06:17<08:04,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 42% 127/300 [06:20<08:41,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 43% 128/300 [06:24<09:04,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 43% 129/300 [06:26<07:45,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 43% 130/300 [06:29<08:11,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44% 131/300 [06:31<07:15,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44% 132/300 [06:33<07:17,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 44% 133/300 [06:36<06:50,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 45% 134/300 [06:37<06:03,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 45% 135/300 [06:39<05:43,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 45% 136/300 [06:40<05:05,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46% 137/300 [06:43<05:51,  2.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46% 138/300 [06:45<05:42,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 46% 139/300 [06:47<05:38,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47% 140/300 [06:49<05:10,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47% 141/300 [06:51<05:21,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 47% 142/300 [06:55<06:36,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 48% 143/300 [06:57<06:13,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 48% 144/300 [06:59<06:15,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 48% 145/300 [07:01<05:41,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49% 146/300 [07:05<07:16,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49% 147/300 [07:08<07:23,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 49% 148/300 [07:12<08:16,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50% 149/300 [07:15<07:53,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50% 150/300 [07:18<07:15,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 50% 151/300 [07:23<08:44,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51% 152/300 [07:25<07:51,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51% 153/300 [07:27<07:12,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 51% 154/300 [07:30<07:04,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 52% 155/300 [07:34<07:28,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 52% 156/300 [07:36<06:44,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 52% 157/300 [07:39<06:57,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53% 158/300 [07:52<14:18,  6.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53% 159/300 [07:54<11:01,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 53% 160/300 [07:57<09:36,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54% 161/300 [07:59<08:12,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54% 162/300 [08:06<10:17,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 54% 163/300 [08:09<09:12,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 55% 164/300 [08:12<08:29,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 55% 165/300 [08:13<07:05,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 55% 166/300 [08:16<06:23,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56% 167/300 [08:22<08:35,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56% 168/300 [08:27<09:22,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 56% 169/300 [08:32<09:49,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 57% 170/300 [08:37<10:15,  4.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 57% 171/300 [08:40<09:02,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 57% 172/300 [08:43<07:53,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58% 173/300 [08:46<07:39,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58% 174/300 [08:48<06:21,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 58% 175/300 [08:50<05:41,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59% 176/300 [08:52<05:03,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59% 177/300 [08:55<05:20,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 59% 178/300 [08:58<05:41,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60% 179/300 [09:12<12:38,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60% 180/300 [09:14<09:39,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 60% 181/300 [09:15<07:40,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 61% 182/300 [09:17<06:17,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 61% 183/300 [09:19<05:39,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 61% 184/300 [09:29<09:19,  4.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62% 185/300 [09:32<08:17,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62% 186/300 [09:35<07:30,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 62% 187/300 [09:37<06:31,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63% 188/300 [09:39<05:26,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63% 189/300 [09:40<04:33,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 63% 190/300 [09:44<05:06,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64% 191/300 [09:46<04:47,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64% 192/300 [09:48<04:38,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 64% 193/300 [09:50<04:11,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 65% 194/300 [09:53<04:05,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 65% 195/300 [09:55<04:17,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 65% 196/300 [09:57<03:51,  2.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 66% 197/300 [09:59<03:55,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 66% 198/300 [10:01<03:28,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 66% 199/300 [10:03<03:16,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67% 200/300 [10:04<02:58,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67% 201/300 [10:13<06:33,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 67% 202/300 [10:16<06:01,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68% 203/300 [10:19<05:25,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68% 204/300 [10:21<05:02,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 68% 205/300 [10:23<04:16,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69% 206/300 [10:25<04:06,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69% 207/300 [10:27<03:40,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 69% 208/300 [10:29<03:24,  2.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 70% 209/300 [10:31<03:12,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 70% 210/300 [10:37<05:01,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 70% 211/300 [10:39<04:14,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71% 212/300 [10:44<05:11,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71% 213/300 [10:47<04:53,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 71% 214/300 [10:50<04:42,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72% 215/300 [10:52<04:00,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72% 216/300 [10:55<04:12,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 72% 217/300 [11:00<05:01,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73% 218/300 [11:03<04:32,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73% 219/300 [11:09<05:44,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 73% 220/300 [11:12<04:52,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74% 221/300 [11:15<04:45,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74% 222/300 [11:21<05:29,  4.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 74% 223/300 [11:27<06:08,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 75% 224/300 [11:30<05:27,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 75% 225/300 [11:38<06:40,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 75% 226/300 [11:40<05:33,  4.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76% 227/300 [11:44<05:06,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76% 228/300 [11:49<05:18,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 76% 229/300 [11:58<06:48,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77% 230/300 [12:01<05:51,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77% 231/300 [12:05<05:22,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 77% 232/300 [12:07<04:27,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78% 233/300 [12:10<03:58,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78% 234/300 [12:13<03:41,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 78% 235/300 [12:15<03:22,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79% 236/300 [12:19<03:29,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79% 237/300 [12:21<03:01,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 79% 238/300 [12:23<02:41,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 80% 239/300 [12:25<02:25,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 80% 240/300 [12:27<02:20,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 80% 241/300 [12:31<02:49,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81% 242/300 [12:33<02:38,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81% 243/300 [12:36<02:40,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 81% 244/300 [12:38<02:23,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82% 245/300 [12:44<03:09,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82% 246/300 [12:47<02:56,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 82% 247/300 [12:50<02:46,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83% 248/300 [12:52<02:30,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83% 249/300 [12:54<02:16,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 83% 250/300 [12:57<02:16,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 84% 251/300 [12:59<02:00,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 84% 252/300 [13:00<01:40,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 84% 253/300 [13:02<01:39,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 85% 254/300 [13:05<01:46,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 85% 255/300 [13:08<01:48,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 85% 256/300 [13:09<01:32,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86% 257/300 [13:16<02:34,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86% 258/300 [13:19<02:19,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 86% 259/300 [13:22<02:14,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87% 260/300 [13:27<02:28,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87% 261/300 [13:30<02:19,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 87% 262/300 [13:33<02:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88% 263/300 [13:36<01:58,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88% 264/300 [13:37<01:38,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 88% 265/300 [13:40<01:35,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 89% 266/300 [13:43<01:33,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 89% 267/300 [13:46<01:30,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 89% 268/300 [13:48<01:18,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90% 269/300 [13:50<01:18,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90% 270/300 [13:53<01:15,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 90% 271/300 [13:56<01:18,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91% 272/300 [13:58<01:08,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91% 273/300 [14:01<01:12,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 91% 274/300 [14:03<01:03,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92% 275/300 [14:06<01:02,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92% 276/300 [14:09<01:05,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 92% 277/300 [14:10<00:55,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 93% 278/300 [14:12<00:47,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 93% 279/300 [14:15<00:51,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 93% 280/300 [14:20<01:03,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94% 281/300 [14:22<00:51,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94% 282/300 [14:23<00:43,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 94% 283/300 [14:25<00:36,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 95% 284/300 [14:27<00:34,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 95% 285/300 [14:29<00:29,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 95% 286/300 [14:30<00:26,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96% 287/300 [14:32<00:24,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96% 288/300 [14:34<00:22,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 96% 289/300 [14:38<00:29,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97% 290/300 [14:43<00:31,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97% 291/300 [14:44<00:24,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 97% 292/300 [14:46<00:19,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 98% 293/300 [14:48<00:15,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 98% 294/300 [14:51<00:14,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 98% 295/300 [14:53<00:10,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99% 296/300 [14:57<00:11,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99% 297/300 [14:58<00:07,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            " 99% 298/300 [15:02<00:05,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "100% 299/300 [15:05<00:02,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "100% 300/300 [15:08<00:00,  3.03s/it]\n",
            "0.39666666666666667\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 1 \\\n",
        " --plm mistralai/Mistral-7B-Instruct-v0.3 \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSm7rbpMTez7"
      },
      "source": [
        "# Noise Robustness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNTdo6TYThld",
        "outputId": "cea35d81-6722-454b-cddf-5c344fd40c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Downloading shards: 100% 4/4 [00:00<00:00, 17.86it/s]\n",
            "Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.26s/it]\n",
            "  0% 0/300 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  0% 1/300 [00:16<1:24:34, 16.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 2/300 [00:18<39:12,  7.89s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 3/300 [00:33<56:01, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1% 4/300 [00:49<1:03:51, 12.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 5/300 [01:04<1:08:01, 13.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 6/300 [01:20<1:10:36, 14.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  2% 7/300 [01:35<1:11:59, 14.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 8/300 [01:51<1:12:48, 14.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 9/300 [02:06<1:13:17, 15.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  3% 10/300 [02:14<1:02:19, 12.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 11/300 [02:30<1:05:56, 13.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 12/300 [02:45<1:08:09, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  4% 13/300 [03:00<1:09:43, 14.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 14/300 [03:16<1:10:43, 14.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 15/300 [03:31<1:11:19, 15.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  5% 16/300 [03:47<1:11:46, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 17/300 [04:02<1:11:52, 15.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 18/300 [04:17<1:10:48, 15.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  6% 19/300 [04:32<1:11:06, 15.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 20/300 [04:48<1:11:34, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 21/300 [05:03<1:11:32, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  7% 22/300 [05:19<1:11:14, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 23/300 [05:34<1:10:58, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 24/300 [05:50<1:10:41, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  8% 25/300 [06:05<1:10:27, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 26/300 [06:12<59:04, 12.94s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 27/300 [06:28<1:02:12, 13.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  9% 28/300 [06:43<1:04:12, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 29/300 [06:58<1:05:38, 14.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 30/300 [07:14<1:06:33, 14.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10% 31/300 [07:29<1:07:06, 14.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 32/300 [07:44<1:07:23, 15.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 33/300 [08:00<1:07:38, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 11% 34/300 [08:15<1:07:40, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 35/300 [08:31<1:07:37, 15.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 36/300 [08:46<1:07:28, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 12% 37/300 [09:01<1:07:14, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 38/300 [09:17<1:07:03, 15.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 39/300 [09:32<1:06:52, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 13% 40/300 [09:48<1:06:42, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 41/300 [10:03<1:06:21, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 42/300 [10:18<1:06:05, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 14% 43/300 [10:34<1:05:49, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 44/300 [10:36<48:22, 11.34s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 45/300 [10:51<53:20, 12.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 15% 46/300 [11:06<56:46, 13.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 47/300 [11:22<59:07, 14.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 48/300 [11:37<1:00:37, 14.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 16% 49/300 [11:53<1:01:29, 14.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 50/300 [12:08<1:02:02, 14.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 51/300 [12:23<1:02:20, 15.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 17% 52/300 [12:39<1:02:32, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 53/300 [12:54<1:02:33, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 54/300 [13:09<1:02:33, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 18% 55/300 [13:25<1:02:27, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 56/300 [13:40<1:02:15, 15.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 57/300 [13:56<1:02:05, 15.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 19% 58/300 [14:11<1:01:50, 15.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 59/300 [14:26<1:01:33, 15.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 60/300 [14:41<1:01:18, 15.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20% 61/300 [14:43<44:54, 11.27s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 62/300 [14:59<49:31, 12.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 63/300 [15:14<52:42, 13.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 21% 64/300 [15:29<54:49, 13.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 65/300 [15:45<56:15, 14.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 66/300 [16:00<57:07, 14.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 22% 67/300 [16:15<57:48, 14.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 68/300 [16:31<58:07, 15.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 69/300 [16:46<58:16, 15.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 23% 70/300 [17:01<58:15, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 71/300 [17:17<58:11, 15.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 72/300 [17:32<58:00, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 24% 73/300 [17:36<44:20, 11.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 74/300 [17:51<48:13, 12.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 75/300 [18:06<50:51, 13.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 25% 76/300 [18:22<52:34, 14.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 77/300 [18:37<53:51, 14.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 78/300 [18:52<54:31, 14.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 26% 79/300 [19:08<55:00, 14.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 80/300 [19:23<55:10, 15.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 81/300 [19:38<55:17, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 27% 82/300 [19:54<55:13, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 83/300 [20:09<55:10, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 84/300 [20:25<55:05, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 28% 85/300 [20:40<54:49, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 86/300 [20:55<54:29, 15.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 87/300 [21:10<54:19, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 29% 88/300 [21:26<54:10, 15.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 89/300 [21:41<54:07, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 90/300 [21:57<54:00, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 30% 91/300 [22:12<53:42, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 92/300 [22:28<53:31, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 93/300 [22:43<53:14, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 31% 94/300 [22:59<52:57, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 95/300 [23:14<52:44, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 96/300 [23:29<52:26, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 32% 97/300 [23:45<52:16, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 98/300 [24:00<51:58, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 99/300 [24:16<51:40, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 33% 100/300 [24:31<51:21, 15.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 101/300 [24:46<51:01, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 102/300 [25:02<50:44, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 34% 103/300 [25:17<50:33, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 104/300 [25:33<50:25, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 105/300 [25:48<50:07, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 35% 106/300 [26:04<49:47, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 107/300 [26:19<49:31, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 108/300 [26:34<49:16, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 36% 109/300 [26:50<49:02, 15.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 110/300 [27:05<48:58, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 111/300 [27:21<48:48, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 37% 112/300 [27:37<48:40, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 113/300 [27:52<48:16, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 114/300 [28:07<47:57, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 38% 115/300 [28:23<47:36, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 116/300 [28:38<47:17, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 117/300 [28:53<46:56, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 39% 118/300 [29:09<46:39, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 119/300 [29:11<34:05, 11.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 120/300 [29:26<37:32, 12.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40% 121/300 [29:41<39:54, 13.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 122/300 [29:57<41:24, 13.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 123/300 [30:12<42:24, 14.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 41% 124/300 [30:27<43:03, 14.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 125/300 [30:43<43:27, 14.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 126/300 [30:49<35:43, 12.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 42% 127/300 [31:04<38:08, 13.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 128/300 [31:20<39:43, 13.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 129/300 [31:35<40:47, 14.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 43% 130/300 [31:51<41:33, 14.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 131/300 [32:06<42:08, 14.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 132/300 [32:19<39:39, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 44% 133/300 [32:34<40:33, 14.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 134/300 [32:49<40:58, 14.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 135/300 [33:05<41:09, 14.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 45% 136/300 [33:20<41:14, 15.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 137/300 [33:36<41:20, 15.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 138/300 [33:37<29:36, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 46% 139/300 [33:52<32:57, 12.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 140/300 [34:07<35:16, 13.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 141/300 [34:23<36:46, 13.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 47% 142/300 [34:30<31:06, 11.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 143/300 [34:45<33:42, 12.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 144/300 [35:01<35:31, 13.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 48% 145/300 [35:16<36:41, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 146/300 [35:32<37:19, 14.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 147/300 [35:47<37:42, 14.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 49% 148/300 [36:02<37:55, 14.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 149/300 [36:18<38:03, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 150/300 [36:33<37:58, 15.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 50% 151/300 [36:49<37:55, 15.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 152/300 [37:04<37:42, 15.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 153/300 [37:19<37:30, 15.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 51% 154/300 [37:35<37:16, 15.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 155/300 [37:50<37:01, 15.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 156/300 [38:05<36:49, 15.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 52% 157/300 [38:21<36:40, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 158/300 [38:36<36:27, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 159/300 [38:52<36:11, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 53% 160/300 [39:07<35:54, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 161/300 [39:08<25:32, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 162/300 [39:23<28:19, 12.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 54% 163/300 [39:39<30:13, 13.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 164/300 [39:54<31:24, 13.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 165/300 [40:09<32:10, 14.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 55% 166/300 [40:11<23:41, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 167/300 [40:27<26:41, 12.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 168/300 [40:42<28:41, 13.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 56% 169/300 [40:57<29:58, 13.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 170/300 [40:59<21:48, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 171/300 [41:14<25:06, 11.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 57% 172/300 [41:30<27:15, 12.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 173/300 [41:45<28:39, 13.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 174/300 [42:00<29:33, 14.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 58% 175/300 [42:16<30:08, 14.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 176/300 [42:31<30:24, 14.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 177/300 [42:43<28:40, 13.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 59% 178/300 [42:59<29:17, 14.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 179/300 [43:14<29:36, 14.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 180/300 [43:29<29:49, 14.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60% 181/300 [43:45<29:54, 15.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 182/300 [44:00<29:50, 15.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 183/300 [44:16<29:42, 15.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 61% 184/300 [44:31<29:36, 15.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 185/300 [44:47<29:25, 15.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 186/300 [45:02<29:15, 15.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 62% 187/300 [45:17<29:01, 15.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 188/300 [45:33<28:49, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 189/300 [45:48<28:32, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 63% 190/300 [46:04<28:16, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 191/300 [46:19<28:00, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 192/300 [46:35<27:48, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 64% 193/300 [46:50<27:34, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 194/300 [47:06<27:18, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 195/300 [47:21<27:03, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 65% 196/300 [47:37<26:50, 15.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 197/300 [47:52<26:39, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 198/300 [48:08<26:20, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 66% 199/300 [48:23<26:07, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 200/300 [48:39<25:55, 15.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 201/300 [48:54<25:34, 15.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 67% 202/300 [49:10<25:16, 15.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 203/300 [49:25<24:58, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 204/300 [49:41<24:44, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 68% 205/300 [49:56<24:29, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 206/300 [50:12<24:17, 15.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 207/300 [50:27<24:04, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 69% 208/300 [50:43<23:47, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 209/300 [50:58<23:32, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 210/300 [51:14<23:16, 15.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 70% 211/300 [51:29<23:02, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 212/300 [51:45<22:45, 15.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 213/300 [52:00<22:28, 15.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 71% 214/300 [52:13<21:04, 14.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 215/300 [52:29<21:08, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 216/300 [52:44<21:09, 15.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 72% 217/300 [53:00<21:04, 15.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 218/300 [53:15<20:56, 15.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 219/300 [53:31<20:44, 15.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 73% 220/300 [53:41<18:27, 13.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 221/300 [53:56<18:52, 14.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 222/300 [54:12<19:07, 14.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 74% 223/300 [54:27<19:09, 14.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 224/300 [54:43<19:05, 15.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 225/300 [54:58<18:59, 15.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 75% 226/300 [55:00<13:51, 11.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 227/300 [55:16<15:12, 12.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 228/300 [55:30<15:34, 12.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 76% 229/300 [55:45<16:14, 13.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 230/300 [56:01<16:36, 14.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 231/300 [56:16<16:49, 14.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 77% 232/300 [56:25<14:41, 12.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 233/300 [56:41<15:21, 13.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 234/300 [56:57<15:44, 14.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 78% 235/300 [57:12<15:55, 14.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 236/300 [57:28<15:55, 14.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 237/300 [57:43<15:50, 15.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 79% 238/300 [57:59<15:44, 15.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 239/300 [58:14<15:31, 15.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 240/300 [58:27<14:25, 14.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80% 241/300 [58:42<14:30, 14.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 242/300 [58:58<14:28, 14.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 243/300 [59:13<14:24, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 81% 244/300 [59:29<14:13, 15.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 245/300 [59:30<10:13, 11.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 246/300 [59:46<11:13, 12.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 82% 247/300 [1:00:01<11:48, 13.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 248/300 [1:00:07<09:38, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 249/300 [1:00:16<08:50, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 83% 250/300 [1:00:31<09:54, 11.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 251/300 [1:00:39<08:48, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 252/300 [1:00:55<09:44, 12.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 84% 253/300 [1:01:10<10:18, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 254/300 [1:01:26<10:37, 13.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 255/300 [1:01:41<10:48, 14.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 85% 256/300 [1:01:57<10:48, 14.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 257/300 [1:01:59<07:51, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 258/300 [1:02:14<08:36, 12.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 86% 259/300 [1:02:30<09:02, 13.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 260/300 [1:02:45<09:15, 13.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 261/300 [1:03:01<09:19, 14.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 87% 262/300 [1:03:16<09:17, 14.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 263/300 [1:03:32<09:10, 14.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 264/300 [1:03:47<09:01, 15.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 88% 265/300 [1:03:52<07:06, 12.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 266/300 [1:04:08<07:26, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 267/300 [1:04:09<05:12,  9.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 89% 268/300 [1:04:24<05:59, 11.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 269/300 [1:04:39<06:27, 12.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 270/300 [1:04:41<04:36,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 90% 271/300 [1:04:56<05:20, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 272/300 [1:05:12<05:44, 12.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 273/300 [1:05:27<05:57, 13.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 91% 274/300 [1:05:35<05:04, 11.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 275/300 [1:05:51<05:20, 12.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 276/300 [1:06:06<05:26, 13.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 92% 277/300 [1:06:22<05:26, 14.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 278/300 [1:06:37<05:20, 14.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 279/300 [1:06:52<05:10, 14.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 93% 280/300 [1:06:59<04:08, 12.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 281/300 [1:07:15<04:12, 13.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 282/300 [1:07:30<04:10, 13.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 94% 283/300 [1:07:45<04:04, 14.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 284/300 [1:08:01<03:55, 14.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 285/300 [1:08:16<03:43, 14.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 95% 286/300 [1:08:32<03:30, 15.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 287/300 [1:08:47<03:16, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 288/300 [1:09:02<03:02, 15.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 96% 289/300 [1:09:18<02:47, 15.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 290/300 [1:09:33<02:33, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 291/300 [1:09:49<02:18, 15.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 97% 292/300 [1:10:04<02:02, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 293/300 [1:10:19<01:47, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 294/300 [1:10:29<01:22, 13.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 98% 295/300 [1:10:45<01:11, 14.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 296/300 [1:11:00<00:58, 14.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 297/300 [1:11:16<00:44, 14.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 99% 298/300 [1:11:31<00:30, 15.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 299/300 [1:11:46<00:15, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100% 300/300 [1:12:02<00:00, 14.41s/it]\n",
            "0.85\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm islam23/llama3-8b-RAG_News_Finance \\\n",
        " --passage_num 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCsDw1Q7TslB",
        "outputId": "787d29c0-38a9-4382-c756-991985d771ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 1.46k/1.46k [00:00<00:00, 9.31MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 37.9MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 7.74MB/s]\n",
            "special_tokens_map.json: 100% 72.0/72.0 [00:00<00:00, 555kB/s]\n",
            "config.json: 100% 596/596 [00:00<00:00, 4.54MB/s]\n",
            "model.safetensors.index.json: 100% 25.1k/25.1k [00:00<00:00, 88.6MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.94G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 21.0M/4.94G [00:00<00:27, 177MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 52.4M/4.94G [00:00<00:21, 224MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 115M/4.94G [00:00<00:13, 367MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.94G [00:00<00:10, 442MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 231M/4.94G [00:00<00:10, 439MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 294M/4.94G [00:00<00:09, 474MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 357M/4.94G [00:00<00:09, 498MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 419M/4.94G [00:00<00:08, 518MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 482M/4.94G [00:01<00:08, 534MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 545M/4.94G [00:01<00:08, 549MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 608M/4.94G [00:01<00:07, 559MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 671M/4.94G [00:01<00:07, 560MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 734M/4.94G [00:01<00:07, 558MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 797M/4.94G [00:01<00:07, 551MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.94G [00:01<00:07, 548MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 923M/4.94G [00:01<00:07, 542MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 986M/4.94G [00:01<00:07, 532MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.05G/4.94G [00:02<00:07, 523MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.11G/4.94G [00:02<00:07, 512MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.16G/4.94G [00:02<00:07, 509MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.22G/4.94G [00:02<00:07, 506MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.27G/4.94G [00:02<00:07, 505MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.32G/4.94G [00:02<00:07, 494MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.37G/4.94G [00:02<00:07, 496MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.43G/4.94G [00:02<00:07, 497MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.94G [00:02<00:06, 500MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.53G/4.94G [00:03<00:06, 500MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.58G/4.94G [00:03<00:06, 502MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.64G/4.94G [00:03<00:06, 505MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.69G/4.94G [00:03<00:06, 510MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.74G/4.94G [00:03<00:06, 512MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.79G/4.94G [00:03<00:06, 513MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.85G/4.94G [00:03<00:06, 513MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.90G/4.94G [00:03<00:05, 513MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.94G [00:03<00:05, 514MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.00G/4.94G [00:03<00:05, 514MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.06G/4.94G [00:04<00:05, 512MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.11G/4.94G [00:04<00:05, 513MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.16G/4.94G [00:04<00:05, 516MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.21G/4.94G [00:04<00:05, 486MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.26G/4.94G [00:04<00:05, 494MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.94G [00:04<00:05, 444MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.37G/4.94G [00:04<00:06, 400MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.41G/4.94G [00:04<00:06, 391MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.46G/4.94G [00:05<00:06, 408MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.51G/4.94G [00:05<00:06, 391MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.55G/4.94G [00:05<00:06, 351MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.94G [00:05<00:07, 326MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.94G [00:05<00:07, 309MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.67G/4.94G [00:05<00:07, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.71G/4.94G [00:05<00:07, 292MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.74G/4.94G [00:06<00:07, 288MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.77G/4.94G [00:06<00:07, 283MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.80G/4.94G [00:06<00:07, 281MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.83G/4.94G [00:06<00:07, 279MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.86G/4.94G [00:06<00:07, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.89G/4.94G [00:06<00:07, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.94G [00:06<00:07, 270MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.96G/4.94G [00:06<00:07, 279MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.99G/4.94G [00:06<00:07, 267MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.02G/4.94G [00:07<00:07, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.05G/4.94G [00:07<00:07, 270MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.10G/4.94G [00:07<00:05, 329MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.16G/4.94G [00:07<00:04, 378MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.21G/4.94G [00:07<00:04, 415MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.26G/4.94G [00:07<00:03, 442MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.31G/4.94G [00:07<00:03, 462MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.37G/4.94G [00:07<00:03, 478MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.94G [00:07<00:03, 489MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.47G/4.94G [00:07<00:02, 499MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.94G [00:08<00:02, 488MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.58G/4.94G [00:08<00:02, 491MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.94G [00:08<00:02, 498MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.68G/4.94G [00:08<00:02, 503MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.73G/4.94G [00:08<00:02, 507MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.80G/4.94G [00:08<00:02, 512MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.86G/4.94G [00:08<00:02, 513MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.91G/4.94G [00:08<00:02, 507MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.94G [00:08<00:01, 511MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.02G/4.94G [00:09<00:01, 478MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.07G/4.94G [00:09<00:02, 426MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.12G/4.94G [00:09<00:02, 352MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.16G/4.94G [00:09<00:02, 322MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.20G/4.94G [00:09<00:02, 301MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.25G/4.94G [00:09<00:02, 276MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.28G/4.94G [00:10<00:02, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.31G/4.94G [00:10<00:03, 186MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.35G/4.94G [00:10<00:02, 217MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.38G/4.94G [00:10<00:02, 216MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.94G [00:10<00:02, 215MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.45G/4.94G [00:10<00:02, 214MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.48G/4.94G [00:11<00:02, 212MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.51G/4.94G [00:11<00:01, 221MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.56G/4.94G [00:11<00:01, 276MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.94G [00:11<00:01, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.67G/4.94G [00:11<00:00, 357MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.72G/4.94G [00:11<00:00, 381MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.77G/4.94G [00:11<00:00, 400MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.82G/4.94G [00:11<00:00, 413MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.88G/4.94G [00:12<00:00, 421MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.94G [00:12<00:00, 403MB/s]\n",
            "Downloading shards:  33% 1/3 [00:12<00:25, 12.77s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 41.9M/5.00G [00:00<00:12, 394MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 94.4M/5.00G [00:00<00:11, 436MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 147M/5.00G [00:00<00:10, 451MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 199M/5.00G [00:00<00:10, 455MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 252M/5.00G [00:00<00:10, 459MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 304M/5.00G [00:00<00:10, 461MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 357M/5.00G [00:00<00:10, 461MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 409M/5.00G [00:00<00:09, 461MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 461M/5.00G [00:01<00:09, 462MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 514M/5.00G [00:01<00:09, 462MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 566M/5.00G [00:01<00:09, 463MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 619M/5.00G [00:01<00:09, 464MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 671M/5.00G [00:01<00:09, 464MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 724M/5.00G [00:01<00:09, 464MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 776M/5.00G [00:01<00:09, 463MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 828M/5.00G [00:01<00:09, 441MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 881M/5.00G [00:01<00:09, 417MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 933M/5.00G [00:02<00:10, 395MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 975M/5.00G [00:02<00:10, 381MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.02G/5.00G [00:02<00:11, 358MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.06G/5.00G [00:02<00:11, 340MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.10G/5.00G [00:02<00:11, 332MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.14G/5.00G [00:02<00:11, 333MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.18G/5.00G [00:02<00:10, 352MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.23G/5.00G [00:02<00:10, 365MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.28G/5.00G [00:03<00:09, 391MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.32G/5.00G [00:04<00:49, 73.9MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.37G/5.00G [00:04<00:35, 103MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/5.00G [00:05<00:26, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.47G/5.00G [00:05<00:21, 164MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.51G/5.00G [00:05<00:17, 195MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.55G/5.00G [00:05<00:15, 227MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/5.00G [00:05<00:13, 256MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.64G/5.00G [00:05<00:12, 277MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.68G/5.00G [00:05<00:11, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.72G/5.00G [00:05<00:10, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.76G/5.00G [00:05<00:09, 338MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.80G/5.00G [00:06<00:09, 354MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.85G/5.00G [00:06<00:08, 361MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.89G/5.00G [00:06<00:08, 364MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.93G/5.00G [00:06<00:08, 373MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.97G/5.00G [00:06<00:09, 315MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 2.02G/5.00G [00:06<00:08, 362MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.08G/5.00G [00:06<00:07, 369MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.13G/5.00G [00:06<00:07, 386MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.17G/5.00G [00:07<00:07, 392MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.21G/5.00G [00:07<00:07, 381MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.25G/5.00G [00:07<00:07, 380MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.30G/5.00G [00:07<00:07, 379MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.34G/5.00G [00:07<00:07, 379MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.38G/5.00G [00:07<00:06, 387MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.42G/5.00G [00:07<00:09, 260MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.47G/5.00G [00:07<00:08, 314MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.53G/5.00G [00:08<00:06, 360MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.58G/5.00G [00:08<00:06, 400MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/5.00G [00:08<00:05, 436MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.69G/5.00G [00:08<00:05, 398MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.75G/5.00G [00:08<00:05, 411MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.80G/5.00G [00:08<00:05, 409MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.85G/5.00G [00:08<00:05, 397MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/5.00G [00:08<00:05, 387MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.94G/5.00G [00:09<00:05, 386MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.98G/5.00G [00:09<00:05, 388MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 3.02G/5.00G [00:09<00:05, 381MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.06G/5.00G [00:09<00:04, 389MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.10G/5.00G [00:09<00:05, 375MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.16G/5.00G [00:09<00:04, 371MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.20G/5.00G [00:09<00:04, 372MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.25G/5.00G [00:09<00:04, 390MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.29G/5.00G [00:10<00:04, 377MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.33G/5.00G [00:10<00:04, 379MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.38G/5.00G [00:10<00:04, 374MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.42G/5.00G [00:10<00:04, 372MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.46G/5.00G [00:10<00:04, 382MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.50G/5.00G [00:10<00:04, 373MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.54G/5.00G [00:10<00:03, 377MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.59G/5.00G [00:10<00:03, 377MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.63G/5.00G [00:10<00:03, 377MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.67G/5.00G [00:13<00:28, 46.5MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.70G/5.00G [00:13<00:22, 58.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.76G/5.00G [00:13<00:13, 91.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/5.00G [00:14<00:08, 132MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.89G/5.00G [00:14<00:06, 179MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.95G/5.00G [00:14<00:04, 231MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 4.02G/5.00G [00:14<00:03, 284MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.08G/5.00G [00:14<00:02, 336MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.14G/5.00G [00:14<00:02, 383MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.20G/5.00G [00:14<00:01, 425MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.27G/5.00G [00:14<00:01, 458MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.33G/5.00G [00:14<00:01, 480MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.39G/5.00G [00:15<00:01, 495MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.46G/5.00G [00:15<00:01, 508MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.52G/5.00G [00:15<00:00, 519MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.58G/5.00G [00:15<00:00, 522MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.65G/5.00G [00:15<00:00, 522MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.71G/5.00G [00:15<00:00, 522MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.77G/5.00G [00:15<00:00, 520MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.83G/5.00G [00:15<00:00, 515MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.89G/5.00G [00:16<00:00, 489MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.94G/5.00G [00:16<00:00, 480MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [00:16<00:00, 307MB/s]\n",
            "Downloading shards:  67% 2/3 [00:29<00:15, 15.13s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   0% 21.0M/4.54G [00:00<00:23, 190MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 52.4M/4.54G [00:00<00:20, 218MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 105M/4.54G [00:00<00:13, 340MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 168M/4.54G [00:00<00:10, 419MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   5% 231M/4.54G [00:00<00:09, 461MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 294M/4.54G [00:00<00:08, 487MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 346M/4.54G [00:00<00:08, 497MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   9% 398M/4.54G [00:00<00:08, 505MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 451M/4.54G [00:01<00:08, 508MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  11% 503M/4.54G [00:01<00:07, 506MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 556M/4.54G [00:01<00:07, 506MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 608M/4.54G [00:01<00:07, 506MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 661M/4.54G [00:01<00:07, 507MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 713M/4.54G [00:01<00:07, 511MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  17% 765M/4.54G [00:01<00:07, 515MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 818M/4.54G [00:01<00:07, 512MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 881M/4.54G [00:01<00:07, 518MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  21% 933M/4.54G [00:01<00:06, 518MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 996M/4.54G [00:02<00:06, 522MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 1.06G/4.54G [00:02<00:06, 528MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 1.12G/4.54G [00:02<00:06, 528MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 1.18G/4.54G [00:02<00:06, 526MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 1.25G/4.54G [00:02<00:06, 522MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  29% 1.30G/4.54G [00:02<00:06, 522MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.35G/4.54G [00:02<00:06, 515MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 1.41G/4.54G [00:02<00:06, 516MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 1.46G/4.54G [00:02<00:05, 515MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 1.51G/4.54G [00:03<00:05, 513MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.56G/4.54G [00:03<00:05, 510MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 1.61G/4.54G [00:03<00:05, 510MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 1.67G/4.54G [00:03<00:05, 494MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 1.72G/4.54G [00:03<00:05, 497MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  39% 1.77G/4.54G [00:03<00:05, 497MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 1.82G/4.54G [00:03<00:05, 499MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 1.88G/4.54G [00:03<00:05, 502MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 1.93G/4.54G [00:03<00:05, 439MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 1.98G/4.54G [00:04<00:06, 421MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 2.03G/4.54G [00:04<00:06, 408MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 2.08G/4.54G [00:04<00:06, 400MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 2.12G/4.54G [00:04<00:06, 394MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 2.16G/4.54G [00:04<00:06, 387MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 2.20G/4.54G [00:04<00:05, 391MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 2.24G/4.54G [00:04<00:05, 387MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 2.29G/4.54G [00:04<00:05, 385MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 2.33G/4.54G [00:04<00:05, 378MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  52% 2.37G/4.54G [00:07<00:38, 56.1MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 2.43G/4.54G [00:07<00:24, 86.5MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 2.50G/4.54G [00:07<00:16, 124MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 2.56G/4.54G [00:07<00:11, 169MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 2.61G/4.54G [00:07<00:09, 207MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.66G/4.54G [00:07<00:07, 247MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  60% 2.72G/4.54G [00:07<00:06, 292MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 2.77G/4.54G [00:08<00:05, 335MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.82G/4.54G [00:08<00:04, 372MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 2.87G/4.54G [00:08<00:04, 402MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 2.93G/4.54G [00:08<00:03, 428MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 2.98G/4.54G [00:08<00:03, 449MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 3.04G/4.54G [00:08<00:03, 480MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 3.10G/4.54G [00:08<00:02, 506MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 3.17G/4.54G [00:08<00:02, 526MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 3.23G/4.54G [00:08<00:02, 525MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 3.29G/4.54G [00:08<00:02, 536MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 3.36G/4.54G [00:09<00:02, 540MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 3.42G/4.54G [00:09<00:02, 543MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 3.48G/4.54G [00:09<00:01, 545MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 3.54G/4.54G [00:09<00:01, 549MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 3.61G/4.54G [00:09<00:01, 541MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.67G/4.54G [00:09<00:01, 537MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  82% 3.73G/4.54G [00:09<00:01, 539MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 3.80G/4.54G [00:09<00:01, 542MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 3.86G/4.54G [00:10<00:01, 357MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 3.91G/4.54G [00:10<00:01, 322MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 3.97G/4.54G [00:10<00:01, 367MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 4.04G/4.54G [00:10<00:01, 405MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 4.10G/4.54G [00:10<00:01, 437MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 4.16G/4.54G [00:10<00:00, 465MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 4.23G/4.54G [00:11<00:00, 486MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  94% 4.29G/4.54G [00:11<00:00, 503MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 4.35G/4.54G [00:11<00:00, 517MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 4.41G/4.54G [00:11<00:00, 526MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  99% 4.48G/4.54G [00:11<00:00, 533MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 4.54G/4.54G [00:11<00:00, 391MB/s]\n",
            "Downloading shards: 100% 3/3 [00:41<00:00, 13.89s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:07<00:00,  2.36s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 982kB/s]\n",
            "100% 300/300 [00:00<00:00, 11671.92it/s]\n",
            "0.9266666666666666\n"
          ]
        }
      ],
      "source": [
        "!python evalue.py \\\n",
        " --dataset en \\\n",
        " --modelname WizardLM\\\n",
        " --temp 0.2 \\\n",
        " --noise_rate 0.6 \\\n",
        " --plm mistralai/Mistral-7B-Instruct-v0.3 \\\n",
        " --passage_num 5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
